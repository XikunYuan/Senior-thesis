{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The goal of this code is to classify EEG motor imagery signal. linear classifiers are applied directly on the raw EEG signal on time and frequency domain, but results are not satisfactory. Previous works on EEG classification make use of covariance matrix and obtained satisfactory results. Classifiers based on covariance matrix are tested and proven to work well on a single experimental subject, but not as well across different subjects. \n",
    "\n",
    "#### In order to investigate the hidden patterns in the EEG signal, a convolutional neural network is built. CNN is known for object detection in images. If there is indeed hidden patterns in the covariance, it makes sense to input a covariance matrix as an image input into CNN. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below handles the preprocessing of the raw data with the help of python library MNE. The EEG data comes from PhysioNet, one of the largest EEG dataset online. The link: https://www.physionet.org/physiobank/database/eegmmidb/. The dataset can also be linked from mne.datasets.eegbci.load_data() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d9933d12968d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mepochs_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mepochs_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs_total\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#initializing training samples and labels\n",
    "#epochs will be concatenated\n",
    "epochs_total = np.zeros(1)\n",
    "labels_total = np.zeros(1)\n",
    "epochs_train_total = np.zeros(1)\n",
    "\n",
    "\n",
    "#Using data taken from 108 different people, each performing various MI tasks. In this experiment, we are trying to \n",
    "#classify motor imagery of hands vs. feet, only run 6, 10, 14 are relevant\n",
    "for i in range(108):\n",
    "    subject = i+1\n",
    "    runs = [6, 10, 14] \n",
    "\n",
    "    \n",
    "    #the 3 lines below are taken from mne website\n",
    "    #reading eeg files and concatenate them into one file\n",
    "    raw_fnames = mne.datasets.eegbci.load_data(subject, runs)\n",
    "    raw_files = [mne.io.read_raw_edf(f, preload=True, stim_channel='auto') for f in\n",
    "                 raw_fnames]\n",
    "    raw = mne.io.concatenate_raws(raw_files)\n",
    "    raw.rename_channels(lambda x: x.strip('.'))\n",
    "\n",
    "    #We can print the names of all 64 electrode channels, but only some of them are \n",
    "    #relevant to motor imagery.\n",
    "    #The relevant channels are FC5, FC3, C5, C3, CP5, CP3, FP2, FC4, FC6, C4\n",
    "    print(raw.ch_names)\n",
    "    \n",
    "    #Electrode relevant to right hand MI: FC5, FC3, C5, C3, CP5, CP3\n",
    "    right_hand = np.array([0,1,7,8,14,15])\n",
    "    #Electrode relevant to left hand MI: FC2, FC4, FC6, C4\n",
    "    left_hand = np.array([23, 5, 6, 12])\n",
    "    \n",
    "    \n",
    "    #print the channel names to verify we got the right ones\n",
    "    for i in right_hand:\n",
    "        print(raw.ch_names[i])\n",
    "    \n",
    "    for i in left_hand:\n",
    "        print(raw.ch_names[i])\n",
    "\n",
    "        \n",
    "        \n",
    "    #Since it is shown motor imagery will change the mu band (8 -13 Hz) and beta band (13 - 25 Hz), we want to \n",
    "    #filter out the noise by applying a band pass filter\n",
    "    raw.filter(7., 30., fir_design='firwin', skip_by_annotation='edge')\n",
    "\n",
    "    \n",
    "    #the next four lines make raw data into epochs for training\n",
    "    #The time points when stimuli was presented in front of the experimental subjects \n",
    "    #are recorded in stim channel. We take a second before the stimuli happened and four seconds\n",
    "    #afterward.\n",
    "    #passing these parameter into mne.Epochs\n",
    "    events = mne.find_events(raw, shortest_event=0, stim_channel='STI 014')\n",
    "    picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                       exclude='bads')\n",
    "    tmin, tmax = -1., 4.\n",
    "    event_id = dict(hands=2, feet=3)\n",
    "    epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks,\n",
    "                    baseline=None, preload=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Since right after the stimuli the eeg might not be pure motor imagery\n",
    "    #only take the 1-2 seconds after as training data\n",
    "    epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "    epochs_train = epochs_train.get_data()\n",
    "    labels = epochs.events[:, -1] - 2\n",
    "\n",
    "    \n",
    "    \n",
    "    #the section below simply concatenate all epochs into one ndarray\n",
    "    epochs_data = epochs.get_data()\n",
    "    if epochs_total.size == 1:\n",
    "        epochs_total = epochs_data\n",
    "    else:\n",
    "        epochs_total = np.concatenate((epochs_total, epochs_data), axis = 0)\n",
    "        \n",
    "        \n",
    "    if labels_total.size == 1:\n",
    "        labels_total = labels\n",
    "    else:\n",
    "        labels_total = np.concatenate((labels_total, labels), axis = 0)\n",
    "        \n",
    "        \n",
    "    if epochs_train_total.size == 1:\n",
    "        epochs_train_total = epochs_train\n",
    "    else:\n",
    "        epochs_train_total = np.concatenate((epochs_train_total, epochs_train), axis = 0)\n",
    "        \n",
    "\n",
    "        \n",
    "#printing the shape of the samples and labels to make sure they make sense\n",
    "print(epochs_total.shape)\n",
    "print(labels_total.shape)\n",
    "print(epochs_train_total.shape)\n",
    "\n",
    "\n",
    "#Please ignore the error message below. This is due to corrupted #89 dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kun\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:433: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  array = np.array(array, dtype=dtype, order=order, copy=copy)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.484103 / Chance level: 0.516667\n"
     ]
    }
   ],
   "source": [
    "#the first naive approach would be feeding frequency series directly into a logistic regression classifier\n",
    "#training sample size: 3504\n",
    "#testing sample size: 390\n",
    "#input shape: 10 selected channels X 161 frequency points (DFT of time series)\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import ShuffleSplit  \n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "\n",
    "index = np.concatenate((left_hand,right_hand))\n",
    "\n",
    "\n",
    "clf = sklearn.linear_model.LogisticRegression(C=1)\n",
    "#Using 10 fold cross validation\n",
    "cv = ShuffleSplit(n_splits=10)\n",
    "scores = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(labels_total):\n",
    "    y_train, y_test = labels_total[train_idx], labels_total[test_idx]\n",
    "    X_train = epochs_train_total[train_idx][:,index]\n",
    "    \n",
    "    X_train = fft(X_train)\n",
    "    \n",
    "    #Since logistic regression only handles 1D data, the 2D eeg data is flattened\n",
    "    X_train = X_train.reshape(1610,3504).T\n",
    "    X_test = epochs_train_total[test_idx][:,index]\n",
    "    X_test = fft(X_test)\n",
    "    X_test = X_test.reshape(1610,390).T\n",
    "    \n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "    \n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))\n",
    "\n",
    "\n",
    "#As predicted, the accuracy is only 48%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.530769 / Chance level: 0.516667\n"
     ]
    }
   ],
   "source": [
    "# A classifier that shows good performance is from this paper\n",
    "#The idea is as below:\n",
    "    #1. take the covariance matrix of the input matrix. This can be calculated as A^T * A\n",
    "    #2. Project the covariance matrix to either Euclidean space or Riemannian space\n",
    "    #3. Calculate the centroid of each class\n",
    "    #4. To classify a new point, simply find the class with the nearest centroid\n",
    "\n",
    "import sklearn \n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import pyriemann.classification\n",
    "import pyriemann.estimation\n",
    "\n",
    "\n",
    "# a function that verify the covariance matrix is indeed positive definitive and \n",
    "# proper to be projected onto a Riemannian space\n",
    "# From math, as long as all the eigen values of a matrix are positive, it is positive definitive\n",
    "def check_pos_def(x):\n",
    "    return np.all(np.linalg.eigvals(x) >= 0)\n",
    "\n",
    "\n",
    "#Only use the channels that are relevant to motor imagery to decrease noise\n",
    "index = np.concatenate((left_hand,right_hand))\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10)\n",
    "scores = []\n",
    "epochs_data = epochs_train_total\n",
    "\n",
    "for train_idx, test_idx in cv.split(labels_total):\n",
    "    y_train, y_test = labels_total[train_idx], labels_total[test_idx]\n",
    "    X_train = epochs_data[train_idx]\n",
    "    X_test = epochs_data[test_idx]\n",
    "\n",
    "    \n",
    "    #Converting input matrix into covariance matrices\n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    \n",
    "\n",
    "    mdm = pyriemann.classification.MDM(metric=dict(mean='riemann', distance='riemann'))\n",
    "    mdm.fit(cov_X_train, y_train)\n",
    "    y_predict = mdm.predict(cov_X_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.720000 / Chance level: 0.501027\n"
     ]
    }
   ],
   "source": [
    "#However, when only testing on the same person, the accuracy is good\n",
    "# The accuracy is %\n",
    "# This shows that covariance matrix does reveal a characteristics of eeg signal\n",
    "# the difficulty could come from transfer learning, the experience from on subject cannot be applied to another subject directly\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10)\n",
    "scores = []\n",
    "epochs_data = epochs_train_total[:50,:]\n",
    "\n",
    "\n",
    "for train_idx, test_idx in cv.split(labels_total[:50]):\n",
    "    y_train, y_test = labels_total[train_idx], labels_total[test_idx]\n",
    "    X_train = epochs_data[train_idx]\n",
    "    X_test = epochs_data[test_idx]\n",
    "    \n",
    "    #Converting input matrix into covariance matrices\n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    \n",
    "    #fitting the data to MDM classifier\n",
    "    mdm = pyriemann.classification.MDM(metric=dict(mean='riemann', distance='riemann'))\n",
    "    mdm.fit(cov_X_train, y_train)\n",
    "    y_predict = mdm.predict(cov_X_test)\n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3115 64\n",
      "779 64\n",
      "3115 64\n",
      "779 64\n",
      "3115 64\n",
      "779 64\n",
      "3115 64\n",
      "779 64\n",
      "3115 64\n",
      "779 64\n",
      "3115 64\n",
      "779 64\n",
      "3115 64\n",
      "779 64\n",
      "3115 64\n",
      "779 64\n",
      "3115 64\n",
      "779 64\n",
      "3115 64\n",
      "779 64\n",
      "Classification accuracy: 0.636200 / Chance level: 0.516667\n"
     ]
    }
   ],
   "source": [
    "# another classifier based on covariance matrix projected on Riemmanian spaced is shown in this paper by ths same author\n",
    "#whenn applied on a smaller sample size, the accuracy of the tangent space classifier is good\n",
    "#it agains shows that the covariance matrix of eeg data contains useful information\n",
    "# but the difficulty is in transfer learning\n",
    "\n",
    "#even when we increase sample size to 150, the accuracy achieve 72%\n",
    "\n",
    "import sklearn \n",
    "import numpy as np\n",
    "import pyriemann.estimation\n",
    "import pyriemann.classification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "epochs_data = epochs_train_total\n",
    "\n",
    "for train_idx, test_idx in cv.split(labels_total):\n",
    "    y_train, y_test = labels_total[train_idx], labels_total[test_idx]\n",
    "    X_train = epochs_data[train_idx]\n",
    "    X_test = epochs_data[test_idx]\n",
    "\n",
    "    \n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    \n",
    "    TSclassifier = pyriemann.classification.TSclassifier(metric='riemann')\n",
    "    TSclassifier.fit(cov_X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_predict = TSclassifier.predict(cov_X_test)\n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using neural networks to explore pattern in the covariance matrix, we can attempt to use linear classifiers. Linear discriminant analysis is chosen. \n",
    "\n",
    "Since the covariance matrix is always symmetrical, each value will appear twice, therefore we only take the upper half of the covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3504, 10, 10)\n",
      "(390, 10, 10)\n",
      "(3504, 10, 10)\n",
      "(390, 10, 10)\n",
      "(3504, 10, 10)\n",
      "(390, 10, 10)\n",
      "(3504, 10, 10)\n",
      "(390, 10, 10)\n",
      "(3504, 10, 10)\n",
      "(390, 10, 10)\n",
      "(3504, 10, 10)\n",
      "(390, 10, 10)\n",
      "(3504, 10, 10)\n",
      "(390, 10, 10)\n",
      "(3504, 10, 10)\n",
      "(390, 10, 10)\n",
      "(3504, 10, 10)\n",
      "(390, 10, 10)\n",
      "(3504, 10, 10)\n",
      "(390, 10, 10)\n",
      "Classification accuracy: 0.578462 / Chance level: 0.501027\n"
     ]
    }
   ],
   "source": [
    "#Below is a function that takes the upper half of a matrix and put them in an array\n",
    "def takeupper(m):\n",
    "    print(m.shape)\n",
    "    ret = []\n",
    "    for k in range(m.shape[0]):\n",
    "        row = []\n",
    "        for i in range(m.shape[1]):\n",
    "            for j in range(i):\n",
    "                row.append(m[k][i][j])\n",
    "        ret.append(row)\n",
    "    return np.array(ret)\n",
    "\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10)\n",
    "scores = []\n",
    "epochs_data = epochs_train_total\n",
    "clf = sklearn.discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "labels = labels_total\n",
    "\n",
    "for train_idx, test_idx in cv.split(labels):\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "    X_train = epochs_data[train_idx][:,index]\n",
    "    X_test = epochs_data[test_idx][:,index]\n",
    "\n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    \n",
    "    #take the covariance matrix of input signal, then only take the upper half to avoid dupplicate\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    X_tr = takeupper(cov_X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    X_ts = takeupper(cov_X_test)\n",
    "    \n",
    "\n",
    "    clf.fit(X_tr, y_train)\n",
    "    y_predict = clf.predict(X_ts)\n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "    \n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the part below a CNN will be built to detect patterns in the covariance matrix of the EEG signal. \n",
    "\n",
    "Since only 10 channels are relevant to motor imagery, the input data size is 3115 X 10 X 10 (sample, num_channel, num_channel)\n",
    "\n",
    "The first two layers are convolutional layers. The kernel size is set to be 3X3, 8 filters at each layer.\n",
    "Since each element in the covariance matrix could provide useful information, and the size is only 10 X 10, no max looking layer is added.\n",
    "\n",
    "The batch size is set to be 128, and epoch set to be 4. Tuning batch size does not seem to affect the result.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3894, 64, 161)\n",
      "the shape of cov matrix is (3115, 10, 10)\n",
      "Train on 3115 samples, validate on 779 samples\n",
      "Epoch 1/4\n",
      "3115/3115 [==============================] - 3s - loss: 0.6932 - acc: 0.5050 - val_loss: 0.6931 - val_acc: 0.5122\n",
      "Epoch 2/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4915 - val_loss: 0.6932 - val_acc: 0.4878\n",
      "Epoch 3/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.5040 - val_loss: 0.6932 - val_acc: 0.4878\n",
      "Epoch 4/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4992 - val_loss: 0.6932 - val_acc: 0.4878\n",
      "Test loss: 0.693227203116\n",
      "Test accuracy: 0.487804878202\n",
      "the shape of cov matrix is (3115, 10, 10)\n",
      "Train on 3115 samples, validate on 779 samples\n",
      "Epoch 1/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6932 - val_acc: 0.4981\n",
      "Epoch 2/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.5043 - val_loss: 0.6931 - val_acc: 0.5019\n",
      "Epoch 3/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4934 - val_loss: 0.6931 - val_acc: 0.4981\n",
      "Epoch 4/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4963 - val_loss: 0.6932 - val_acc: 0.4981\n",
      "Test loss: 0.693153212787\n",
      "Test accuracy: 0.49807445462\n",
      "the shape of cov matrix is (3115, 10, 10)\n",
      "Train on 3115 samples, validate on 779 samples\n",
      "Epoch 1/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4941 - val_loss: 0.6932 - val_acc: 0.4955\n",
      "Epoch 2/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.5021 - val_loss: 0.6932 - val_acc: 0.4955\n",
      "Epoch 3/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4941 - val_loss: 0.6932 - val_acc: 0.4955\n",
      "Epoch 4/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.5034 - val_loss: 0.6932 - val_acc: 0.4955\n",
      "Test loss: 0.693176926177\n",
      "Test accuracy: 0.495507060563\n",
      "the shape of cov matrix is (3115, 10, 10)\n",
      "Train on 3115 samples, validate on 779 samples\n",
      "Epoch 1/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4915 - val_loss: 0.6932 - val_acc: 0.4840\n",
      "Epoch 2/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6931 - acc: 0.5018 - val_loss: 0.6932 - val_acc: 0.4840\n",
      "Epoch 3/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6931 - acc: 0.5053 - val_loss: 0.6933 - val_acc: 0.4840\n",
      "Epoch 4/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6931 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.4840\n",
      "Test loss: 0.693369697622\n",
      "Test accuracy: 0.483953787059\n",
      "the shape of cov matrix is (3115, 10, 10)\n",
      "Train on 3115 samples, validate on 779 samples\n",
      "Epoch 1/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4918 - val_loss: 0.6932 - val_acc: 0.4865\n",
      "Epoch 2/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4963 - val_loss: 0.6932 - val_acc: 0.4865\n",
      "Epoch 3/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6931 - acc: 0.5047 - val_loss: 0.6933 - val_acc: 0.4865\n",
      "Epoch 4/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6931 - acc: 0.5047 - val_loss: 0.6934 - val_acc: 0.4865\n",
      "Test loss: 0.693359139642\n",
      "Test accuracy: 0.486521181307\n",
      "the shape of cov matrix is (3115, 10, 10)\n",
      "Train on 3115 samples, validate on 779 samples\n",
      "Epoch 1/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4960 - val_loss: 0.6931 - val_acc: 0.4955\n",
      "Epoch 2/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4960 - val_loss: 0.6932 - val_acc: 0.4955\n",
      "Epoch 3/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4989 - val_loss: 0.6931 - val_acc: 0.5045\n",
      "Epoch 4/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4982 - val_loss: 0.6931 - val_acc: 0.5045\n",
      "Test loss: 0.69314498834\n",
      "Test accuracy: 0.504492939858\n",
      "the shape of cov matrix is (3115, 10, 10)\n",
      "Train on 3115 samples, validate on 779 samples\n",
      "Epoch 1/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4912 - val_loss: 0.6932 - val_acc: 0.4737\n",
      "Epoch 2/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.5053 - val_loss: 0.6933 - val_acc: 0.4737\n",
      "Epoch 3/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6931 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.4737\n",
      "Epoch 4/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6931 - acc: 0.5053 - val_loss: 0.6934 - val_acc: 0.4737\n",
      "Test loss: 0.69337557897\n",
      "Test accuracy: 0.473684210603\n",
      "the shape of cov matrix is (3115, 10, 10)\n",
      "Train on 3115 samples, validate on 779 samples\n",
      "Epoch 1/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4860 - val_loss: 0.6931 - val_acc: 0.5019\n",
      "Epoch 2/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4998 - val_loss: 0.6932 - val_acc: 0.4981\n",
      "Epoch 3/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4841 - val_loss: 0.6931 - val_acc: 0.5019\n",
      "Epoch 4/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4880 - val_loss: 0.6931 - val_acc: 0.5019\n",
      "Test loss: 0.693142106582\n",
      "Test accuracy: 0.501925545801\n",
      "the shape of cov matrix is (3115, 10, 10)\n",
      "Train on 3115 samples, validate on 779 samples\n",
      "Epoch 1/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4880 - val_loss: 0.6931 - val_acc: 0.5006\n",
      "Epoch 2/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4950 - val_loss: 0.6931 - val_acc: 0.5006\n",
      "Epoch 3/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4989 - val_loss: 0.6931 - val_acc: 0.5006\n",
      "Epoch 4/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4902 - val_loss: 0.6931 - val_acc: 0.5006\n",
      "Test loss: 0.69314642834\n",
      "Test accuracy: 0.500641848677\n",
      "the shape of cov matrix is (3115, 10, 10)\n",
      "Train on 3115 samples, validate on 779 samples\n",
      "Epoch 1/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.5008 - val_loss: 0.6932 - val_acc: 0.4865\n",
      "Epoch 2/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6932 - acc: 0.4979 - val_loss: 0.6932 - val_acc: 0.4865\n",
      "Epoch 3/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6931 - acc: 0.5047 - val_loss: 0.6933 - val_acc: 0.4865\n",
      "Epoch 4/4\n",
      "3115/3115 [==============================] - 0s - loss: 0.6931 - acc: 0.5047 - val_loss: 0.6933 - val_acc: 0.4865\n",
      "Test loss: 0.693303425214\n",
      "Test accuracy: 0.486521181154\n",
      "Classification accuracy: 0.592576 / Chance level: 0.501027\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import pyriemann.estimation\n",
    "\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "\n",
    "index = np.concatenate((left_hand, right_hand))\n",
    "\n",
    "epochs_data = epochs_train_total\n",
    "labels = labels_total\n",
    "\n",
    "print(epochs_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "for train_idx, test_idx in cv.split(labels):\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "    X_train = epochs_data[train_idx][:,index]\n",
    "    X_test = epochs_data[test_idx][:,index]\n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    \n",
    "    print(\"the shape of cov matrix is {}\".format(cov_X_train.shape))\n",
    "\n",
    "    num_train = cov_X_train.shape[0]\n",
    "    num_test = cov_X_test.shape[0]\n",
    "    \n",
    "    cov_X_train = cov_X_train.reshape(num_train, 1, 10, 10)\n",
    "    cov_X_test = cov_X_test.reshape(num_test, 1, 10, 10)\n",
    "\n",
    "    x_train = cov_X_train\n",
    "    x_test = cov_X_test\n",
    "\n",
    "\n",
    "\n",
    "    num_classes = 2\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=(1,10, 10), data_format='channels_first'))\n",
    "    model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=128,\n",
    "              epochs=4,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    scores.append(score)\n",
    "\n",
    "# Printing the results\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
