{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and concatenante data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1669, 32, 1033)\n",
      "(1669,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "\n",
    "# sparse_files = ['sparse_ANM210861_20130701.npy', 'sparse_ANM210861_20130702.npy', \n",
    "#                'sparse_ANM210861_20130703.npy']\n",
    "\n",
    "# label_files = ['ANM210861_20130701_labels.npy', 'ANM210861_20130702_labels.npy',\n",
    "#               'ANM210861_20130703_labels.npy']\n",
    "\n",
    "sparse_files = ['sparse_ANM210861_20130701.npy', 'sparse_ANM210861_20130702.npy', \n",
    "               'sparse_ANM210861_20130703.npy', 'sparse_ANM210862_20130626.npy', 'sparse_ANM210862_20130627.npy', \n",
    "               'sparse_ANM210862_20130628.npy']\n",
    "\n",
    "label_files = ['ANM210861_20130701_labels.npy', 'ANM210861_20130702_labels.npy',\n",
    "              'ANM210861_20130703_labels.npy', 'ANM210862_20130626_labels.npy', 'ANM210862_20130627_labels.npy',\n",
    "              'ANM210862_20130628_labels.npy']\n",
    "\n",
    "\n",
    "agg_spares_epochs = np.load(sparse_files[0])\n",
    "agg_labels = np.load(label_files[0])\n",
    "ind = np.linspace(0,3443-1, num = 1033)\n",
    "ind = [int(np.floor(i)) for i in ind]\n",
    "agg_spares_epochs = agg_spares_epochs[:,:, ind]\n",
    "\n",
    "\n",
    "for i in range(1,6):\n",
    "    new_epochs =  np.load(sparse_files[i])\n",
    "    agg_spares_epochs = np.concatenate((agg_spares_epochs, new_epochs), axis = 0)\n",
    "    new_label = np.load(label_files[i])\n",
    "    agg_labels = np.concatenate((agg_labels, new_label), axis = 0)\n",
    "\n",
    "print(agg_spares_epochs.shape)\n",
    "print(agg_labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "agg_epochs_std = copy.copy(agg_spares_epochs)\n",
    "sample_num, chan_num, timepoint = agg_spares_epochs.shape\n",
    "for c in range(chan_num):\n",
    "    original_timepoints = agg_spares_epochs[:,c,:]\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(original_timepoints)\n",
    "    chan_std = scaler.transform(original_timepoints)\n",
    "    agg_epochs_std[:,c,:] = chan_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Down sampling with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1335, 32, 1032)\n",
      "0.7275449101796407\n",
      "(1335, 32, 1032)\n",
      "0.7874251497005988\n",
      "(1335, 32, 1032)\n",
      "0.7275449101796407\n",
      "(1335, 32, 1032)\n",
      "0.7305389221556886\n",
      "(1335, 32, 1032)\n",
      "0.8083832335329342\n",
      "(1335, 32, 1032)\n",
      "0.7844311377245509\n",
      "(1335, 32, 1032)\n",
      "0.8023952095808383\n",
      "(1335, 32, 1032)\n",
      "0.7904191616766467\n",
      "(1335, 32, 1032)\n",
      "0.7964071856287425\n",
      "(1335, 32, 1032)\n",
      "0.7694610778443114\n",
      "Classification accuracy: 0.772455 / Chance level: 0.500899\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import pyriemann.estimation\n",
    "import pyriemann.classification\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import ShuffleSplit  \n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pyriemann.tangentspace import FGDA, TangentSpace\n",
    "\n",
    "ind = np.linspace(0,1032, num = 1032)\n",
    "ind = [int(np.floor(i)) for i in ind]\n",
    "epochs_ds = agg_epochs_std[:,:,ind]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "epochs_data = epochs_ds\n",
    "labels = agg_labels\n",
    "\n",
    "for train_idx, test_idx in cv.split(epochs_data):\n",
    "    y_train, y_test = np.asarray(labels)[train_idx], np.asarray(labels)[test_idx]\n",
    "    X_train = epochs_data[train_idx]\n",
    "    X_test = epochs_data[test_idx]\n",
    "    print(X_train.shape)\n",
    "\n",
    "    \n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    \n",
    "    ts = TangentSpace()\n",
    "    T = ts.fit_transform(cov_X_train, y_train)\n",
    "    \n",
    "#     clf = sklearn.linear_model.LogisticRegression()\n",
    "    clf=SVC(kernel='poly', degree = 2.7,  random_state=0, coef0 =0.2, gamma= 0.03, C=100)\n",
    "    clf.fit(T, y_train)\n",
    "\n",
    "    \n",
    "    \n",
    "    T_test = ts.fit_transform(cov_X_test, y_test)\n",
    "    \n",
    "    y_predict = clf.predict(T_test)\n",
    "    print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "class_balance = np.mean(np.asarray(labels) == np.asarray(labels)[0])\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1335, 32, 900)\n",
      "(1335, 528)\n",
      "(1335, 200)\n",
      "(334, 528)\n",
      "0.47904191616766467\n",
      "(1335, 32, 900)\n",
      "(1335, 528)\n",
      "(1335, 200)\n",
      "(334, 528)\n",
      "0.48502994011976047\n",
      "(1335, 32, 900)\n",
      "(1335, 528)\n",
      "(1335, 200)\n",
      "(334, 528)\n",
      "0.5419161676646707\n",
      "(1335, 32, 900)\n",
      "(1335, 528)\n",
      "(1335, 200)\n",
      "(334, 528)\n",
      "0.45209580838323354\n",
      "(1335, 32, 900)\n",
      "(1335, 528)\n",
      "(1335, 200)\n",
      "(334, 528)\n",
      "0.4940119760479042\n",
      "(1335, 32, 900)\n",
      "(1335, 528)\n",
      "(1335, 200)\n",
      "(334, 528)\n",
      "0.45808383233532934\n",
      "(1335, 32, 900)\n",
      "(1335, 528)\n",
      "(1335, 200)\n",
      "(334, 528)\n",
      "0.5359281437125748\n",
      "(1335, 32, 900)\n",
      "(1335, 528)\n",
      "(1335, 200)\n",
      "(334, 528)\n",
      "0.5\n",
      "(1335, 32, 900)\n",
      "(1335, 528)\n",
      "(1335, 200)\n",
      "(334, 528)\n",
      "0.48502994011976047\n",
      "(1335, 32, 900)\n",
      "(1335, 528)\n",
      "(1335, 200)\n",
      "(334, 528)\n",
      "0.5838323353293413\n",
      "Classification accuracy: 0.501497 / Chance level: 0.500899\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import pyriemann.estimation\n",
    "import pyriemann.classification\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import ShuffleSplit  \n",
    "from scipy.fftpack import fft, ifft\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pyriemann.tangentspace import FGDA, TangentSpace\n",
    "\n",
    "ind = np.linspace(0,1032, num = 900)\n",
    "ind = [int(np.floor(i)) for i in ind]\n",
    "epochs_ds = agg_epochs_std[:,:,ind]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "epochs_data = epochs_ds\n",
    "labels = agg_labels\n",
    "\n",
    "for train_idx, test_idx in cv.split(epochs_data):\n",
    "    y_train, y_test = np.asarray(labels)[train_idx], np.asarray(labels)[test_idx]\n",
    "    X_train = epochs_data[train_idx]\n",
    "    X_test = epochs_data[test_idx]\n",
    "    print(X_train.shape)\n",
    "\n",
    "    \n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    \n",
    "    ts = TangentSpace()\n",
    "    T = ts.fit_transform(cov_X_train, y_train)\n",
    "    print(T.shape)\n",
    "    \n",
    "    pca = PCA(n_components=200)\n",
    "    T_pca = pca.fit_transform(T)\n",
    "    print(T_pca.shape)\n",
    "\n",
    "    \n",
    "    clf = sklearn.linear_model.LogisticRegression()\n",
    "    clf.fit(T_pca, y_train)\n",
    "\n",
    "    \n",
    "    \n",
    "    T_test = ts.fit_transform(cov_X_test, y_test)\n",
    "    print(T_test.shape)\n",
    "\n",
    "    pca = PCA(n_components=200)\n",
    "    T_test_pca = pca.fit_transform(T_test)\n",
    "    \n",
    "    \n",
    "    y_predict = clf.predict(T_test_pca)\n",
    "    print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "class_balance = np.mean(np.asarray(labels) == np.asarray(labels)[0])\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tangent Space classifier with single SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.7275449101796407\n",
      "Time:  5.098197242251834\n",
      "0.7874251497005988\n",
      "Time:  4.792557641685666\n",
      "0.7634730538922155\n",
      "Time:  5.504539821876108\n",
      "0.7724550898203593\n",
      "Time:  5.686747652871741\n",
      "0.7874251497005988\n",
      "Time:  6.390531811680638\n",
      "0.7634730538922155\n",
      "Time:  4.884890077783112\n",
      "0.7994011976047904\n",
      "Time:  5.1043903959277515\n",
      "0.781437125748503\n",
      "Time:  4.641040101064256\n",
      "0.8083832335329342\n",
      "Time:  5.15174525055513\n",
      "0.7724550898203593\n",
      "Time:  5.056253165214457\n",
      "Classification accuracy: 0.776347 / Chance level: 0.500899\n",
      "0.01\n",
      "0.718562874251497\n",
      "Time:  4.195653383741792\n",
      "0.8023952095808383\n",
      "Time:  4.291192773386413\n",
      "0.7634730538922155\n",
      "Time:  4.278804147196148\n",
      "0.7664670658682635\n",
      "Time:  4.332877604287432\n",
      "0.7964071856287425\n",
      "Time:  5.404239856936954\n",
      "0.7664670658682635\n",
      "Time:  4.472165591034809\n",
      "0.7994011976047904\n",
      "Time:  4.633008572281895\n",
      "0.7964071856287425\n",
      "Time:  4.446504861212887\n",
      "0.8023952095808383\n",
      "Time:  4.526077193203761\n",
      "0.7724550898203593\n",
      "Time:  4.547804245514897\n",
      "Classification accuracy: 0.777395 / Chance level: 0.500899\n",
      "0.02\n",
      "0.7215568862275449\n",
      "Time:  4.289292253410082\n",
      "0.7964071856287425\n",
      "Time:  4.815857330219288\n",
      "0.7634730538922155\n",
      "Time:  4.509992802325513\n",
      "0.7724550898203593\n",
      "Time:  4.399585020674763\n",
      "0.8053892215568862\n",
      "Time:  4.871683829162819\n",
      "0.7634730538922155\n",
      "Time:  4.674961924672999\n",
      "0.7964071856287425\n",
      "Time:  4.78118791310105\n",
      "0.7934131736526946\n",
      "Time:  4.489736357346004\n",
      "0.8083832335329342\n",
      "Time:  4.773566354952948\n",
      "0.7724550898203593\n",
      "Time:  5.09492489746097\n",
      "Classification accuracy: 0.778044 / Chance level: 0.500899\n",
      "0.03\n",
      "0.7335329341317365\n",
      "Time:  5.0774867687078995\n",
      "0.7874251497005988\n",
      "Time:  5.007472688720981\n",
      "0.7604790419161677\n",
      "Time:  4.737605344829831\n",
      "0.7754491017964071\n",
      "Time:  4.706582069257223\n",
      "0.811377245508982\n",
      "Time:  4.71529533653765\n",
      "0.7754491017964071\n",
      "Time:  4.347215446061028\n",
      "0.7934131736526946\n",
      "Time:  4.334499399884606\n",
      "0.7934131736526946\n",
      "Time:  4.550862793402615\n",
      "0.8143712574850299\n",
      "Time:  4.583836675861619\n",
      "0.7724550898203593\n",
      "Time:  5.038033587910888\n",
      "Classification accuracy: 0.778967 / Chance level: 0.500899\n",
      "0.04\n",
      "0.7335329341317365\n",
      "Time:  4.909987793634514\n",
      "0.7874251497005988\n",
      "Time:  5.196625904578866\n",
      "0.7634730538922155\n",
      "Time:  4.3727031905361855\n",
      "0.7754491017964071\n",
      "Time:  4.5056936758783195\n",
      "0.8143712574850299\n",
      "Time:  4.60959572443295\n",
      "0.7784431137724551\n",
      "Time:  4.341410929705802\n",
      "0.7934131736526946\n",
      "Time:  4.369572758657142\n",
      "0.7934131736526946\n",
      "Time:  4.391096216954253\n",
      "0.811377245508982\n",
      "Time:  4.970602693933728\n",
      "0.7784431137724551\n",
      "Time:  4.853757816804347\n",
      "Classification accuracy: 0.779760 / Chance level: 0.500899\n",
      "0.05\n",
      "0.7335329341317365\n",
      "Time:  4.574175467431445\n",
      "0.7844311377245509\n",
      "Time:  4.681702324218151\n",
      "0.7604790419161677\n",
      "Time:  4.532426636589776\n",
      "0.7754491017964071\n",
      "Time:  4.368469919100363\n",
      "0.8173652694610778\n",
      "Time:  4.364450444567694\n",
      "0.781437125748503\n",
      "Time:  4.317589038757944\n",
      "0.7964071856287425\n",
      "Time:  4.628415880889577\n",
      "0.7934131736526946\n",
      "Time:  4.304512181322082\n",
      "0.8143712574850299\n",
      "Time:  4.383570658717076\n",
      "0.781437125748503\n",
      "Time:  4.646654008900612\n",
      "Classification accuracy: 0.780439 / Chance level: 0.500899\n",
      "0.06\n",
      "0.7335329341317365\n",
      "Time:  4.121864698560273\n",
      "0.781437125748503\n",
      "Time:  4.286292604018456\n",
      "0.7664670658682635\n",
      "Time:  4.1747982146799245\n",
      "0.7784431137724551\n",
      "Time:  4.232058219540193\n",
      "0.8173652694610778\n",
      "Time:  4.492310731769749\n",
      "0.781437125748503\n",
      "Time:  4.222502750142326\n",
      "0.7964071856287425\n",
      "Time:  4.291760425033772\n",
      "0.7934131736526946\n",
      "Time:  4.327740449632017\n",
      "0.811377245508982\n",
      "Time:  4.529495624815638\n",
      "0.7874251497005988\n",
      "Time:  4.429344065535929\n",
      "Classification accuracy: 0.781052 / Chance level: 0.500899\n",
      "0.07\n",
      "0.7305389221556886\n",
      "Time:  4.546839144960813\n",
      "0.781437125748503\n",
      "Time:  4.269215750292631\n",
      "0.7664670658682635\n",
      "Time:  4.333484676188107\n",
      "0.781437125748503\n",
      "Time:  4.164412137356862\n",
      "0.8173652694610778\n",
      "Time:  4.295612479431895\n",
      "0.7784431137724551\n",
      "Time:  4.398033717765827\n",
      "0.8023952095808383\n",
      "Time:  4.236638852972646\n",
      "0.7904191616766467\n",
      "Time:  4.672838796207486\n",
      "0.8083832335329342\n",
      "Time:  5.0450888857146765\n",
      "0.7904191616766467\n",
      "Time:  4.622954088854158\n",
      "Classification accuracy: 0.781512 / Chance level: 0.500899\n",
      "0.08\n",
      "0.7305389221556886\n",
      "Time:  4.551112764185234\n",
      "0.781437125748503\n",
      "Time:  4.645470009998803\n",
      "0.7664670658682635\n",
      "Time:  4.639503174953575\n",
      "0.7844311377245509\n",
      "Time:  4.871359191782744\n",
      "0.8173652694610778\n",
      "Time:  4.912578863694989\n",
      "0.7784431137724551\n",
      "Time:  4.50885703526302\n",
      "0.7964071856287425\n",
      "Time:  4.693415704657923\n",
      "0.7934131736526946\n",
      "Time:  4.681565512750865\n",
      "0.8053892215568862\n",
      "Time:  4.632390833724401\n",
      "0.7934131736526946\n",
      "Time:  4.483682797743484\n",
      "Classification accuracy: 0.781870 / Chance level: 0.500899\n",
      "0.09\n",
      "0.7305389221556886\n",
      "Time:  4.18839449192393\n",
      "0.7844311377245509\n",
      "Time:  4.526909192432072\n",
      "0.7694610778443114\n",
      "Time:  4.324667524946051\n",
      "0.7844311377245509\n",
      "Time:  4.233168943147632\n",
      "0.8173652694610778\n",
      "Time:  4.32913824543698\n",
      "0.7754491017964071\n",
      "Time:  4.251645447749127\n",
      "0.7994011976047904\n",
      "Time:  4.771961254992448\n",
      "0.7874251497005988\n",
      "Time:  4.713135570424981\n",
      "0.8053892215568862\n",
      "Time:  4.2230708655574745\n",
      "0.7934131736526946\n",
      "Time:  4.312484811608272\n",
      "Classification accuracy: 0.782156 / Chance level: 0.500899\n",
      "0.1\n",
      "0.7335329341317365\n",
      "Time:  4.207435401799046\n",
      "0.781437125748503\n",
      "Time:  4.384818657559492\n",
      "0.7694610778443114\n",
      "Time:  4.350650109541903\n",
      "0.7904191616766467\n",
      "Time:  4.182741163834294\n",
      "0.8173652694610778\n",
      "Time:  4.253481504017202\n",
      "0.7754491017964071\n",
      "Time:  4.141439868809414\n",
      "0.7964071856287425\n",
      "Time:  4.217022407399497\n",
      "0.7844311377245509\n",
      "Time:  4.238660880082648\n",
      "0.8083832335329342\n",
      "Time:  4.227952484218008\n",
      "0.7904191616766467\n",
      "Time:  4.273154065480298\n",
      "Classification accuracy: 0.782390 / Chance level: 0.500899\n",
      "0.11\n",
      "0.7365269461077845\n",
      "Time:  4.1901799975141785\n",
      "0.781437125748503\n",
      "Time:  4.269797314970617\n",
      "0.7664670658682635\n",
      "Time:  4.228137991292272\n",
      "0.7934131736526946\n",
      "Time:  4.194355297989318\n",
      "0.8173652694610778\n",
      "Time:  4.436997159886687\n",
      "0.7724550898203593\n",
      "Time:  4.346068084806461\n",
      "0.8023952095808383\n",
      "Time:  4.355225641529842\n",
      "0.7844311377245509\n",
      "Time:  4.680846672837902\n",
      "0.8083832335329342\n",
      "Time:  4.181250150724395\n",
      "0.7904191616766467\n",
      "Time:  4.350888022364643\n",
      "Classification accuracy: 0.782635 / Chance level: 0.500899\n",
      "0.12\n",
      "0.7395209580838323\n",
      "Time:  4.303734442913083\n",
      "0.781437125748503\n",
      "Time:  4.344211158992493\n",
      "0.7604790419161677\n",
      "Time:  4.789052949284269\n",
      "0.7934131736526946\n",
      "Time:  4.464445714137241\n",
      "0.8203592814371258\n",
      "Time:  4.538418051322424\n",
      "0.7724550898203593\n",
      "Time:  4.303336530238539\n",
      "0.8023952095808383\n",
      "Time:  4.414038340602133\n",
      "0.7874251497005988\n",
      "Time:  4.513975639211026\n",
      "0.8053892215568862\n",
      "Time:  4.414198340453709\n",
      "0.7904191616766467\n",
      "Time:  4.336885484628056\n",
      "Classification accuracy: 0.782842 / Chance level: 0.500899\n",
      "0.13\n",
      "0.7395209580838323\n",
      "Time:  4.146061313798214\n",
      "0.781437125748503\n",
      "Time:  4.555661861415047\n",
      "0.7604790419161677\n",
      "Time:  4.4730537061531095\n",
      "0.7964071856287425\n",
      "Time:  4.3683581510881595\n",
      "0.8203592814371258\n",
      "Time:  5.370032816201501\n",
      "0.7694610778443114\n",
      "Time:  5.219705303461751\n",
      "0.7994011976047904\n",
      "Time:  5.214337192498874\n",
      "0.7874251497005988\n",
      "Time:  4.8318137212162355\n",
      "0.8083832335329342\n",
      "Time:  4.835884673962028\n",
      "0.7904191616766467\n",
      "Time:  4.282257361384495\n",
      "Classification accuracy: 0.783020 / Chance level: 0.500899\n",
      "0.14\n",
      "0.7395209580838323\n",
      "Time:  4.192951936972122\n",
      "0.781437125748503\n",
      "Time:  4.274662701762168\n",
      "0.7574850299401198\n",
      "Time:  4.171268942591155\n",
      "0.7994011976047904\n",
      "Time:  4.179208645371659\n",
      "0.8143712574850299\n",
      "Time:  4.25958793313589\n",
      "0.7664670658682635\n",
      "Time:  4.13764856797809\n",
      "0.7994011976047904\n",
      "Time:  4.243466904610386\n",
      "0.7874251497005988\n",
      "Time:  4.556118672585512\n",
      "0.8023952095808383\n",
      "Time:  4.723235503085903\n",
      "0.7934131736526946\n",
      "Time:  5.118183774438194\n",
      "Classification accuracy: 0.783094 / Chance level: 0.500899\n",
      "0.15\n",
      "0.7395209580838323\n",
      "Time:  4.405663159964547\n",
      "0.781437125748503\n",
      "Time:  4.35735433520756\n",
      "0.7544910179640718\n",
      "Time:  4.43437455362357\n",
      "0.8023952095808383\n",
      "Time:  4.337004209155566\n",
      "0.811377245508982\n",
      "Time:  4.277455974533609\n",
      "0.7694610778443114\n",
      "Time:  4.384463411512229\n",
      "0.8023952095808383\n",
      "Time:  4.970009071295976\n",
      "0.7904191616766467\n",
      "Time:  4.472154460610341\n",
      "0.8053892215568862\n",
      "Time:  4.163458167227191\n",
      "0.7934131736526946\n",
      "Time:  5.224531269999943\n",
      "Classification accuracy: 0.783215 / Chance level: 0.500899\n",
      "0.16\n",
      "0.7425149700598802\n",
      "Time:  5.1650080788330115\n",
      "0.781437125748503\n",
      "Time:  4.721320142543618\n",
      "0.7514970059880239\n",
      "Time:  4.2070170833465\n",
      "0.8023952095808383\n",
      "Time:  4.734358507261732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8173652694610778\n",
      "Time:  4.278679857456382\n",
      "0.7664670658682635\n",
      "Time:  4.313213390642659\n",
      "0.8023952095808383\n",
      "Time:  4.298022216327126\n",
      "0.7874251497005988\n",
      "Time:  4.360206042707432\n",
      "0.8053892215568862\n",
      "Time:  4.635812047942522\n",
      "0.7934131736526946\n",
      "Time:  4.287611095549096\n",
      "Classification accuracy: 0.783322 / Chance level: 0.500899\n",
      "0.17\n",
      "0.7395209580838323\n",
      "Time:  4.180933397395165\n",
      "0.781437125748503\n",
      "Time:  4.294400654468973\n",
      "0.7574850299401198\n",
      "Time:  4.205248737160673\n",
      "0.8023952095808383\n",
      "Time:  4.17229340540905\n",
      "0.8143712574850299\n",
      "Time:  4.336489427024276\n",
      "0.7664670658682635\n",
      "Time:  4.180388470364392\n",
      "0.8023952095808383\n",
      "Time:  4.396149893426241\n",
      "0.7874251497005988\n",
      "Time:  4.866267022592865\n",
      "0.8083832335329342\n",
      "Time:  4.3611038969471565\n",
      "0.7934131736526946\n",
      "Time:  4.6095836664731\n",
      "Classification accuracy: 0.783433 / Chance level: 0.500899\n",
      "0.18\n",
      "0.7395209580838323\n",
      "Time:  4.369496700756713\n",
      "0.781437125748503\n",
      "Time:  4.566905908956755\n",
      "0.7574850299401198\n",
      "Time:  4.310150205078003\n",
      "0.8023952095808383\n",
      "Time:  4.415046107783269\n",
      "0.8143712574850299\n",
      "Time:  4.522907341071459\n",
      "0.7694610778443114\n",
      "Time:  5.097593880492582\n",
      "0.8023952095808383\n",
      "Time:  4.609804883659308\n",
      "0.7934131736526946\n",
      "Time:  5.145297488419715\n",
      "0.8083832335329342\n",
      "Time:  4.61070969441414\n",
      "0.7934131736526946\n",
      "Time:  4.331668098162936\n",
      "Classification accuracy: 0.783580 / Chance level: 0.500899\n",
      "0.19\n",
      "0.7425149700598802\n",
      "Time:  4.247253103997082\n",
      "0.781437125748503\n",
      "Time:  4.308388351639792\n",
      "0.7514970059880239\n",
      "Time:  4.448458714473077\n",
      "0.8023952095808383\n",
      "Time:  4.391804853978101\n",
      "0.8143712574850299\n",
      "Time:  4.132111645577652\n",
      "0.7694610778443114\n",
      "Time:  4.1859759434426\n",
      "0.8053892215568862\n",
      "Time:  4.205686997623729\n",
      "0.7934131736526946\n",
      "Time:  4.800720416723038\n",
      "0.8083832335329342\n",
      "Time:  4.763313378955672\n",
      "0.7934131736526946\n",
      "Time:  4.87934480756428\n",
      "Classification accuracy: 0.783713 / Chance level: 0.500899\n",
      "0.2\n",
      "0.7425149700598802\n",
      "Time:  4.3978254860749075\n",
      "0.7844311377245509\n",
      "Time:  4.260912917414089\n",
      "0.7514970059880239\n",
      "Time:  4.399204267404684\n",
      "0.8023952095808383\n",
      "Time:  4.238488822271165\n",
      "0.811377245508982\n",
      "Time:  4.217963855801713\n",
      "0.7694610778443114\n",
      "Time:  4.220914809586247\n",
      "0.8053892215568862\n",
      "Time:  4.176414908832498\n",
      "0.7934131736526946\n",
      "Time:  4.290776310004617\n",
      "0.8083832335329342\n",
      "Time:  4.236058679597704\n",
      "0.7934131736526946\n",
      "Time:  4.197825207814276\n",
      "Classification accuracy: 0.783832 / Chance level: 0.500899\n",
      "0.21\n",
      "0.7425149700598802\n",
      "Time:  4.146629892980968\n",
      "0.7874251497005988\n",
      "Time:  4.26662189762601\n",
      "0.7544910179640718\n",
      "Time:  4.227230861698899\n",
      "0.7994011976047904\n",
      "Time:  4.17880841385886\n",
      "0.811377245508982\n",
      "Time:  4.253374837449428\n",
      "0.7694610778443114\n",
      "Time:  4.2128786431270555\n",
      "0.8083832335329342\n",
      "Time:  4.206658590925372\n",
      "0.7934131736526946\n",
      "Time:  4.278104785526011\n",
      "0.8053892215568862\n",
      "Time:  4.3001388520451655\n",
      "0.7934131736526946\n",
      "Time:  4.241963833540808\n",
      "Classification accuracy: 0.783955 / Chance level: 0.500899\n",
      "0.22\n",
      "0.7395209580838323\n",
      "Time:  4.269487981924158\n",
      "0.7874251497005988\n",
      "Time:  4.191172924129432\n",
      "0.7544910179640718\n",
      "Time:  4.316149503861311\n",
      "0.7994011976047904\n",
      "Time:  4.193744515947174\n",
      "0.811377245508982\n",
      "Time:  4.397148385253672\n",
      "0.7694610778443114\n",
      "Time:  4.178656298057945\n",
      "0.8083832335329342\n",
      "Time:  4.248672696883318\n",
      "0.7934131736526946\n",
      "Time:  4.243912121588892\n",
      "0.8053892215568862\n",
      "Time:  4.2487084069950924\n",
      "0.7934131736526946\n",
      "Time:  4.268374011942797\n",
      "Classification accuracy: 0.784054 / Chance level: 0.500899\n",
      "0.23\n",
      "0.7395209580838323\n",
      "Time:  4.199033322635842\n",
      "0.7874251497005988\n",
      "Time:  4.251868520005928\n",
      "0.7544910179640718\n",
      "Time:  4.233150392440393\n",
      "0.7964071856287425\n",
      "Time:  4.204575346480851\n",
      "0.811377245508982\n",
      "Time:  4.224148197891509\n",
      "0.7694610778443114\n",
      "Time:  4.352992136355169\n",
      "0.8053892215568862\n",
      "Time:  4.17924667432203\n",
      "0.7934131736526946\n",
      "Time:  4.231037003096162\n",
      "0.8053892215568862\n",
      "Time:  4.249795014683059\n",
      "0.7904191616766467\n",
      "Time:  4.3275002179709645\n",
      "Classification accuracy: 0.784107 / Chance level: 0.500899\n",
      "0.24\n",
      "0.7395209580838323\n",
      "Time:  4.130070603992635\n",
      "0.7874251497005988\n",
      "Time:  4.239535082170505\n",
      "0.7514970059880239\n",
      "Time:  4.430136180743148\n",
      "0.7964071856287425\n",
      "Time:  4.263200219640339\n",
      "0.811377245508982\n",
      "Time:  4.368939715766146\n",
      "0.7694610778443114\n",
      "Time:  4.771933892698826\n",
      "0.8053892215568862\n",
      "Time:  4.539377122896667\n",
      "0.7934131736526946\n",
      "Time:  4.391221434229237\n",
      "0.8083832335329342\n",
      "Time:  4.2574059061744265\n",
      "0.7904191616766467\n",
      "Time:  5.0349138226886225\n",
      "Classification accuracy: 0.784156 / Chance level: 0.500899\n",
      "0.25\n",
      "0.7395209580838323\n",
      "Time:  4.814750780521081\n",
      "0.7874251497005988\n",
      "Time:  5.078677260357381\n",
      "0.7514970059880239\n",
      "Time:  4.986334621370588\n",
      "0.7964071856287425\n",
      "Time:  4.860484303318799\n",
      "0.811377245508982\n",
      "Time:  5.250094608607924\n",
      "0.7634730538922155\n",
      "Time:  5.322287932950303\n",
      "0.8083832335329342\n",
      "Time:  4.809218495797268\n",
      "0.7934131736526946\n",
      "Time:  5.844001999766306\n",
      "0.8083832335329342\n",
      "Time:  5.961510064686308\n",
      "0.7904191616766467\n",
      "Time:  4.809011655409449\n",
      "Classification accuracy: 0.784189 / Chance level: 0.500899\n",
      "0.26\n",
      "0.7395209580838323\n",
      "Time:  4.323137091583021\n",
      "0.7874251497005988\n",
      "Time:  4.566506141211676\n",
      "0.7514970059880239\n",
      "Time:  5.127316287706435\n",
      "0.7934131736526946\n",
      "Time:  5.488718851043586\n",
      "0.811377245508982\n",
      "Time:  5.574134655875014\n",
      "0.7634730538922155\n",
      "Time:  5.093208957023535\n",
      "0.8083832335329342\n",
      "Time:  5.197029846233136\n",
      "0.7904191616766467\n",
      "Time:  4.940509272571035\n",
      "0.811377245508982\n",
      "Time:  4.4742228644888655\n",
      "0.7904191616766467\n",
      "Time:  4.6727381586197225\n",
      "Classification accuracy: 0.784209 / Chance level: 0.500899\n",
      "0.27\n",
      "0.7425149700598802\n",
      "Time:  5.144775749773089\n",
      "0.7874251497005988\n",
      "Time:  4.772131921500886\n",
      "0.7514970059880239\n",
      "Time:  4.763275350005415\n",
      "0.7934131736526946\n",
      "Time:  4.628051359488609\n",
      "0.811377245508982\n",
      "Time:  4.946232165813626\n",
      "0.7604790419161677\n",
      "Time:  4.933661742690674\n",
      "0.8083832335329342\n",
      "Time:  4.30626754201262\n",
      "0.7904191616766467\n",
      "Time:  4.245839540090856\n",
      "0.8143712574850299\n",
      "Time:  4.432865917341815\n",
      "0.7874251497005988\n",
      "Time:  4.291838801772656\n",
      "Classification accuracy: 0.784228 / Chance level: 0.500899\n",
      "0.28\n",
      "0.7425149700598802\n",
      "Time:  5.327998768233101\n",
      "0.7874251497005988\n",
      "Time:  5.864010792801537\n",
      "0.7514970059880239\n",
      "Time:  5.833435516813324\n",
      "0.7964071856287425\n",
      "Time:  6.196610136477602\n",
      "0.811377245508982\n",
      "Time:  5.411234401173715\n",
      "0.7634730538922155\n",
      "Time:  4.521704327694579\n",
      "0.8083832335329342\n",
      "Time:  4.815477968252253\n",
      "0.7904191616766467\n",
      "Time:  4.607840827510017\n",
      "0.8143712574850299\n",
      "Time:  4.467924435548412\n",
      "0.7874251497005988\n",
      "Time:  4.436845971621324\n",
      "Classification accuracy: 0.784266 / Chance level: 0.500899\n",
      "0.29\n",
      "0.7425149700598802\n",
      "Time:  4.516246245800403\n",
      "0.781437125748503\n",
      "Time:  4.323472395619774\n",
      "0.7514970059880239\n",
      "Time:  4.314429389514771\n",
      "0.7994011976047904\n",
      "Time:  4.178359022971335\n",
      "0.811377245508982\n",
      "Time:  4.1897384906772\n",
      "0.7634730538922155\n",
      "Time:  4.205817780111147\n",
      "0.8083832335329342\n",
      "Time:  4.33087876556192\n",
      "0.7874251497005988\n",
      "Time:  4.2914200195523335\n",
      "0.8143712574850299\n",
      "Time:  4.6229239439546745\n",
      "0.7874251497005988\n",
      "Time:  4.5279401479974695\n",
      "Classification accuracy: 0.784281 / Chance level: 0.500899\n",
      "0.3\n",
      "0.7395209580838323\n",
      "Time:  4.148049949634924\n",
      "0.781437125748503\n",
      "Time:  4.288449123757346\n",
      "0.7514970059880239\n",
      "Time:  4.324540916367823\n",
      "0.7994011976047904\n",
      "Time:  4.267523462007375\n",
      "0.8143712574850299\n",
      "Time:  4.1950041089817205\n",
      "0.7634730538922155\n",
      "Time:  4.190873793972287\n",
      "0.8053892215568862\n",
      "Time:  4.254647879746699\n",
      "0.7874251497005988\n",
      "Time:  4.305452702188859\n",
      "0.8143712574850299\n",
      "Time:  4.35031434173743\n",
      "0.7874251497005988\n",
      "Time:  4.496908060838905\n",
      "Classification accuracy: 0.784286 / Chance level: 0.500899\n",
      "0.31\n",
      "0.7395209580838323\n",
      "Time:  4.1037944544514176\n",
      "0.7844311377245509\n",
      "Time:  4.236022041950719\n",
      "0.7485029940119761\n",
      "Time:  4.271993718730528\n",
      "0.7994011976047904\n",
      "Time:  4.129632807296957\n",
      "0.8143712574850299\n",
      "Time:  4.307851772427284\n",
      "0.7634730538922155\n",
      "Time:  4.226319094428845\n",
      "0.8053892215568862\n",
      "Time:  4.18063565854095\n",
      "0.7874251497005988\n",
      "Time:  4.195430775252589\n",
      "0.811377245508982\n",
      "Time:  4.31007924862206\n",
      "0.7844311377245509\n",
      "Time:  4.3811641681954825\n",
      "Classification accuracy: 0.784272 / Chance level: 0.500899\n",
      "0.32\n",
      "0.7395209580838323\n",
      "Time:  4.121963017309554\n",
      "0.7844311377245509\n",
      "Time:  4.328534883677776\n",
      "0.7485029940119761\n",
      "Time:  4.36014065146378\n",
      "0.7994011976047904\n",
      "Time:  4.266288912427626\n",
      "0.811377245508982\n",
      "Time:  4.247715944147558\n",
      "0.7634730538922155\n",
      "Time:  4.227273528325895\n",
      "0.8053892215568862\n",
      "Time:  4.194409095040783\n",
      "0.7874251497005988\n",
      "Time:  4.359947260338913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811377245508982\n",
      "Time:  4.198117845224033\n",
      "0.781437125748503\n",
      "Time:  4.247052756356879\n",
      "Classification accuracy: 0.784241 / Chance level: 0.500899\n",
      "0.33\n",
      "0.7395209580838323\n",
      "Time:  4.209268211693143\n",
      "0.7844311377245509\n",
      "Time:  4.236970910635819\n",
      "0.7485029940119761\n",
      "Time:  4.277930872643765\n",
      "0.8023952095808383\n",
      "Time:  4.712287339327531\n",
      "0.811377245508982\n",
      "Time:  4.9837203629260785\n",
      "0.7634730538922155\n",
      "Time:  4.870092642232976\n",
      "0.8053892215568862\n",
      "Time:  4.681497338901181\n",
      "0.7844311377245509\n",
      "Time:  4.582542300250452\n",
      "0.8083832335329342\n",
      "Time:  4.550567837154404\n",
      "0.7784431137724551\n",
      "Time:  4.324284916605393\n",
      "Classification accuracy: 0.784193 / Chance level: 0.500899\n",
      "0.34\n",
      "0.7365269461077845\n",
      "Time:  4.31206371054941\n",
      "0.7844311377245509\n",
      "Time:  4.406162637762236\n",
      "0.7455089820359282\n",
      "Time:  4.62681309976756\n",
      "0.7964071856287425\n",
      "Time:  4.2299888881264\n",
      "0.811377245508982\n",
      "Time:  4.379850314341866\n",
      "0.7634730538922155\n",
      "Time:  4.383995469917409\n",
      "0.8053892215568862\n",
      "Time:  4.376187477159419\n",
      "0.7844311377245509\n",
      "Time:  4.381957674705745\n",
      "0.8053892215568862\n",
      "Time:  4.290868136006338\n",
      "0.7784431137724551\n",
      "Time:  4.3436727247094495\n",
      "Classification accuracy: 0.784106 / Chance level: 0.500899\n",
      "0.35000000000000003\n",
      "0.7395209580838323\n",
      "Time:  4.2007562195883565\n",
      "0.781437125748503\n",
      "Time:  4.159033823504842\n",
      "0.7455089820359282\n",
      "Time:  4.245980061699811\n",
      "0.7964071856287425\n",
      "Time:  4.186845507853377\n",
      "0.811377245508982\n",
      "Time:  4.256667588018445\n",
      "0.7664670658682635\n",
      "Time:  4.180061977913738\n",
      "0.8053892215568862\n",
      "Time:  4.212965831452038\n",
      "0.7844311377245509\n",
      "Time:  4.2194196225673295\n",
      "0.8053892215568862\n",
      "Time:  4.376480578336896\n",
      "0.7784431137724551\n",
      "Time:  4.337973947386445\n",
      "Classification accuracy: 0.784032 / Chance level: 0.500899\n",
      "0.36\n",
      "0.7365269461077845\n",
      "Time:  4.101014167175208\n",
      "0.781437125748503\n",
      "Time:  4.191042605409621\n",
      "0.7455089820359282\n",
      "Time:  4.2015330304620875\n",
      "0.7964071856287425\n",
      "Time:  4.2082840966641015\n",
      "0.811377245508982\n",
      "Time:  4.261567293618782\n",
      "0.7664670658682635\n",
      "Time:  4.2957775807281\n",
      "0.8083832335329342\n",
      "Time:  4.39285760662483\n",
      "0.7844311377245509\n",
      "Time:  4.2982313755535415\n",
      "0.8053892215568862\n",
      "Time:  4.196900918816709\n",
      "0.7784431137724551\n",
      "Time:  4.297683202148846\n",
      "Classification accuracy: 0.783962 / Chance level: 0.500899\n",
      "0.37\n",
      "0.7335329341317365\n",
      "Time:  4.189029853653437\n",
      "0.781437125748503\n",
      "Time:  4.667373757798032\n",
      "0.7455089820359282\n",
      "Time:  4.4394569836920255\n",
      "0.7964071856287425\n",
      "Time:  4.284876721273804\n",
      "0.811377245508982\n",
      "Time:  4.36237786677998\n",
      "0.7694610778443114\n",
      "Time:  4.315712634701413\n",
      "0.8083832335329342\n",
      "Time:  4.543575611756069\n",
      "0.7874251497005988\n",
      "Time:  4.503663300949938\n",
      "0.8053892215568862\n",
      "Time:  4.612306446556431\n",
      "0.781437125748503\n",
      "Time:  4.343512261090154\n",
      "Classification accuracy: 0.783911 / Chance level: 0.500899\n",
      "0.38\n",
      "0.7335329341317365\n",
      "Time:  4.10571769904459\n",
      "0.781437125748503\n",
      "Time:  4.340560843537787\n",
      "0.7455089820359282\n",
      "Time:  4.225193994022902\n",
      "0.7964071856287425\n",
      "Time:  4.268161606342801\n",
      "0.811377245508982\n",
      "Time:  4.329631230486939\n",
      "0.7694610778443114\n",
      "Time:  4.3434700582306505\n",
      "0.8083832335329342\n",
      "Time:  4.373636291119965\n",
      "0.7844311377245509\n",
      "Time:  4.923104535091397\n",
      "0.8053892215568862\n",
      "Time:  4.7372946204804975\n",
      "0.781437125748503\n",
      "Time:  5.076394595808097\n",
      "Classification accuracy: 0.783855 / Chance level: 0.500899\n",
      "0.39\n",
      "0.7335329341317365\n",
      "Time:  4.466168147322151\n",
      "0.781437125748503\n",
      "Time:  4.876624810087151\n",
      "0.7455089820359282\n",
      "Time:  4.403232553523594\n",
      "0.7934131736526946\n",
      "Time:  4.48957867633294\n",
      "0.811377245508982\n",
      "Time:  4.741694848283032\n",
      "0.7694610778443114\n",
      "Time:  4.611867258557822\n",
      "0.8083832335329342\n",
      "Time:  4.355588307859989\n",
      "0.7844311377245509\n",
      "Time:  4.377176693633373\n",
      "0.8053892215568862\n",
      "Time:  4.326003175881169\n",
      "0.781437125748503\n",
      "Time:  4.159348257995816\n",
      "Classification accuracy: 0.783795 / Chance level: 0.500899\n",
      "0.4\n",
      "0.7335329341317365\n",
      "Time:  4.104473410343644\n",
      "0.781437125748503\n",
      "Time:  4.208880965675689\n",
      "0.7455089820359282\n",
      "Time:  4.273327514594712\n",
      "0.7934131736526946\n",
      "Time:  4.71165847034581\n",
      "0.811377245508982\n",
      "Time:  4.484773579340526\n",
      "0.7694610778443114\n",
      "Time:  4.420624305507772\n",
      "0.811377245508982\n",
      "Time:  4.319542428250315\n",
      "0.7844311377245509\n",
      "Time:  4.3320697209787795\n",
      "0.8053892215568862\n",
      "Time:  4.3654155451217775\n",
      "0.7844311377245509\n",
      "Time:  4.237848822864862\n",
      "Classification accuracy: 0.783752 / Chance level: 0.500899\n",
      "0.41000000000000003\n",
      "0.7335329341317365\n",
      "Time:  4.120789685064665\n",
      "0.781437125748503\n",
      "Time:  4.538358225290949\n",
      "0.7455089820359282\n",
      "Time:  4.5533402403800665\n",
      "0.7934131736526946\n",
      "Time:  4.299789634977742\n",
      "0.811377245508982\n",
      "Time:  4.320200050829044\n",
      "0.7694610778443114\n",
      "Time:  4.396685545103082\n",
      "0.811377245508982\n",
      "Time:  4.376865969283699\n",
      "0.7844311377245509\n",
      "Time:  4.6727478977411465\n",
      "0.8053892215568862\n",
      "Time:  4.258677093401047\n",
      "0.7844311377245509\n",
      "Time:  4.3013849958169885\n",
      "Classification accuracy: 0.783711 / Chance level: 0.500899\n",
      "0.42\n",
      "0.7335329341317365\n",
      "Time:  4.141726941006937\n",
      "0.7844311377245509\n",
      "Time:  4.805730035264787\n",
      "0.7425149700598802\n",
      "Time:  5.149296557174239\n",
      "0.7934131736526946\n",
      "Time:  4.583026473714426\n",
      "0.811377245508982\n",
      "Time:  4.989371372177402\n",
      "0.7694610778443114\n",
      "Time:  4.599058922611903\n",
      "0.811377245508982\n",
      "Time:  4.441376981911162\n",
      "0.781437125748503\n",
      "Time:  4.836712499281248\n",
      "0.8053892215568862\n",
      "Time:  4.346531388724543\n",
      "0.7874251497005988\n",
      "Time:  4.42135288454233\n",
      "Classification accuracy: 0.783672 / Chance level: 0.500899\n",
      "0.43\n",
      "0.7365269461077845\n",
      "Time:  4.400865947023021\n",
      "0.781437125748503\n",
      "Time:  4.5569144979344856\n",
      "0.7425149700598802\n",
      "Time:  4.368433745220955\n",
      "0.7934131736526946\n",
      "Time:  4.515170768537246\n",
      "0.811377245508982\n",
      "Time:  5.364172647723763\n",
      "0.7694610778443114\n",
      "Time:  4.368421687260934\n",
      "0.811377245508982\n",
      "Time:  4.401598236198652\n",
      "0.781437125748503\n",
      "Time:  4.486591084900965\n",
      "0.8053892215568862\n",
      "Time:  4.4602458339747955\n",
      "0.7844311377245509\n",
      "Time:  4.318698371062283\n",
      "Classification accuracy: 0.783628 / Chance level: 0.500899\n",
      "0.44\n",
      "0.7395209580838323\n",
      "Time:  4.38545216421835\n",
      "0.781437125748503\n",
      "Time:  4.304182906265169\n",
      "0.7395209580838323\n",
      "Time:  4.270312097101851\n",
      "0.7934131736526946\n",
      "Time:  4.156938057332809\n",
      "0.811377245508982\n",
      "Time:  4.519610880360915\n",
      "0.7694610778443114\n",
      "Time:  4.39092508667818\n",
      "0.8083832335329342\n",
      "Time:  4.451125842433839\n",
      "0.781437125748503\n",
      "Time:  4.646526009019226\n",
      "0.8053892215568862\n",
      "Time:  4.68946811411638\n",
      "0.7844311377245509\n",
      "Time:  4.397116385283425\n",
      "Classification accuracy: 0.783580 / Chance level: 0.500899\n",
      "0.45\n",
      "0.7335329341317365\n",
      "Time:  4.703184507191054\n",
      "0.781437125748503\n",
      "Time:  4.206535692488615\n",
      "0.7425149700598802\n",
      "Time:  4.276291917642311\n",
      "0.7934131736526946\n",
      "Time:  4.234211029137441\n",
      "0.811377245508982\n",
      "Time:  4.269399402296358\n",
      "0.7694610778443114\n",
      "Time:  4.280380957327907\n",
      "0.8083832335329342\n",
      "Time:  4.23771896791277\n",
      "0.781437125748503\n",
      "Time:  4.320672630100944\n",
      "0.8053892215568862\n",
      "Time:  4.193273791746378\n",
      "0.7844311377245509\n",
      "Time:  4.186183247598365\n",
      "Classification accuracy: 0.783526 / Chance level: 0.500899\n",
      "0.46\n",
      "0.7335329341317365\n",
      "Time:  4.240076762827357\n",
      "0.781437125748503\n",
      "Time:  4.193062777449086\n",
      "0.7425149700598802\n",
      "Time:  4.231758161847665\n",
      "0.7934131736526946\n",
      "Time:  4.377889504566156\n",
      "0.811377245508982\n",
      "Time:  4.539165181064163\n",
      "0.7724550898203593\n",
      "Time:  4.229030280319876\n",
      "0.811377245508982\n",
      "Time:  4.244326266132248\n",
      "0.781437125748503\n",
      "Time:  4.337297310332815\n",
      "0.8053892215568862\n",
      "Time:  4.324030308146121\n",
      "0.7844311377245509\n",
      "Time:  4.364652183511225\n",
      "Classification accuracy: 0.783488 / Chance level: 0.500899\n",
      "0.47000000000000003\n",
      "0.7335329341317365\n",
      "Time:  4.266598709241862\n",
      "0.781437125748503\n",
      "Time:  4.2126820056287215\n",
      "0.7425149700598802\n",
      "Time:  4.404452726304953\n",
      "0.7934131736526946\n",
      "Time:  5.07369500410914\n",
      "0.811377245508982\n",
      "Time:  4.708529429769442\n",
      "0.7724550898203593\n",
      "Time:  4.716415335498823\n",
      "0.8083832335329342\n",
      "Time:  5.217450001206089\n",
      "0.781437125748503\n",
      "Time:  4.521894936213357\n",
      "0.8053892215568862\n",
      "Time:  4.171984536130367\n",
      "0.7844311377245509\n",
      "Time:  4.246978089759523\n",
      "Classification accuracy: 0.783446 / Chance level: 0.500899\n",
      "0.48\n",
      "0.7335329341317365\n",
      "Time:  4.130867356876934\n",
      "0.781437125748503\n",
      "Time:  4.171299551258471\n",
      "0.7455089820359282\n",
      "Time:  4.1991172645866754\n",
      "0.7904191616766467\n",
      "Time:  4.392181433339374\n",
      "0.811377245508982\n",
      "Time:  4.451451407349396\n",
      "0.7724550898203593\n",
      "Time:  4.770970647215563\n",
      "0.811377245508982\n",
      "Time:  5.18743171020833\n",
      "0.7844311377245509\n",
      "Time:  4.610805230557617\n",
      "0.8053892215568862\n",
      "Time:  4.219768839634526\n",
      "0.7874251497005988\n",
      "Time:  4.942247937625325\n",
      "Classification accuracy: 0.783423 / Chance level: 0.500899\n",
      "0.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7335329341317365\n",
      "Time:  4.091906697361537\n",
      "0.781437125748503\n",
      "Time:  4.213933714612267\n",
      "0.7455089820359282\n",
      "Time:  4.284412489820625\n",
      "0.7904191616766467\n",
      "Time:  4.702203638535593\n",
      "0.811377245508982\n",
      "Time:  4.266529607856683\n",
      "0.7724550898203593\n",
      "Time:  4.200295234508758\n",
      "0.8143712574850299\n",
      "Time:  5.196793788481045\n",
      "0.7844311377245509\n",
      "Time:  4.332876212984502\n",
      "0.8053892215568862\n",
      "Time:  4.1894398242880015\n",
      "0.7874251497005988\n",
      "Time:  4.655106174973753\n",
      "Classification accuracy: 0.783407 / Chance level: 0.500899\n",
      "0.5\n",
      "0.7335329341317365\n",
      "Time:  4.1077429725282855\n",
      "0.781437125748503\n",
      "Time:  4.23195665441699\n",
      "0.7485029940119761\n",
      "Time:  4.180254441503166\n",
      "0.7904191616766467\n",
      "Time:  4.145957893604191\n",
      "0.811377245508982\n",
      "Time:  4.248310030553057\n",
      "0.7724550898203593\n",
      "Time:  4.204057317975639\n",
      "0.8173652694610778\n",
      "Time:  4.202469841187394\n",
      "0.7874251497005988\n",
      "Time:  4.322902888901353\n",
      "0.8023952095808383\n",
      "Time:  4.165958338821383\n",
      "0.7874251497005988\n",
      "Time:  4.2133136572160765\n",
      "Classification accuracy: 0.783404 / Chance level: 0.500899\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import pyriemann.estimation\n",
    "import pyriemann.classification\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import ShuffleSplit  \n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import timeit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "epochs_data = agg_epochs_std\n",
    "labels = agg_labels\n",
    "\n",
    "\n",
    "# degree = [1.8, 1.9, 2, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6]\n",
    "# degree = [2.7, 2.8, 2.9, 3.0, 3.1, 3.2,3.3, 3.4, 3.5, 3.6]\n",
    "degree = np.linspace(3.7, 5.5, 19)\n",
    "coefs = np.linspace(0.0, 0.5, 51)\n",
    "\n",
    "\n",
    "for coef in coefs:\n",
    "    print(coef)\n",
    "    for train_idx, test_idx in cv.split(epochs_data):\n",
    "        start = timeit.default_timer()\n",
    "        y_train, y_test = np.asarray(labels)[train_idx], np.asarray(labels)[test_idx]\n",
    "        X_train = epochs_data[train_idx]\n",
    "        X_test = epochs_data[test_idx]\n",
    "\n",
    "\n",
    "        cov =  pyriemann.estimation.Covariances('lwf')\n",
    "        cov_X_train = cov.transform(X_train)\n",
    "        cov_X_test = cov.transform(X_test)\n",
    "\n",
    "    #     TSclassifier = pyriemann.classification.TSclassifier(metric='riemann', clf=sklearn.discriminant_analysis.LinearDiscriminantAnalysis())\n",
    "    #     TSclassifier = pyriemann.classification.TSclassifier(metric='riemann', clf=SVC(kernel='rbf', random_state=0, gamma= 0.03, C=100))\n",
    "        TSclassifier = pyriemann.classification.TSclassifier(metric='riemann', clf=SVC(kernel='poly', degree = 2.7,  random_state=0, coef0 =coef, gamma= 0.03, C=100))\n",
    "\n",
    "    #     TSclassifier = pyriemann.classification.TSclassifier(metric='riemann', clf=LogisticRegression())\n",
    "\n",
    "        TSclassifier.fit(cov_X_train, y_train)\n",
    "\n",
    "\n",
    "        y_predict = TSclassifier.predict(cov_X_test)\n",
    "        print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "        scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "        stop = timeit.default_timer()\n",
    "        print('Time: ', stop - start)  \n",
    "\n",
    "\n",
    "    class_balance = np.mean(np.asarray(labels) == np.asarray(labels)[0])\n",
    "    print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                              class_balance))\n",
    "\n",
    "\n",
    "\n",
    "#non-even number of degree\n",
    "# degree =2  70%\n",
    "# degree = 2.2     0.776347\n",
    "#2.6     0.776347 ON AVERAGE\n",
    "#    2.2 with 0.2 coef   => 0.786228!!!    with 0.3 coef 0.784431;    with 0.1 =>0.784731\n",
    "\n",
    "    \n",
    "#linear with 0.2 coef =>   0.701796\n",
    "\n",
    "#   degree 1.2  coef 0.2   =>  0.724251\n",
    "\n",
    "# degree 1.4   coef  0.2  => 0.724251\n",
    "\n",
    "# degree 1.6          0.724251\n",
    "\n",
    "#1.8          0.724251\n",
    "#1.9           0.724251\n",
    "#2.0         0.744910\n",
    "#2.1           0.755240 \n",
    "#2.2          0.761437\n",
    "#2.3          0.765569 \n",
    "#2.4           0.768520\n",
    "#2.5            0.770734\n",
    "#2.6           0.772455\n",
    "#2.7           0.786228\n",
    "#2.8            0.786228\n",
    "#2.9          0.786228\n",
    "#3               0.782859\n",
    "#3.1           0.780838\n",
    "#3.2              0.779491\n",
    "#3.3              0.778529\n",
    "#3.4           0.777807\n",
    "#3.5           0.777246\n",
    "#3.6            0.776796\n",
    "#3.7            0.772754\n",
    "\n",
    "#3.8               0.772754\n",
    "#3.9              0.772754\n",
    "#4.0            0.772231\n",
    "#                      0.771916\n",
    "#                  0.771707 \n",
    "#                 0.771557\n",
    "#                 0.771445 \n",
    "#                 0.771357 \n",
    "#                 0.771287\n",
    "#                 0.771230\n",
    "#                 0.771183\n",
    "#                 0.771142\n",
    "#                 0.770488\n",
    "#      degree 5.1    0.769920\n",
    "#                   0.769424\n",
    "#                    0.768986\n",
    "#                   0.768596\n",
    "#                 0.768248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.6 0.7 0.8 0.9 1.  1.1 1.2 1.3 1.4 1.5 1.6 1.7 1.8 1.9 2.  2.1 2.2\n",
      " 2.3 2.4 2.5 2.6 2.7 2.8 2.9 3.  3.1 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9 4.\n",
      " 4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 4.9 5. ]\n"
     ]
    }
   ],
   "source": [
    "# degree = np.linspace(3.7, 5.5, 19)\n",
    "# print(degree)\n",
    "\n",
    "coefs = np.linspace(0.5, 5, 46)\n",
    "print(coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging of 21 SVM base classifiers with fine-tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7634730538922155\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7724550898203593\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.781437125748503\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7574850299401198\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.8053892215568862\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7634730538922155\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7754491017964071\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7904191616766467\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7994011976047904\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7994011976047904\n",
      "Classification accuracy: 0.780838 / Chance level: 0.500899\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7455089820359282\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7604790419161677\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7634730538922155\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7964071856287425\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.8143712574850299\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7574850299401198\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7994011976047904\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.8053892215568862\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.781437125748503\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7724550898203593\n",
      "Classification accuracy: 0.780240 / Chance level: 0.500899\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7664670658682635\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7934131736526946\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7844311377245509\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7994011976047904\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.8263473053892215\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7634730538922155\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7934131736526946\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.781437125748503\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7964071856287425\n",
      "(1335, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7904191616766467\n",
      "Classification accuracy: 0.783333 / Chance level: 0.500899\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import pyriemann.estimation\n",
    "import pyriemann.classification\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import ShuffleSplit  \n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_estimators = [9,11,13]\n",
    "n_samples, _,_ = agg_epochs_std.shape\n",
    "labels = agg_labels\n",
    "\n",
    "agg_epochs_std_train_test = agg_epochs_std\n",
    "epochs_data = agg_epochs_std_train_test\n",
    "\n",
    "for n_estimator in n_estimators:\n",
    "    for train_idx, test_idx in cv.split(epochs_data):\n",
    "        y_train, y_test = np.asarray(labels)[train_idx], np.asarray(labels)[test_idx]\n",
    "        X_train = epochs_data[train_idx]\n",
    "        X_test = epochs_data[test_idx]\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "\n",
    "\n",
    "        cov =  pyriemann.estimation.Covariances('lwf')\n",
    "        cov_X_train = cov.transform(X_train)\n",
    "        cov_X_test = cov.transform(X_test)\n",
    "\n",
    "        n_samples_train, _,_ = cov_X_train.shape\n",
    "        subset_size = n_samples_train//3 * 2\n",
    "\n",
    "        ind_sets = [np.random.randint(0, n_samples_train, size = subset_size) for i in range(n_estimator)]\n",
    "\n",
    "        clfs = [pyriemann.classification.TSclassifier(metric='riemann', clf=SVC(kernel='rbf', degree=2.7, coef0=0.2,  random_state=0, gamma= 0.03, C=100, probability=True)) for i in range(n_estimator)]\n",
    "\n",
    "\n",
    "        for i in range(n_estimator):\n",
    "            clfs[i].fit(cov_X_train[ind_sets[i],:,:], y_train[ind_sets[i]])\n",
    "\n",
    "        y_predict = [clfs[i].predict(cov_X_test) for i in range(n_estimator)]\n",
    "        y_predict = scipy.stats.mode(y_predict, axis=0).mode[0]\n",
    "\n",
    "\n",
    "        scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "        print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "\n",
    "    class_balance = np.mean(np.asarray(labels) == np.asarray(labels)[0])\n",
    "    print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                              class_balance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for two stage classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334\n",
      "(1001, 32, 1033)\n",
      "(334, 32, 1033)\n",
      "0.7395209580838323\n",
      "Classification accuracy: 0.739521 / Chance level: 0.500899\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import pyriemann.estimation\n",
    "import pyriemann.classification\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import ShuffleSplit  \n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cv = ShuffleSplit(n_splits=1, test_size=0.4, random_state=42)\n",
    "scores = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_estimator = 9\n",
    "n_samples, _,_ = agg_epochs_std.shape\n",
    "labels = agg_labels\n",
    "\n",
    "agg_epochs_std_train_test = agg_epochs_std\n",
    "epochs_data = agg_epochs_std_train_test\n",
    "\n",
    "wrong = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(epochs_data):\n",
    "    val_idx = test_idx[len(test_idx)//2:]\n",
    "    test_idx = test_idx[:len(test_idx)//2]\n",
    "    X_validation = epochs_data[val_idx]\n",
    "    y_validation = np.asarray(labels)[val_idx]\n",
    "    \n",
    "    print(len(val_idx))\n",
    "    \n",
    "    \n",
    "    y_train, y_test = np.asarray(labels)[train_idx], np.asarray(labels)[test_idx]\n",
    "    \n",
    "    X_train = epochs_data[train_idx]\n",
    "    X_test = epochs_data[test_idx]\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "\n",
    "    \n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    \n",
    "#     n_samples_train, _,_ = cov_X_train.shape\n",
    "#     subset_size = n_samples_train//3 * 2\n",
    "    \n",
    "#     ind_sets = [np.random.randint(0, n_samples_train, size = subset_size) for i in range(n_estimator)]\n",
    "    \n",
    "#     clfs = [pyriemann.classification.TSclassifier(metric='riemann', clf=SVC(kernel='rbf', random_state=0, gamma= 0.03, C=100, probability=True)) for i in range(n_estimator)]\n",
    "    clf = pyriemann.classification.TSclassifier(metric='riemann', clf=SVC(kernel='rbf', random_state=0, gamma= 0.03, C=100, probability=True))\n",
    "#     clf = pyriemann.classification.TSclassifier(metric='riemann')\n",
    "\n",
    "#     for i in range(n_estimator):\n",
    "#         clfs[i].fit(cov_X_train[ind_sets[i],:,:], y_train[ind_sets[i]])\n",
    "    \n",
    "#     y_predict = [clfs[i].predict(cov_X_test) for i in range(n_estimator)]\n",
    "#     y_predict = scipy.stats.mode(y_predict, axis=0).mode[0]\n",
    "\n",
    "    clf.fit(cov_X_train, y_train)\n",
    "    y_predict = clf.predict(cov_X_test)\n",
    "\n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "    print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "    \n",
    "    \n",
    "#     wrong.append([test_idx[i] for i in range(len(y_test)) if y_predict[i] != y_test[i]])\n",
    "\n",
    "class_balance = np.mean(np.asarray(labels) == np.asarray(labels)[0])\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7802746566791511\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick out the channel that were repeatedly classified wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1128, 1090, 983, 1117, 777, 1178, 771, 744, 247, 554, 1243, 1143, 879, 643, 1272, 765, 81, 1222, 723, 254, 716, 1179, 704, 1247, 1176, 503, 1274, 371, 838, 1029, 1053, 904, 1157, 1018, 872, 354, 638, 1268, 833, 608, 625, 1201, 602, 901, 1061, 785, 1295, 680, 903, 724, 826, 296, 1155, 675, 470, 295, 715, 656, 1051, 369, 490, 858, 1209, 931, 505, 835, 676, 580, 1286, 1324, 1127, 21, 1033, 576, 738, 1180, 760, 670, 1185, 1182, 839, 743, 429, 936, 1115, 471, 315, 1126, 463, 1186, 184, 244, 682, 1109, 283, 1257, 485, 1314, 1057, 1005, 944, 425, 472, 1104, 996, 1161, 1080, 834, 577, 975, 1015, 1008, 825, 1192, 1083, 1248, 1320, 898, 790, 836, 831, 1184, 1242, 650, 1141, 655, 1079, 1043, 1211, 755, 436, 874, 518, 719, 599, 491, 1147, 997, 1049, 1167, 811, 803, 717, 1082, 991, 837, 1025, 37, 1170, 805]\n"
     ]
    }
   ],
   "source": [
    "result = [1128, 1268, 833, 1090, 983, 608, 625, 1201, 602, 901, 1061, 1117, 777, 785, 1295, 680, 903, 724, 826, 296, 1178, 1155, 675, 470, 771, 744, 247, 554, 295, 715, 656, 1051, 1243, 369, 490, 858, 1143, 879, 643, 1272, 1209, 931, 505, 835, 676, 580, 1286, 1324, 1127, 21, 1033, 765, 576, 738, 1180, 760, 670, 81, 1222, 1185, 1182, 839, 743, 723, 254, 429, 936, 1115, 716, 471, 315, 1126, 463, 1186, 184, 244, 1179, 682, 1109, 283, 704, 1247, 1257, 485, 1314, 1057, 1005, 944, 425, 472, 1104, 996, 1161, 1080, 834, 577, 975, 1015, 1008, 1176, 825, 1192, 1083, 1248, 1320, 898, 790, 503, 836, 831, 1184, 1242, 1274, 371, 650, 1141, 655, 1079, 1043, 838, 1211, 755, 436, 874, 1029, 1053, 518, 719, 599, 491, 1147, 997, 1049, 1167, 904, 811, 803, 1157, 1018, 872, 354, 638, 717, 1082, 991, 837, 1025, 37, 1170, 805]\n",
    "result = result + sum(wrong, [])\n",
    "from collections import Counter\n",
    "l = [i[0] for i in list(Counter(result).most_common(150))]\n",
    "print(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training another classifier to classify \"good\" epochs and \"bad\" epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(122, 32, 1033)\n",
      "[[89  1]\n",
      " [30  2]]\n",
      "recall: 0.0625\n",
      "specificiity: 0.9888888888888889\n",
      "(122, 32, 1033)\n",
      "[[92  5]\n",
      " [21  4]]\n",
      "recall: 0.16\n",
      "specificiity: 0.9484536082474226\n",
      "Classification accuracy: 0.766393 / Chance level: 0.752475\n",
      "1.1526818432767743\n",
      "(122, 32, 1033)\n",
      "[[90  0]\n",
      " [32  0]]\n",
      "recall: 0.0\n",
      "specificiity: 1.0\n",
      "(122, 32, 1033)\n",
      "[[97  0]\n",
      " [25  0]]\n",
      "recall: 0.0\n",
      "specificiity: 1.0\n",
      "Classification accuracy: 0.766393 / Chance level: 0.752475\n",
      "0.4054674414465533\n",
      "(122, 32, 1033)\n",
      "[[90  0]\n",
      " [32  0]]\n",
      "recall: 0.0\n",
      "specificiity: 1.0\n",
      "(122, 32, 1033)\n",
      "[[96  1]\n",
      " [23  2]]\n",
      "recall: 0.08\n",
      "specificiity: 0.9896907216494846\n",
      "Classification accuracy: 0.767760 / Chance level: 0.752475\n",
      "-0.057156080501559604\n",
      "(122, 32, 1033)\n",
      "[[89  1]\n",
      " [29  3]]\n",
      "recall: 0.09375\n",
      "specificiity: 0.9888888888888889\n",
      "(122, 32, 1033)\n",
      "[[92  5]\n",
      " [20  5]]\n",
      "recall: 0.2\n",
      "specificiity: 0.9484536082474226\n",
      "Classification accuracy: 0.769467 / Chance level: 0.752475\n",
      "-0.4054627747697755\n",
      "(122, 32, 1033)\n",
      "[[80 10]\n",
      " [26  6]]\n",
      "recall: 0.1875\n",
      "specificiity: 0.8888888888888888\n",
      "(122, 32, 1033)\n",
      "[[82 15]\n",
      " [17  8]]\n",
      "recall: 0.32\n",
      "specificiity: 0.845360824742268\n",
      "Classification accuracy: 0.759836 / Chance level: 0.752475\n",
      "-0.6931448472215563\n",
      "(122, 32, 1033)\n",
      "[[68 22]\n",
      " [22 10]]\n",
      "recall: 0.3125\n",
      "specificiity: 0.7555555555555555\n",
      "(122, 32, 1033)\n",
      "[[72 25]\n",
      " [14 11]]\n",
      "recall: 0.44\n",
      "specificiity: 0.7422680412371134\n",
      "Classification accuracy: 0.743169 / Chance level: 0.752475\n",
      "-0.9444592755024624\n",
      "(122, 32, 1033)\n",
      "[[61 29]\n",
      " [17 15]]\n",
      "recall: 0.46875\n",
      "specificiity: 0.6777777777777778\n",
      "(122, 32, 1033)\n",
      "[[61 36]\n",
      " [ 9 16]]\n",
      "recall: 0.64\n",
      "specificiity: 0.6288659793814433\n",
      "Classification accuracy: 0.726581 / Chance level: 0.752475\n",
      "-1.1727179274834425\n",
      "(122, 32, 1033)\n",
      "[[50 40]\n",
      " [12 20]]\n",
      "recall: 0.625\n",
      "specificiity: 0.5555555555555556\n",
      "(122, 32, 1033)\n",
      "[[54 43]\n",
      " [ 7 18]]\n",
      "recall: 0.72\n",
      "specificiity: 0.5567010309278351\n",
      "Classification accuracy: 0.708504 / Chance level: 0.752475\n",
      "-1.3862920277815018\n",
      "(122, 32, 1033)\n",
      "[[44 46]\n",
      " [10 22]]\n",
      "recall: 0.6875\n",
      "specificiity: 0.4888888888888889\n",
      "(122, 32, 1033)\n",
      "[[49 48]\n",
      " [ 4 21]]\n",
      "recall: 0.84\n",
      "specificiity: 0.5051546391752577\n",
      "Classification accuracy: 0.691712 / Chance level: 0.752475\n",
      "-1.591086440427515\n",
      "(122, 32, 1033)\n",
      "[[38 52]\n",
      " [ 7 25]]\n",
      "recall: 0.78125\n",
      "specificiity: 0.4222222222222222\n",
      "(122, 32, 1033)\n",
      "[[43 54]\n",
      " [ 2 23]]\n",
      "recall: 0.92\n",
      "specificiity: 0.44329896907216493\n",
      "Classification accuracy: 0.675410 / Chance level: 0.752475\n",
      "-1.791757135889666\n",
      "(122, 32, 1033)\n",
      "[[34 56]\n",
      " [ 6 26]]\n",
      "recall: 0.8125\n",
      "specificiity: 0.37777777777777777\n",
      "(122, 32, 1033)\n",
      "[[37 60]\n",
      " [ 2 23]]\n",
      "recall: 0.92\n",
      "specificiity: 0.38144329896907214\n",
      "Classification accuracy: 0.658718 / Chance level: 0.752475\n",
      "-1.9924278313518173\n",
      "(122, 32, 1033)\n",
      "[[30 60]\n",
      " [ 4 28]]\n",
      "recall: 0.875\n",
      "specificiity: 0.3333333333333333\n",
      "(122, 32, 1033)\n",
      "[[34 63]\n",
      " [ 1 24]]\n",
      "recall: 0.96\n",
      "specificiity: 0.35051546391752575\n",
      "Classification accuracy: 0.643443 / Chance level: 0.752475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pyriemann.tangentspace import FGDA, TangentSpace\n",
    "\n",
    "correct = [i for i in np.random.randint(0,(n_samples//5 * 4),500) if i not in l]\n",
    "bad = l\n",
    "ind = correct + bad\n",
    "X = agg_epochs_std_train_test[ind]\n",
    "y = [0 for i in range(len(correct))] + [1 for i in range(len(bad))] \n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=2, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "epochs_data = X\n",
    "labels = y\n",
    "\n",
    "\n",
    "inter_adj = [0, 1.1526818432767743, 0.4054674414465533, -0.057156080501559604, -0.4054627747697755, -0.6931448472215563, -0.9444592755024624, -1.1727179274834425, -1.3862920277815018, -1.591086440427515, -1.791757135889666, -1.9924278313518173]\n",
    "\n",
    "for adj in inter_adj:\n",
    "    print(adj)\n",
    "    for train_idx, test_idx in cv.split(epochs_data):\n",
    "        y_train, y_test = np.asarray(labels)[train_idx], np.asarray(labels)[test_idx]\n",
    "        X_train = epochs_data[train_idx]\n",
    "        X_test = epochs_data[test_idx]\n",
    "        \n",
    "        print(X_test.shape)\n",
    "\n",
    "\n",
    "        cov =  pyriemann.estimation.Covariances('lwf')\n",
    "        cov_X_train = cov.transform(X_train)\n",
    "        cov_X_test = cov.transform(X_test)\n",
    "\n",
    "\n",
    "        ts = TangentSpace()\n",
    "        ts.fit(cov_X_train, y_train)\n",
    "        T = ts.transform(cov_X_train)\n",
    "\n",
    "\n",
    "        bad_catcher =LogisticRegression(penalty='l2', C=1.0, fit_intercept=True)\n",
    "        bad_catcher.fit(T, y_train)\n",
    "\n",
    "\n",
    "        bad_catcher.intercept_[0] = bad_catcher.intercept_[0] - adj\n",
    "        \n",
    "        \n",
    "        T_test = ts.transform(cov_X_test)\n",
    "\n",
    "        y_predict = bad_catcher.predict(T_test)\n",
    "        \n",
    "        \n",
    "#         print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "        true_negative, false_negative, false_positive, true_positive = confusion_matrix(y_test,y_predict)[0][0],confusion_matrix(y_test,y_predict)[1][0],confusion_matrix(y_test,y_predict)[0][1],confusion_matrix(y_test,y_predict)[1][1]   \n",
    "        recall = (true_positive/(true_positive+false_negative))\n",
    "        specificity = (true_negative/(true_negative+false_positive))\n",
    "        print(confusion_matrix(y_test,y_predict))\n",
    "        print(\"recall: {}\".format(recall))\n",
    "        print(\"specificiity: {}\".format(specificity))\n",
    "        scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "    class_balance = np.mean(np.asarray(labels) == np.asarray(labels)[0])\n",
    "    print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                              class_balance))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two stag classifer on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334, 32, 1033)\n",
      "[0.18019778 0.81980222]\n",
      "[0.42039515 0.57960485]\n",
      "[0.23138797 0.76861203]\n",
      "[0.27833027 0.72166973]\n",
      "[0.13768129 0.86231871]\n",
      "[0.21316125 0.78683875]\n",
      "[0.46853376 0.53146624]\n",
      "[0.10034112 0.89965888]\n",
      "[0.15580151 0.84419849]\n",
      "[0.08315754 0.91684246]\n",
      "[0.21872734 0.78127266]\n",
      "[0.34256012 0.65743988]\n",
      "[0.31471191 0.68528809]\n",
      "[0.11907302 0.88092698]\n",
      "[0.19775697 0.80224303]\n",
      "[0.25259036 0.74740964]\n",
      "[0.35446431 0.64553569]\n",
      "[0.3679004 0.6320996]\n",
      "[0.14493363 0.85506637]\n",
      "[0.27416582 0.72583418]\n",
      "[0.23122752 0.76877248]\n",
      "[0.28746067 0.71253933]\n",
      "[0.14025645 0.85974355]\n",
      "[0.16109604 0.83890396]\n",
      "[0.17810547 0.82189453]\n",
      "[0.24628235 0.75371765]\n",
      "[0.31970625 0.68029375]\n",
      "[0.33313181 0.66686819]\n",
      "[0.21814537 0.78185463]\n",
      "[0.17801012 0.82198988]\n",
      "[0.08066027 0.91933973]\n",
      "[0.27674142 0.72325858]\n",
      "[0.26557284 0.73442716]\n",
      "[0.27962612 0.72037388]\n",
      "[0.10408911 0.89591089]\n",
      "[0.4083309 0.5916691]\n",
      "[0.25361353 0.74638647]\n",
      "[0.18923664 0.81076336]\n",
      "[0.30304132 0.69695868]\n",
      "[0.17892273 0.82107727]\n",
      "[0.18387533 0.81612467]\n",
      "[0.13656229 0.86343771]\n",
      "[0.47647884 0.52352116]\n",
      "[0.15400239 0.84599761]\n",
      "[0.17398663 0.82601337]\n",
      "[0.13324334 0.86675666]\n",
      "[0.19928624 0.80071376]\n",
      "[0.19218719 0.80781281]\n",
      "[0.16596362 0.83403638]\n",
      "[0.39856655 0.60143345]\n",
      "[0.41329136 0.58670864]\n",
      "[0.20203257 0.79796743]\n",
      "[0.28424841 0.71575159]\n",
      "[0.43551606 0.56448394]\n",
      "[0.3385997 0.6614003]\n",
      "[0.14433603 0.85566397]\n",
      "[0.19245868 0.80754132]\n",
      "[0.3064581 0.6935419]\n",
      "[0.29849218 0.70150782]\n",
      "[0.31079022 0.68920978]\n",
      "[0.1492974 0.8507026]\n",
      "[0.2306924 0.7693076]\n",
      "[0.40627299 0.59372701]\n",
      "[0.27235657 0.72764343]\n",
      "[0.42626607 0.57373393]\n",
      "[0.08854394 0.91145606]\n",
      "[0.27758711 0.72241289]\n",
      "[0.36548017 0.63451983]\n",
      "[0.30872799 0.69127201]\n",
      "[0.09482145 0.90517855]\n",
      "[0.30212984 0.69787016]\n",
      "[0.20399319 0.79600681]\n",
      "[0.26159713 0.73840287]\n",
      "[0.4098076 0.5901924]\n",
      "[0.22730386 0.77269614]\n",
      "[0.2484818 0.7515182]\n",
      "[0.24181712 0.75818288]\n",
      "[0.15367097 0.84632903]\n",
      "[0.15780336 0.84219664]\n",
      "[0.29207204 0.70792796]\n",
      "[0.07867737 0.92132263]\n",
      "[0.28067791 0.71932209]\n",
      "[0.14087127 0.85912873]\n",
      "[0.17643477 0.82356523]\n",
      "[0.46303108 0.53696892]\n",
      "[0.19048224 0.80951776]\n",
      "[0.1850227 0.8149773]\n",
      "[0.27234405 0.72765595]\n",
      "[0.3920251 0.6079749]\n",
      "[0.09864847 0.90135153]\n",
      "[0.27285674 0.72714326]\n",
      "[0.16188235 0.83811765]\n",
      "[0.24662968 0.75337032]\n",
      "[0.3694693 0.6305307]\n",
      "[0.3646181 0.6353819]\n",
      "[0.16573496 0.83426504]\n",
      "[0.39836253 0.60163747]\n",
      "[0.28862669 0.71137331]\n",
      "[0.1861061 0.8138939]\n",
      "[0.24850504 0.75149496]\n",
      "[0.17499501 0.82500499]\n",
      "[0.46749862 0.53250138]\n",
      "[0.14810597 0.85189403]\n",
      "[0.30720132 0.69279868]\n",
      "[0.16560749 0.83439251]\n",
      "[0.30183647 0.69816353]\n",
      "[0.46275999 0.53724001]\n",
      "[0.47576029 0.52423971]\n",
      "[0.1425521 0.8574479]\n",
      "[0.23362747 0.76637253]\n",
      "[0.09118521 0.90881479]\n",
      "[0.3343452 0.6656548]\n",
      "[0.14167873 0.85832127]\n",
      "[0.25648453 0.74351547]\n",
      "[0.20484021 0.79515979]\n",
      "[0.47678964 0.52321036]\n",
      "[0.11815854 0.88184146]\n",
      "[0.33560547 0.66439453]\n",
      "[0.20401912 0.79598088]\n",
      "[0.16467557 0.83532443]\n",
      "[0.21699644 0.78300356]\n",
      "[0.21598873 0.78401127]\n",
      "[0.26761146 0.73238854]\n",
      "[0.23973818 0.76026182]\n",
      "[0.22615009 0.77384991]\n",
      "[0.29873116 0.70126884]\n",
      "[0.18177458 0.81822542]\n",
      "[0.26636004 0.73363996]\n",
      "[0.38197883 0.61802117]\n",
      "[0.33606624 0.66393376]\n",
      "[0.24093169 0.75906831]\n",
      "[0.44287659 0.55712341]\n",
      "[0.27657692 0.72342308]\n",
      "[0.42208319 0.57791681]\n",
      "[0.23128691 0.76871309]\n",
      "[0.26739846 0.73260154]\n",
      "[0.08300855 0.91699145]\n",
      "[0.1834757 0.8165243]\n",
      "[0.40434866 0.59565134]\n",
      "[0.25006169 0.74993831]\n",
      "[0.16244475 0.83755525]\n",
      "[0.44317047 0.55682953]\n",
      "[0.2926114 0.7073886]\n",
      "[0.06883516 0.93116484]\n",
      "[0.18314959 0.81685041]\n",
      "[0.2904398 0.7095602]\n",
      "[0.28879824 0.71120176]\n",
      "[0.08002552 0.91997448]\n",
      "[0.4937454 0.5062546]\n",
      "[0.46588249 0.53411751]\n",
      "[0.15505906 0.84494094]\n",
      "[0.31245737 0.68754263]\n",
      "[0.16323049 0.83676951]\n",
      "[0.08250949 0.91749051]\n",
      "[0.28239636 0.71760364]\n",
      "[0.28809495 0.71190505]\n",
      "[0.30467351 0.69532649]\n",
      "[0.08251533 0.91748467]\n",
      "[0.19523756 0.80476244]\n",
      "[0.35725755 0.64274245]\n",
      "[0.32898693 0.67101307]\n",
      "[0.48969509 0.51030491]\n",
      "[0.18047293 0.81952707]\n",
      "[0.43444217 0.56555783]\n",
      "[0.08806286 0.91193714]\n",
      "[0.31368004 0.68631996]\n",
      "[0.49276497 0.50723503]\n",
      "[0.08794707 0.91205293]\n",
      "[0.14542746 0.85457254]\n",
      "[0.240482 0.759518]\n",
      "[0.4114554 0.5885446]\n",
      "[0.2088837 0.7911163]\n",
      "[0.26877492 0.73122508]\n",
      "[0.3989099 0.6010901]\n",
      "[0.35638472 0.64361528]\n",
      "[0.34872657 0.65127343]\n",
      "[0.13489459 0.86510541]\n",
      "[0.29093814 0.70906186]\n",
      "[0.28533901 0.71466099]\n",
      "[0.38333474 0.61666526]\n",
      "[0.17083363 0.82916637]\n",
      "[0.15713586 0.84286414]\n",
      "[0.31835894 0.68164106]\n",
      "[0.08706561 0.91293439]\n",
      "[0.35024831 0.64975169]\n",
      "[0.21630659 0.78369341]\n",
      "[0.2296274 0.7703726]\n",
      "[0.41361851 0.58638149]\n",
      "[0.19844562 0.80155438]\n",
      "[0.17702195 0.82297805]\n",
      "[0.34875317 0.65124683]\n",
      "[0.12094721 0.87905279]\n",
      "[0.18949821 0.81050179]\n",
      "[0.21739416 0.78260584]\n",
      "[0.24655474 0.75344526]\n",
      "[0.22044883 0.77955117]\n",
      "[0.417639 0.582361]\n",
      "[0.11783952 0.88216048]\n",
      "[0.34904295 0.65095705]\n",
      "[0.35165041 0.64834959]\n",
      "[0.29190598 0.70809402]\n",
      "[0.20535851 0.79464149]\n",
      "[0.36736014 0.63263986]\n",
      "[0.38236683 0.61763317]\n",
      "[0.36425828 0.63574172]\n",
      "[0.21436418 0.78563582]\n",
      "[0.18718741 0.81281259]\n",
      "[0.22675809 0.77324191]\n",
      "[0.16432382 0.83567618]\n",
      "[0.34656006 0.65343994]\n",
      "[0.21829696 0.78170304]\n",
      "[0.22428997 0.77571003]\n",
      "[0.41515364 0.58484636]\n",
      "[0.28859714 0.71140286]\n",
      "[0.27218346 0.72781654]\n",
      "[0.11197238 0.88802762]\n",
      "[0.1617306 0.8382694]\n",
      "[0.3794053 0.6205947]\n",
      "[0.41866758 0.58133242]\n",
      "[0.22827195 0.77172805]\n",
      "[0.13207838 0.86792162]\n",
      "[0.21369972 0.78630028]\n",
      "[0.39299077 0.60700923]\n",
      "[0.24091389 0.75908611]\n",
      "[0.28758009 0.71241991]\n",
      "[0.13684291 0.86315709]\n",
      "[0.17642597 0.82357403]\n",
      "[0.18946684 0.81053316]\n",
      "[0.29302354 0.70697646]\n",
      "[0.18101068 0.81898932]\n",
      "[0.15122324 0.84877676]\n",
      "[0.33638466 0.66361534]\n",
      "[0.14363604 0.85636396]\n",
      "[0.1826804 0.8173196]\n",
      "[0.47506425 0.52493575]\n",
      "[0.19880073 0.80119927]\n",
      "[0.31173059 0.68826941]\n",
      "[0.25545254 0.74454746]\n",
      "[0.16554368 0.83445632]\n",
      "[0.23203565 0.76796435]\n",
      "[0.12980202 0.87019798]\n",
      "[0.15222702 0.84777298]\n",
      "[0.24886428 0.75113572]\n",
      "0\n",
      "reminding: 1.0\n",
      "0.8023952095808383\n",
      "(334, 32, 1033)\n",
      "[0.18019778 0.81980222]\n",
      "[0.42039515 0.57960485]\n",
      "[0.23138797 0.76861203]\n",
      "[0.27833027 0.72166973]\n",
      "[0.13768129 0.86231871]\n",
      "[0.21316125 0.78683875]\n",
      "[0.46853376 0.53146624]\n",
      "[0.10034112 0.89965888]\n",
      "[0.15580151 0.84419849]\n",
      "[0.08315754 0.91684246]\n",
      "[0.21872734 0.78127266]\n",
      "[0.34256012 0.65743988]\n",
      "[0.31471191 0.68528809]\n",
      "[0.11907302 0.88092698]\n",
      "[0.19775697 0.80224303]\n",
      "[0.25259036 0.74740964]\n",
      "[0.35446431 0.64553569]\n",
      "[0.3679004 0.6320996]\n",
      "[0.14493363 0.85506637]\n",
      "[0.27416582 0.72583418]\n",
      "[0.23122752 0.76877248]\n",
      "[0.28746067 0.71253933]\n",
      "[0.14025645 0.85974355]\n",
      "[0.16109604 0.83890396]\n",
      "[0.17810547 0.82189453]\n",
      "[0.24628235 0.75371765]\n",
      "[0.31970625 0.68029375]\n",
      "[0.33313181 0.66686819]\n",
      "[0.21814537 0.78185463]\n",
      "[0.17801012 0.82198988]\n",
      "[0.08066027 0.91933973]\n",
      "[0.27674142 0.72325858]\n",
      "[0.26557284 0.73442716]\n",
      "[0.27962612 0.72037388]\n",
      "[0.10408911 0.89591089]\n",
      "[0.4083309 0.5916691]\n",
      "[0.25361353 0.74638647]\n",
      "[0.18923664 0.81076336]\n",
      "[0.30304132 0.69695868]\n",
      "[0.17892273 0.82107727]\n",
      "[0.18387533 0.81612467]\n",
      "[0.13656229 0.86343771]\n",
      "[0.47647884 0.52352116]\n",
      "[0.15400239 0.84599761]\n",
      "[0.17398663 0.82601337]\n",
      "[0.13324334 0.86675666]\n",
      "[0.19928624 0.80071376]\n",
      "[0.19218719 0.80781281]\n",
      "[0.16596362 0.83403638]\n",
      "[0.39856655 0.60143345]\n",
      "[0.41329136 0.58670864]\n",
      "[0.20203257 0.79796743]\n",
      "[0.28424841 0.71575159]\n",
      "[0.43551606 0.56448394]\n",
      "[0.3385997 0.6614003]\n",
      "[0.14433603 0.85566397]\n",
      "[0.19245868 0.80754132]\n",
      "[0.3064581 0.6935419]\n",
      "[0.29849218 0.70150782]\n",
      "[0.31079022 0.68920978]\n",
      "[0.1492974 0.8507026]\n",
      "[0.2306924 0.7693076]\n",
      "[0.40627299 0.59372701]\n",
      "[0.27235657 0.72764343]\n",
      "[0.42626607 0.57373393]\n",
      "[0.08854394 0.91145606]\n",
      "[0.27758711 0.72241289]\n",
      "[0.36548017 0.63451983]\n",
      "[0.30872799 0.69127201]\n",
      "[0.09482145 0.90517855]\n",
      "[0.30212984 0.69787016]\n",
      "[0.20399319 0.79600681]\n",
      "[0.26159713 0.73840287]\n",
      "[0.4098076 0.5901924]\n",
      "[0.22730386 0.77269614]\n",
      "[0.2484818 0.7515182]\n",
      "[0.24181712 0.75818288]\n",
      "[0.15367097 0.84632903]\n",
      "[0.15780336 0.84219664]\n",
      "[0.29207204 0.70792796]\n",
      "[0.07867737 0.92132263]\n",
      "[0.28067791 0.71932209]\n",
      "[0.14087127 0.85912873]\n",
      "[0.17643477 0.82356523]\n",
      "[0.46303108 0.53696892]\n",
      "[0.19048224 0.80951776]\n",
      "[0.1850227 0.8149773]\n",
      "[0.27234405 0.72765595]\n",
      "[0.3920251 0.6079749]\n",
      "[0.09864847 0.90135153]\n",
      "[0.27285674 0.72714326]\n",
      "[0.16188235 0.83811765]\n",
      "[0.24662968 0.75337032]\n",
      "[0.3694693 0.6305307]\n",
      "[0.3646181 0.6353819]\n",
      "[0.16573496 0.83426504]\n",
      "[0.39836253 0.60163747]\n",
      "[0.28862669 0.71137331]\n",
      "[0.1861061 0.8138939]\n",
      "[0.24850504 0.75149496]\n",
      "[0.17499501 0.82500499]\n",
      "[0.46749862 0.53250138]\n",
      "[0.14810597 0.85189403]\n",
      "[0.30720132 0.69279868]\n",
      "[0.16560749 0.83439251]\n",
      "[0.30183647 0.69816353]\n",
      "[0.46275999 0.53724001]\n",
      "[0.47576029 0.52423971]\n",
      "[0.1425521 0.8574479]\n",
      "[0.23362747 0.76637253]\n",
      "[0.09118521 0.90881479]\n",
      "[0.3343452 0.6656548]\n",
      "[0.14167873 0.85832127]\n",
      "[0.25648453 0.74351547]\n",
      "[0.20484021 0.79515979]\n",
      "[0.47678964 0.52321036]\n",
      "[0.11815854 0.88184146]\n",
      "[0.33560547 0.66439453]\n",
      "[0.20401912 0.79598088]\n",
      "[0.16467557 0.83532443]\n",
      "[0.21699644 0.78300356]\n",
      "[0.21598873 0.78401127]\n",
      "[0.26761146 0.73238854]\n",
      "[0.23973818 0.76026182]\n",
      "[0.22615009 0.77384991]\n",
      "[0.29873116 0.70126884]\n",
      "[0.18177458 0.81822542]\n",
      "[0.26636004 0.73363996]\n",
      "[0.38197883 0.61802117]\n",
      "[0.33606624 0.66393376]\n",
      "[0.24093169 0.75906831]\n",
      "[0.44287659 0.55712341]\n",
      "[0.27657692 0.72342308]\n",
      "[0.42208319 0.57791681]\n",
      "[0.23128691 0.76871309]\n",
      "[0.26739846 0.73260154]\n",
      "[0.08300855 0.91699145]\n",
      "[0.1834757 0.8165243]\n",
      "[0.40434866 0.59565134]\n",
      "[0.25006169 0.74993831]\n",
      "[0.16244475 0.83755525]\n",
      "[0.44317047 0.55682953]\n",
      "[0.2926114 0.7073886]\n",
      "[0.06883516 0.93116484]\n",
      "[0.18314959 0.81685041]\n",
      "[0.2904398 0.7095602]\n",
      "[0.28879824 0.71120176]\n",
      "[0.08002552 0.91997448]\n",
      "[0.4937454 0.5062546]\n",
      "[0.46588249 0.53411751]\n",
      "[0.15505906 0.84494094]\n",
      "[0.31245737 0.68754263]\n",
      "[0.16323049 0.83676951]\n",
      "[0.08250949 0.91749051]\n",
      "[0.28239636 0.71760364]\n",
      "[0.28809495 0.71190505]\n",
      "[0.30467351 0.69532649]\n",
      "[0.08251533 0.91748467]\n",
      "[0.19523756 0.80476244]\n",
      "[0.35725755 0.64274245]\n",
      "[0.32898693 0.67101307]\n",
      "[0.48969509 0.51030491]\n",
      "[0.18047293 0.81952707]\n",
      "[0.43444217 0.56555783]\n",
      "[0.08806286 0.91193714]\n",
      "[0.31368004 0.68631996]\n",
      "[0.49276497 0.50723503]\n",
      "[0.08794707 0.91205293]\n",
      "[0.14542746 0.85457254]\n",
      "[0.240482 0.759518]\n",
      "[0.4114554 0.5885446]\n",
      "[0.2088837 0.7911163]\n",
      "[0.26877492 0.73122508]\n",
      "[0.3989099 0.6010901]\n",
      "[0.35638472 0.64361528]\n",
      "[0.34872657 0.65127343]\n",
      "[0.13489459 0.86510541]\n",
      "[0.29093814 0.70906186]\n",
      "[0.28533901 0.71466099]\n",
      "[0.38333474 0.61666526]\n",
      "[0.17083363 0.82916637]\n",
      "[0.15713586 0.84286414]\n",
      "[0.31835894 0.68164106]\n",
      "[0.08706561 0.91293439]\n",
      "[0.35024831 0.64975169]\n",
      "[0.21630659 0.78369341]\n",
      "[0.2296274 0.7703726]\n",
      "[0.41361851 0.58638149]\n",
      "[0.19844562 0.80155438]\n",
      "[0.17702195 0.82297805]\n",
      "[0.34875317 0.65124683]\n",
      "[0.12094721 0.87905279]\n",
      "[0.18949821 0.81050179]\n",
      "[0.21739416 0.78260584]\n",
      "[0.24655474 0.75344526]\n",
      "[0.22044883 0.77955117]\n",
      "[0.417639 0.582361]\n",
      "[0.11783952 0.88216048]\n",
      "[0.34904295 0.65095705]\n",
      "[0.35165041 0.64834959]\n",
      "[0.29190598 0.70809402]\n",
      "[0.20535851 0.79464149]\n",
      "[0.36736014 0.63263986]\n",
      "[0.38236683 0.61763317]\n",
      "[0.36425828 0.63574172]\n",
      "[0.21436418 0.78563582]\n",
      "[0.18718741 0.81281259]\n",
      "[0.22675809 0.77324191]\n",
      "[0.16432382 0.83567618]\n",
      "[0.34656006 0.65343994]\n",
      "[0.21829696 0.78170304]\n",
      "[0.22428997 0.77571003]\n",
      "[0.41515364 0.58484636]\n",
      "[0.28859714 0.71140286]\n",
      "[0.27218346 0.72781654]\n",
      "[0.11197238 0.88802762]\n",
      "[0.1617306 0.8382694]\n",
      "[0.3794053 0.6205947]\n",
      "[0.41866758 0.58133242]\n",
      "[0.22827195 0.77172805]\n",
      "[0.13207838 0.86792162]\n",
      "[0.21369972 0.78630028]\n",
      "[0.39299077 0.60700923]\n",
      "[0.24091389 0.75908611]\n",
      "[0.28758009 0.71241991]\n",
      "[0.13684291 0.86315709]\n",
      "[0.17642597 0.82357403]\n",
      "[0.18946684 0.81053316]\n",
      "[0.29302354 0.70697646]\n",
      "[0.18101068 0.81898932]\n",
      "[0.15122324 0.84877676]\n",
      "[0.33638466 0.66361534]\n",
      "[0.14363604 0.85636396]\n",
      "[0.1826804 0.8173196]\n",
      "[0.47506425 0.52493575]\n",
      "[0.19880073 0.80119927]\n",
      "[0.31173059 0.68826941]\n",
      "[0.25545254 0.74454746]\n",
      "[0.16554368 0.83445632]\n",
      "[0.23203565 0.76796435]\n",
      "[0.12980202 0.87019798]\n",
      "[0.15222702 0.84777298]\n",
      "[0.24886428 0.75113572]\n",
      "15\n",
      "reminding: 0.9550898203592815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8025078369905956\n",
      "(334, 32, 1033)\n",
      "[0.18019778 0.81980222]\n",
      "[0.42039515 0.57960485]\n",
      "[0.23138797 0.76861203]\n",
      "[0.27833027 0.72166973]\n",
      "[0.13768129 0.86231871]\n",
      "[0.21316125 0.78683875]\n",
      "[0.46853376 0.53146624]\n",
      "[0.10034112 0.89965888]\n",
      "[0.15580151 0.84419849]\n",
      "[0.08315754 0.91684246]\n",
      "[0.21872734 0.78127266]\n",
      "[0.34256012 0.65743988]\n",
      "[0.31471191 0.68528809]\n",
      "[0.11907302 0.88092698]\n",
      "[0.19775697 0.80224303]\n",
      "[0.25259036 0.74740964]\n",
      "[0.35446431 0.64553569]\n",
      "[0.3679004 0.6320996]\n",
      "[0.14493363 0.85506637]\n",
      "[0.27416582 0.72583418]\n",
      "[0.23122752 0.76877248]\n",
      "[0.28746067 0.71253933]\n",
      "[0.14025645 0.85974355]\n",
      "[0.16109604 0.83890396]\n",
      "[0.17810547 0.82189453]\n",
      "[0.24628235 0.75371765]\n",
      "[0.31970625 0.68029375]\n",
      "[0.33313181 0.66686819]\n",
      "[0.21814537 0.78185463]\n",
      "[0.17801012 0.82198988]\n",
      "[0.08066027 0.91933973]\n",
      "[0.27674142 0.72325858]\n",
      "[0.26557284 0.73442716]\n",
      "[0.27962612 0.72037388]\n",
      "[0.10408911 0.89591089]\n",
      "[0.4083309 0.5916691]\n",
      "[0.25361353 0.74638647]\n",
      "[0.18923664 0.81076336]\n",
      "[0.30304132 0.69695868]\n",
      "[0.17892273 0.82107727]\n",
      "[0.18387533 0.81612467]\n",
      "[0.13656229 0.86343771]\n",
      "[0.47647884 0.52352116]\n",
      "[0.15400239 0.84599761]\n",
      "[0.17398663 0.82601337]\n",
      "[0.13324334 0.86675666]\n",
      "[0.19928624 0.80071376]\n",
      "[0.19218719 0.80781281]\n",
      "[0.16596362 0.83403638]\n",
      "[0.39856655 0.60143345]\n",
      "[0.41329136 0.58670864]\n",
      "[0.20203257 0.79796743]\n",
      "[0.28424841 0.71575159]\n",
      "[0.43551606 0.56448394]\n",
      "[0.3385997 0.6614003]\n",
      "[0.14433603 0.85566397]\n",
      "[0.19245868 0.80754132]\n",
      "[0.3064581 0.6935419]\n",
      "[0.29849218 0.70150782]\n",
      "[0.31079022 0.68920978]\n",
      "[0.1492974 0.8507026]\n",
      "[0.2306924 0.7693076]\n",
      "[0.40627299 0.59372701]\n",
      "[0.27235657 0.72764343]\n",
      "[0.42626607 0.57373393]\n",
      "[0.08854394 0.91145606]\n",
      "[0.27758711 0.72241289]\n",
      "[0.36548017 0.63451983]\n",
      "[0.30872799 0.69127201]\n",
      "[0.09482145 0.90517855]\n",
      "[0.30212984 0.69787016]\n",
      "[0.20399319 0.79600681]\n",
      "[0.26159713 0.73840287]\n",
      "[0.4098076 0.5901924]\n",
      "[0.22730386 0.77269614]\n",
      "[0.2484818 0.7515182]\n",
      "[0.24181712 0.75818288]\n",
      "[0.15367097 0.84632903]\n",
      "[0.15780336 0.84219664]\n",
      "[0.29207204 0.70792796]\n",
      "[0.07867737 0.92132263]\n",
      "[0.28067791 0.71932209]\n",
      "[0.14087127 0.85912873]\n",
      "[0.17643477 0.82356523]\n",
      "[0.46303108 0.53696892]\n",
      "[0.19048224 0.80951776]\n",
      "[0.1850227 0.8149773]\n",
      "[0.27234405 0.72765595]\n",
      "[0.3920251 0.6079749]\n",
      "[0.09864847 0.90135153]\n",
      "[0.27285674 0.72714326]\n",
      "[0.16188235 0.83811765]\n",
      "[0.24662968 0.75337032]\n",
      "[0.3694693 0.6305307]\n",
      "[0.3646181 0.6353819]\n",
      "[0.16573496 0.83426504]\n",
      "[0.39836253 0.60163747]\n",
      "[0.28862669 0.71137331]\n",
      "[0.1861061 0.8138939]\n",
      "[0.24850504 0.75149496]\n",
      "[0.17499501 0.82500499]\n",
      "[0.46749862 0.53250138]\n",
      "[0.14810597 0.85189403]\n",
      "[0.30720132 0.69279868]\n",
      "[0.16560749 0.83439251]\n",
      "[0.30183647 0.69816353]\n",
      "[0.46275999 0.53724001]\n",
      "[0.47576029 0.52423971]\n",
      "[0.1425521 0.8574479]\n",
      "[0.23362747 0.76637253]\n",
      "[0.09118521 0.90881479]\n",
      "[0.3343452 0.6656548]\n",
      "[0.14167873 0.85832127]\n",
      "[0.25648453 0.74351547]\n",
      "[0.20484021 0.79515979]\n",
      "[0.47678964 0.52321036]\n",
      "[0.11815854 0.88184146]\n",
      "[0.33560547 0.66439453]\n",
      "[0.20401912 0.79598088]\n",
      "[0.16467557 0.83532443]\n",
      "[0.21699644 0.78300356]\n",
      "[0.21598873 0.78401127]\n",
      "[0.26761146 0.73238854]\n",
      "[0.23973818 0.76026182]\n",
      "[0.22615009 0.77384991]\n",
      "[0.29873116 0.70126884]\n",
      "[0.18177458 0.81822542]\n",
      "[0.26636004 0.73363996]\n",
      "[0.38197883 0.61802117]\n",
      "[0.33606624 0.66393376]\n",
      "[0.24093169 0.75906831]\n",
      "[0.44287659 0.55712341]\n",
      "[0.27657692 0.72342308]\n",
      "[0.42208319 0.57791681]\n",
      "[0.23128691 0.76871309]\n",
      "[0.26739846 0.73260154]\n",
      "[0.08300855 0.91699145]\n",
      "[0.1834757 0.8165243]\n",
      "[0.40434866 0.59565134]\n",
      "[0.25006169 0.74993831]\n",
      "[0.16244475 0.83755525]\n",
      "[0.44317047 0.55682953]\n",
      "[0.2926114 0.7073886]\n",
      "[0.06883516 0.93116484]\n",
      "[0.18314959 0.81685041]\n",
      "[0.2904398 0.7095602]\n",
      "[0.28879824 0.71120176]\n",
      "[0.08002552 0.91997448]\n",
      "[0.4937454 0.5062546]\n",
      "[0.46588249 0.53411751]\n",
      "[0.15505906 0.84494094]\n",
      "[0.31245737 0.68754263]\n",
      "[0.16323049 0.83676951]\n",
      "[0.08250949 0.91749051]\n",
      "[0.28239636 0.71760364]\n",
      "[0.28809495 0.71190505]\n",
      "[0.30467351 0.69532649]\n",
      "[0.08251533 0.91748467]\n",
      "[0.19523756 0.80476244]\n",
      "[0.35725755 0.64274245]\n",
      "[0.32898693 0.67101307]\n",
      "[0.48969509 0.51030491]\n",
      "[0.18047293 0.81952707]\n",
      "[0.43444217 0.56555783]\n",
      "[0.08806286 0.91193714]\n",
      "[0.31368004 0.68631996]\n",
      "[0.49276497 0.50723503]\n",
      "[0.08794707 0.91205293]\n",
      "[0.14542746 0.85457254]\n",
      "[0.240482 0.759518]\n",
      "[0.4114554 0.5885446]\n",
      "[0.2088837 0.7911163]\n",
      "[0.26877492 0.73122508]\n",
      "[0.3989099 0.6010901]\n",
      "[0.35638472 0.64361528]\n",
      "[0.34872657 0.65127343]\n",
      "[0.13489459 0.86510541]\n",
      "[0.29093814 0.70906186]\n",
      "[0.28533901 0.71466099]\n",
      "[0.38333474 0.61666526]\n",
      "[0.17083363 0.82916637]\n",
      "[0.15713586 0.84286414]\n",
      "[0.31835894 0.68164106]\n",
      "[0.08706561 0.91293439]\n",
      "[0.35024831 0.64975169]\n",
      "[0.21630659 0.78369341]\n",
      "[0.2296274 0.7703726]\n",
      "[0.41361851 0.58638149]\n",
      "[0.19844562 0.80155438]\n",
      "[0.17702195 0.82297805]\n",
      "[0.34875317 0.65124683]\n",
      "[0.12094721 0.87905279]\n",
      "[0.18949821 0.81050179]\n",
      "[0.21739416 0.78260584]\n",
      "[0.24655474 0.75344526]\n",
      "[0.22044883 0.77955117]\n",
      "[0.417639 0.582361]\n",
      "[0.11783952 0.88216048]\n",
      "[0.34904295 0.65095705]\n",
      "[0.35165041 0.64834959]\n",
      "[0.29190598 0.70809402]\n",
      "[0.20535851 0.79464149]\n",
      "[0.36736014 0.63263986]\n",
      "[0.38236683 0.61763317]\n",
      "[0.36425828 0.63574172]\n",
      "[0.21436418 0.78563582]\n",
      "[0.18718741 0.81281259]\n",
      "[0.22675809 0.77324191]\n",
      "[0.16432382 0.83567618]\n",
      "[0.34656006 0.65343994]\n",
      "[0.21829696 0.78170304]\n",
      "[0.22428997 0.77571003]\n",
      "[0.41515364 0.58484636]\n",
      "[0.28859714 0.71140286]\n",
      "[0.27218346 0.72781654]\n",
      "[0.11197238 0.88802762]\n",
      "[0.1617306 0.8382694]\n",
      "[0.3794053 0.6205947]\n",
      "[0.41866758 0.58133242]\n",
      "[0.22827195 0.77172805]\n",
      "[0.13207838 0.86792162]\n",
      "[0.21369972 0.78630028]\n",
      "[0.39299077 0.60700923]\n",
      "[0.24091389 0.75908611]\n",
      "[0.28758009 0.71241991]\n",
      "[0.13684291 0.86315709]\n",
      "[0.17642597 0.82357403]\n",
      "[0.18946684 0.81053316]\n",
      "[0.29302354 0.70697646]\n",
      "[0.18101068 0.81898932]\n",
      "[0.15122324 0.84877676]\n",
      "[0.33638466 0.66361534]\n",
      "[0.14363604 0.85636396]\n",
      "[0.1826804 0.8173196]\n",
      "[0.47506425 0.52493575]\n",
      "[0.19880073 0.80119927]\n",
      "[0.31173059 0.68826941]\n",
      "[0.25545254 0.74454746]\n",
      "[0.16554368 0.83445632]\n",
      "[0.23203565 0.76796435]\n",
      "[0.12980202 0.87019798]\n",
      "[0.15222702 0.84777298]\n",
      "[0.24886428 0.75113572]\n",
      "39\n",
      "reminding: 0.8832335329341318\n",
      "0.8203389830508474\n",
      "(334, 32, 1033)\n",
      "[0.18019778 0.81980222]\n",
      "[0.42039515 0.57960485]\n",
      "[0.23138797 0.76861203]\n",
      "[0.27833027 0.72166973]\n",
      "[0.13768129 0.86231871]\n",
      "[0.21316125 0.78683875]\n",
      "[0.46853376 0.53146624]\n",
      "[0.10034112 0.89965888]\n",
      "[0.15580151 0.84419849]\n",
      "[0.08315754 0.91684246]\n",
      "[0.21872734 0.78127266]\n",
      "[0.34256012 0.65743988]\n",
      "[0.31471191 0.68528809]\n",
      "[0.11907302 0.88092698]\n",
      "[0.19775697 0.80224303]\n",
      "[0.25259036 0.74740964]\n",
      "[0.35446431 0.64553569]\n",
      "[0.3679004 0.6320996]\n",
      "[0.14493363 0.85506637]\n",
      "[0.27416582 0.72583418]\n",
      "[0.23122752 0.76877248]\n",
      "[0.28746067 0.71253933]\n",
      "[0.14025645 0.85974355]\n",
      "[0.16109604 0.83890396]\n",
      "[0.17810547 0.82189453]\n",
      "[0.24628235 0.75371765]\n",
      "[0.31970625 0.68029375]\n",
      "[0.33313181 0.66686819]\n",
      "[0.21814537 0.78185463]\n",
      "[0.17801012 0.82198988]\n",
      "[0.08066027 0.91933973]\n",
      "[0.27674142 0.72325858]\n",
      "[0.26557284 0.73442716]\n",
      "[0.27962612 0.72037388]\n",
      "[0.10408911 0.89591089]\n",
      "[0.4083309 0.5916691]\n",
      "[0.25361353 0.74638647]\n",
      "[0.18923664 0.81076336]\n",
      "[0.30304132 0.69695868]\n",
      "[0.17892273 0.82107727]\n",
      "[0.18387533 0.81612467]\n",
      "[0.13656229 0.86343771]\n",
      "[0.47647884 0.52352116]\n",
      "[0.15400239 0.84599761]\n",
      "[0.17398663 0.82601337]\n",
      "[0.13324334 0.86675666]\n",
      "[0.19928624 0.80071376]\n",
      "[0.19218719 0.80781281]\n",
      "[0.16596362 0.83403638]\n",
      "[0.39856655 0.60143345]\n",
      "[0.41329136 0.58670864]\n",
      "[0.20203257 0.79796743]\n",
      "[0.28424841 0.71575159]\n",
      "[0.43551606 0.56448394]\n",
      "[0.3385997 0.6614003]\n",
      "[0.14433603 0.85566397]\n",
      "[0.19245868 0.80754132]\n",
      "[0.3064581 0.6935419]\n",
      "[0.29849218 0.70150782]\n",
      "[0.31079022 0.68920978]\n",
      "[0.1492974 0.8507026]\n",
      "[0.2306924 0.7693076]\n",
      "[0.40627299 0.59372701]\n",
      "[0.27235657 0.72764343]\n",
      "[0.42626607 0.57373393]\n",
      "[0.08854394 0.91145606]\n",
      "[0.27758711 0.72241289]\n",
      "[0.36548017 0.63451983]\n",
      "[0.30872799 0.69127201]\n",
      "[0.09482145 0.90517855]\n",
      "[0.30212984 0.69787016]\n",
      "[0.20399319 0.79600681]\n",
      "[0.26159713 0.73840287]\n",
      "[0.4098076 0.5901924]\n",
      "[0.22730386 0.77269614]\n",
      "[0.2484818 0.7515182]\n",
      "[0.24181712 0.75818288]\n",
      "[0.15367097 0.84632903]\n",
      "[0.15780336 0.84219664]\n",
      "[0.29207204 0.70792796]\n",
      "[0.07867737 0.92132263]\n",
      "[0.28067791 0.71932209]\n",
      "[0.14087127 0.85912873]\n",
      "[0.17643477 0.82356523]\n",
      "[0.46303108 0.53696892]\n",
      "[0.19048224 0.80951776]\n",
      "[0.1850227 0.8149773]\n",
      "[0.27234405 0.72765595]\n",
      "[0.3920251 0.6079749]\n",
      "[0.09864847 0.90135153]\n",
      "[0.27285674 0.72714326]\n",
      "[0.16188235 0.83811765]\n",
      "[0.24662968 0.75337032]\n",
      "[0.3694693 0.6305307]\n",
      "[0.3646181 0.6353819]\n",
      "[0.16573496 0.83426504]\n",
      "[0.39836253 0.60163747]\n",
      "[0.28862669 0.71137331]\n",
      "[0.1861061 0.8138939]\n",
      "[0.24850504 0.75149496]\n",
      "[0.17499501 0.82500499]\n",
      "[0.46749862 0.53250138]\n",
      "[0.14810597 0.85189403]\n",
      "[0.30720132 0.69279868]\n",
      "[0.16560749 0.83439251]\n",
      "[0.30183647 0.69816353]\n",
      "[0.46275999 0.53724001]\n",
      "[0.47576029 0.52423971]\n",
      "[0.1425521 0.8574479]\n",
      "[0.23362747 0.76637253]\n",
      "[0.09118521 0.90881479]\n",
      "[0.3343452 0.6656548]\n",
      "[0.14167873 0.85832127]\n",
      "[0.25648453 0.74351547]\n",
      "[0.20484021 0.79515979]\n",
      "[0.47678964 0.52321036]\n",
      "[0.11815854 0.88184146]\n",
      "[0.33560547 0.66439453]\n",
      "[0.20401912 0.79598088]\n",
      "[0.16467557 0.83532443]\n",
      "[0.21699644 0.78300356]\n",
      "[0.21598873 0.78401127]\n",
      "[0.26761146 0.73238854]\n",
      "[0.23973818 0.76026182]\n",
      "[0.22615009 0.77384991]\n",
      "[0.29873116 0.70126884]\n",
      "[0.18177458 0.81822542]\n",
      "[0.26636004 0.73363996]\n",
      "[0.38197883 0.61802117]\n",
      "[0.33606624 0.66393376]\n",
      "[0.24093169 0.75906831]\n",
      "[0.44287659 0.55712341]\n",
      "[0.27657692 0.72342308]\n",
      "[0.42208319 0.57791681]\n",
      "[0.23128691 0.76871309]\n",
      "[0.26739846 0.73260154]\n",
      "[0.08300855 0.91699145]\n",
      "[0.1834757 0.8165243]\n",
      "[0.40434866 0.59565134]\n",
      "[0.25006169 0.74993831]\n",
      "[0.16244475 0.83755525]\n",
      "[0.44317047 0.55682953]\n",
      "[0.2926114 0.7073886]\n",
      "[0.06883516 0.93116484]\n",
      "[0.18314959 0.81685041]\n",
      "[0.2904398 0.7095602]\n",
      "[0.28879824 0.71120176]\n",
      "[0.08002552 0.91997448]\n",
      "[0.4937454 0.5062546]\n",
      "[0.46588249 0.53411751]\n",
      "[0.15505906 0.84494094]\n",
      "[0.31245737 0.68754263]\n",
      "[0.16323049 0.83676951]\n",
      "[0.08250949 0.91749051]\n",
      "[0.28239636 0.71760364]\n",
      "[0.28809495 0.71190505]\n",
      "[0.30467351 0.69532649]\n",
      "[0.08251533 0.91748467]\n",
      "[0.19523756 0.80476244]\n",
      "[0.35725755 0.64274245]\n",
      "[0.32898693 0.67101307]\n",
      "[0.48969509 0.51030491]\n",
      "[0.18047293 0.81952707]\n",
      "[0.43444217 0.56555783]\n",
      "[0.08806286 0.91193714]\n",
      "[0.31368004 0.68631996]\n",
      "[0.49276497 0.50723503]\n",
      "[0.08794707 0.91205293]\n",
      "[0.14542746 0.85457254]\n",
      "[0.240482 0.759518]\n",
      "[0.4114554 0.5885446]\n",
      "[0.2088837 0.7911163]\n",
      "[0.26877492 0.73122508]\n",
      "[0.3989099 0.6010901]\n",
      "[0.35638472 0.64361528]\n",
      "[0.34872657 0.65127343]\n",
      "[0.13489459 0.86510541]\n",
      "[0.29093814 0.70906186]\n",
      "[0.28533901 0.71466099]\n",
      "[0.38333474 0.61666526]\n",
      "[0.17083363 0.82916637]\n",
      "[0.15713586 0.84286414]\n",
      "[0.31835894 0.68164106]\n",
      "[0.08706561 0.91293439]\n",
      "[0.35024831 0.64975169]\n",
      "[0.21630659 0.78369341]\n",
      "[0.2296274 0.7703726]\n",
      "[0.41361851 0.58638149]\n",
      "[0.19844562 0.80155438]\n",
      "[0.17702195 0.82297805]\n",
      "[0.34875317 0.65124683]\n",
      "[0.12094721 0.87905279]\n",
      "[0.18949821 0.81050179]\n",
      "[0.21739416 0.78260584]\n",
      "[0.24655474 0.75344526]\n",
      "[0.22044883 0.77955117]\n",
      "[0.417639 0.582361]\n",
      "[0.11783952 0.88216048]\n",
      "[0.34904295 0.65095705]\n",
      "[0.35165041 0.64834959]\n",
      "[0.29190598 0.70809402]\n",
      "[0.20535851 0.79464149]\n",
      "[0.36736014 0.63263986]\n",
      "[0.38236683 0.61763317]\n",
      "[0.36425828 0.63574172]\n",
      "[0.21436418 0.78563582]\n",
      "[0.18718741 0.81281259]\n",
      "[0.22675809 0.77324191]\n",
      "[0.16432382 0.83567618]\n",
      "[0.34656006 0.65343994]\n",
      "[0.21829696 0.78170304]\n",
      "[0.22428997 0.77571003]\n",
      "[0.41515364 0.58484636]\n",
      "[0.28859714 0.71140286]\n",
      "[0.27218346 0.72781654]\n",
      "[0.11197238 0.88802762]\n",
      "[0.1617306 0.8382694]\n",
      "[0.3794053 0.6205947]\n",
      "[0.41866758 0.58133242]\n",
      "[0.22827195 0.77172805]\n",
      "[0.13207838 0.86792162]\n",
      "[0.21369972 0.78630028]\n",
      "[0.39299077 0.60700923]\n",
      "[0.24091389 0.75908611]\n",
      "[0.28758009 0.71241991]\n",
      "[0.13684291 0.86315709]\n",
      "[0.17642597 0.82357403]\n",
      "[0.18946684 0.81053316]\n",
      "[0.29302354 0.70697646]\n",
      "[0.18101068 0.81898932]\n",
      "[0.15122324 0.84877676]\n",
      "[0.33638466 0.66361534]\n",
      "[0.14363604 0.85636396]\n",
      "[0.1826804 0.8173196]\n",
      "[0.47506425 0.52493575]\n",
      "[0.19880073 0.80119927]\n",
      "[0.31173059 0.68826941]\n",
      "[0.25545254 0.74454746]\n",
      "[0.16554368 0.83445632]\n",
      "[0.23203565 0.76796435]\n",
      "[0.12980202 0.87019798]\n",
      "[0.15222702 0.84777298]\n",
      "[0.24886428 0.75113572]\n",
      "89\n",
      "reminding: 0.7335329341317365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8408163265306122\n",
      "(334, 32, 1033)\n",
      "[0.18019778 0.81980222]\n",
      "[0.42039515 0.57960485]\n",
      "[0.23138797 0.76861203]\n",
      "[0.27833027 0.72166973]\n",
      "[0.13768129 0.86231871]\n",
      "[0.21316125 0.78683875]\n",
      "[0.46853376 0.53146624]\n",
      "[0.10034112 0.89965888]\n",
      "[0.15580151 0.84419849]\n",
      "[0.08315754 0.91684246]\n",
      "[0.21872734 0.78127266]\n",
      "[0.34256012 0.65743988]\n",
      "[0.31471191 0.68528809]\n",
      "[0.11907302 0.88092698]\n",
      "[0.19775697 0.80224303]\n",
      "[0.25259036 0.74740964]\n",
      "[0.35446431 0.64553569]\n",
      "[0.3679004 0.6320996]\n",
      "[0.14493363 0.85506637]\n",
      "[0.27416582 0.72583418]\n",
      "[0.23122752 0.76877248]\n",
      "[0.28746067 0.71253933]\n",
      "[0.14025645 0.85974355]\n",
      "[0.16109604 0.83890396]\n",
      "[0.17810547 0.82189453]\n",
      "[0.24628235 0.75371765]\n",
      "[0.31970625 0.68029375]\n",
      "[0.33313181 0.66686819]\n",
      "[0.21814537 0.78185463]\n",
      "[0.17801012 0.82198988]\n",
      "[0.08066027 0.91933973]\n",
      "[0.27674142 0.72325858]\n",
      "[0.26557284 0.73442716]\n",
      "[0.27962612 0.72037388]\n",
      "[0.10408911 0.89591089]\n",
      "[0.4083309 0.5916691]\n",
      "[0.25361353 0.74638647]\n",
      "[0.18923664 0.81076336]\n",
      "[0.30304132 0.69695868]\n",
      "[0.17892273 0.82107727]\n",
      "[0.18387533 0.81612467]\n",
      "[0.13656229 0.86343771]\n",
      "[0.47647884 0.52352116]\n",
      "[0.15400239 0.84599761]\n",
      "[0.17398663 0.82601337]\n",
      "[0.13324334 0.86675666]\n",
      "[0.19928624 0.80071376]\n",
      "[0.19218719 0.80781281]\n",
      "[0.16596362 0.83403638]\n",
      "[0.39856655 0.60143345]\n",
      "[0.41329136 0.58670864]\n",
      "[0.20203257 0.79796743]\n",
      "[0.28424841 0.71575159]\n",
      "[0.43551606 0.56448394]\n",
      "[0.3385997 0.6614003]\n",
      "[0.14433603 0.85566397]\n",
      "[0.19245868 0.80754132]\n",
      "[0.3064581 0.6935419]\n",
      "[0.29849218 0.70150782]\n",
      "[0.31079022 0.68920978]\n",
      "[0.1492974 0.8507026]\n",
      "[0.2306924 0.7693076]\n",
      "[0.40627299 0.59372701]\n",
      "[0.27235657 0.72764343]\n",
      "[0.42626607 0.57373393]\n",
      "[0.08854394 0.91145606]\n",
      "[0.27758711 0.72241289]\n",
      "[0.36548017 0.63451983]\n",
      "[0.30872799 0.69127201]\n",
      "[0.09482145 0.90517855]\n",
      "[0.30212984 0.69787016]\n",
      "[0.20399319 0.79600681]\n",
      "[0.26159713 0.73840287]\n",
      "[0.4098076 0.5901924]\n",
      "[0.22730386 0.77269614]\n",
      "[0.2484818 0.7515182]\n",
      "[0.24181712 0.75818288]\n",
      "[0.15367097 0.84632903]\n",
      "[0.15780336 0.84219664]\n",
      "[0.29207204 0.70792796]\n",
      "[0.07867737 0.92132263]\n",
      "[0.28067791 0.71932209]\n",
      "[0.14087127 0.85912873]\n",
      "[0.17643477 0.82356523]\n",
      "[0.46303108 0.53696892]\n",
      "[0.19048224 0.80951776]\n",
      "[0.1850227 0.8149773]\n",
      "[0.27234405 0.72765595]\n",
      "[0.3920251 0.6079749]\n",
      "[0.09864847 0.90135153]\n",
      "[0.27285674 0.72714326]\n",
      "[0.16188235 0.83811765]\n",
      "[0.24662968 0.75337032]\n",
      "[0.3694693 0.6305307]\n",
      "[0.3646181 0.6353819]\n",
      "[0.16573496 0.83426504]\n",
      "[0.39836253 0.60163747]\n",
      "[0.28862669 0.71137331]\n",
      "[0.1861061 0.8138939]\n",
      "[0.24850504 0.75149496]\n",
      "[0.17499501 0.82500499]\n",
      "[0.46749862 0.53250138]\n",
      "[0.14810597 0.85189403]\n",
      "[0.30720132 0.69279868]\n",
      "[0.16560749 0.83439251]\n",
      "[0.30183647 0.69816353]\n",
      "[0.46275999 0.53724001]\n",
      "[0.47576029 0.52423971]\n",
      "[0.1425521 0.8574479]\n",
      "[0.23362747 0.76637253]\n",
      "[0.09118521 0.90881479]\n",
      "[0.3343452 0.6656548]\n",
      "[0.14167873 0.85832127]\n",
      "[0.25648453 0.74351547]\n",
      "[0.20484021 0.79515979]\n",
      "[0.47678964 0.52321036]\n",
      "[0.11815854 0.88184146]\n",
      "[0.33560547 0.66439453]\n",
      "[0.20401912 0.79598088]\n",
      "[0.16467557 0.83532443]\n",
      "[0.21699644 0.78300356]\n",
      "[0.21598873 0.78401127]\n",
      "[0.26761146 0.73238854]\n",
      "[0.23973818 0.76026182]\n",
      "[0.22615009 0.77384991]\n",
      "[0.29873116 0.70126884]\n",
      "[0.18177458 0.81822542]\n",
      "[0.26636004 0.73363996]\n",
      "[0.38197883 0.61802117]\n",
      "[0.33606624 0.66393376]\n",
      "[0.24093169 0.75906831]\n",
      "[0.44287659 0.55712341]\n",
      "[0.27657692 0.72342308]\n",
      "[0.42208319 0.57791681]\n",
      "[0.23128691 0.76871309]\n",
      "[0.26739846 0.73260154]\n",
      "[0.08300855 0.91699145]\n",
      "[0.1834757 0.8165243]\n",
      "[0.40434866 0.59565134]\n",
      "[0.25006169 0.74993831]\n",
      "[0.16244475 0.83755525]\n",
      "[0.44317047 0.55682953]\n",
      "[0.2926114 0.7073886]\n",
      "[0.06883516 0.93116484]\n",
      "[0.18314959 0.81685041]\n",
      "[0.2904398 0.7095602]\n",
      "[0.28879824 0.71120176]\n",
      "[0.08002552 0.91997448]\n",
      "[0.4937454 0.5062546]\n",
      "[0.46588249 0.53411751]\n",
      "[0.15505906 0.84494094]\n",
      "[0.31245737 0.68754263]\n",
      "[0.16323049 0.83676951]\n",
      "[0.08250949 0.91749051]\n",
      "[0.28239636 0.71760364]\n",
      "[0.28809495 0.71190505]\n",
      "[0.30467351 0.69532649]\n",
      "[0.08251533 0.91748467]\n",
      "[0.19523756 0.80476244]\n",
      "[0.35725755 0.64274245]\n",
      "[0.32898693 0.67101307]\n",
      "[0.48969509 0.51030491]\n",
      "[0.18047293 0.81952707]\n",
      "[0.43444217 0.56555783]\n",
      "[0.08806286 0.91193714]\n",
      "[0.31368004 0.68631996]\n",
      "[0.49276497 0.50723503]\n",
      "[0.08794707 0.91205293]\n",
      "[0.14542746 0.85457254]\n",
      "[0.240482 0.759518]\n",
      "[0.4114554 0.5885446]\n",
      "[0.2088837 0.7911163]\n",
      "[0.26877492 0.73122508]\n",
      "[0.3989099 0.6010901]\n",
      "[0.35638472 0.64361528]\n",
      "[0.34872657 0.65127343]\n",
      "[0.13489459 0.86510541]\n",
      "[0.29093814 0.70906186]\n",
      "[0.28533901 0.71466099]\n",
      "[0.38333474 0.61666526]\n",
      "[0.17083363 0.82916637]\n",
      "[0.15713586 0.84286414]\n",
      "[0.31835894 0.68164106]\n",
      "[0.08706561 0.91293439]\n",
      "[0.35024831 0.64975169]\n",
      "[0.21630659 0.78369341]\n",
      "[0.2296274 0.7703726]\n",
      "[0.41361851 0.58638149]\n",
      "[0.19844562 0.80155438]\n",
      "[0.17702195 0.82297805]\n",
      "[0.34875317 0.65124683]\n",
      "[0.12094721 0.87905279]\n",
      "[0.18949821 0.81050179]\n",
      "[0.21739416 0.78260584]\n",
      "[0.24655474 0.75344526]\n",
      "[0.22044883 0.77955117]\n",
      "[0.417639 0.582361]\n",
      "[0.11783952 0.88216048]\n",
      "[0.34904295 0.65095705]\n",
      "[0.35165041 0.64834959]\n",
      "[0.29190598 0.70809402]\n",
      "[0.20535851 0.79464149]\n",
      "[0.36736014 0.63263986]\n",
      "[0.38236683 0.61763317]\n",
      "[0.36425828 0.63574172]\n",
      "[0.21436418 0.78563582]\n",
      "[0.18718741 0.81281259]\n",
      "[0.22675809 0.77324191]\n",
      "[0.16432382 0.83567618]\n",
      "[0.34656006 0.65343994]\n",
      "[0.21829696 0.78170304]\n",
      "[0.22428997 0.77571003]\n",
      "[0.41515364 0.58484636]\n",
      "[0.28859714 0.71140286]\n",
      "[0.27218346 0.72781654]\n",
      "[0.11197238 0.88802762]\n",
      "[0.1617306 0.8382694]\n",
      "[0.3794053 0.6205947]\n",
      "[0.41866758 0.58133242]\n",
      "[0.22827195 0.77172805]\n",
      "[0.13207838 0.86792162]\n",
      "[0.21369972 0.78630028]\n",
      "[0.39299077 0.60700923]\n",
      "[0.24091389 0.75908611]\n",
      "[0.28758009 0.71241991]\n",
      "[0.13684291 0.86315709]\n",
      "[0.17642597 0.82357403]\n",
      "[0.18946684 0.81053316]\n",
      "[0.29302354 0.70697646]\n",
      "[0.18101068 0.81898932]\n",
      "[0.15122324 0.84877676]\n",
      "[0.33638466 0.66361534]\n",
      "[0.14363604 0.85636396]\n",
      "[0.1826804 0.8173196]\n",
      "[0.47506425 0.52493575]\n",
      "[0.19880073 0.80119927]\n",
      "[0.31173059 0.68826941]\n",
      "[0.25545254 0.74454746]\n",
      "[0.16554368 0.83445632]\n",
      "[0.23203565 0.76796435]\n",
      "[0.12980202 0.87019798]\n",
      "[0.15222702 0.84777298]\n",
      "[0.24886428 0.75113572]\n",
      "129\n",
      "reminding: 0.6137724550898204\n",
      "0.8536585365853658\n",
      "(334, 32, 1033)\n",
      "[0.18019778 0.81980222]\n",
      "[0.42039515 0.57960485]\n",
      "[0.23138797 0.76861203]\n",
      "[0.27833027 0.72166973]\n",
      "[0.13768129 0.86231871]\n",
      "[0.21316125 0.78683875]\n",
      "[0.46853376 0.53146624]\n",
      "[0.10034112 0.89965888]\n",
      "[0.15580151 0.84419849]\n",
      "[0.08315754 0.91684246]\n",
      "[0.21872734 0.78127266]\n",
      "[0.34256012 0.65743988]\n",
      "[0.31471191 0.68528809]\n",
      "[0.11907302 0.88092698]\n",
      "[0.19775697 0.80224303]\n",
      "[0.25259036 0.74740964]\n",
      "[0.35446431 0.64553569]\n",
      "[0.3679004 0.6320996]\n",
      "[0.14493363 0.85506637]\n",
      "[0.27416582 0.72583418]\n",
      "[0.23122752 0.76877248]\n",
      "[0.28746067 0.71253933]\n",
      "[0.14025645 0.85974355]\n",
      "[0.16109604 0.83890396]\n",
      "[0.17810547 0.82189453]\n",
      "[0.24628235 0.75371765]\n",
      "[0.31970625 0.68029375]\n",
      "[0.33313181 0.66686819]\n",
      "[0.21814537 0.78185463]\n",
      "[0.17801012 0.82198988]\n",
      "[0.08066027 0.91933973]\n",
      "[0.27674142 0.72325858]\n",
      "[0.26557284 0.73442716]\n",
      "[0.27962612 0.72037388]\n",
      "[0.10408911 0.89591089]\n",
      "[0.4083309 0.5916691]\n",
      "[0.25361353 0.74638647]\n",
      "[0.18923664 0.81076336]\n",
      "[0.30304132 0.69695868]\n",
      "[0.17892273 0.82107727]\n",
      "[0.18387533 0.81612467]\n",
      "[0.13656229 0.86343771]\n",
      "[0.47647884 0.52352116]\n",
      "[0.15400239 0.84599761]\n",
      "[0.17398663 0.82601337]\n",
      "[0.13324334 0.86675666]\n",
      "[0.19928624 0.80071376]\n",
      "[0.19218719 0.80781281]\n",
      "[0.16596362 0.83403638]\n",
      "[0.39856655 0.60143345]\n",
      "[0.41329136 0.58670864]\n",
      "[0.20203257 0.79796743]\n",
      "[0.28424841 0.71575159]\n",
      "[0.43551606 0.56448394]\n",
      "[0.3385997 0.6614003]\n",
      "[0.14433603 0.85566397]\n",
      "[0.19245868 0.80754132]\n",
      "[0.3064581 0.6935419]\n",
      "[0.29849218 0.70150782]\n",
      "[0.31079022 0.68920978]\n",
      "[0.1492974 0.8507026]\n",
      "[0.2306924 0.7693076]\n",
      "[0.40627299 0.59372701]\n",
      "[0.27235657 0.72764343]\n",
      "[0.42626607 0.57373393]\n",
      "[0.08854394 0.91145606]\n",
      "[0.27758711 0.72241289]\n",
      "[0.36548017 0.63451983]\n",
      "[0.30872799 0.69127201]\n",
      "[0.09482145 0.90517855]\n",
      "[0.30212984 0.69787016]\n",
      "[0.20399319 0.79600681]\n",
      "[0.26159713 0.73840287]\n",
      "[0.4098076 0.5901924]\n",
      "[0.22730386 0.77269614]\n",
      "[0.2484818 0.7515182]\n",
      "[0.24181712 0.75818288]\n",
      "[0.15367097 0.84632903]\n",
      "[0.15780336 0.84219664]\n",
      "[0.29207204 0.70792796]\n",
      "[0.07867737 0.92132263]\n",
      "[0.28067791 0.71932209]\n",
      "[0.14087127 0.85912873]\n",
      "[0.17643477 0.82356523]\n",
      "[0.46303108 0.53696892]\n",
      "[0.19048224 0.80951776]\n",
      "[0.1850227 0.8149773]\n",
      "[0.27234405 0.72765595]\n",
      "[0.3920251 0.6079749]\n",
      "[0.09864847 0.90135153]\n",
      "[0.27285674 0.72714326]\n",
      "[0.16188235 0.83811765]\n",
      "[0.24662968 0.75337032]\n",
      "[0.3694693 0.6305307]\n",
      "[0.3646181 0.6353819]\n",
      "[0.16573496 0.83426504]\n",
      "[0.39836253 0.60163747]\n",
      "[0.28862669 0.71137331]\n",
      "[0.1861061 0.8138939]\n",
      "[0.24850504 0.75149496]\n",
      "[0.17499501 0.82500499]\n",
      "[0.46749862 0.53250138]\n",
      "[0.14810597 0.85189403]\n",
      "[0.30720132 0.69279868]\n",
      "[0.16560749 0.83439251]\n",
      "[0.30183647 0.69816353]\n",
      "[0.46275999 0.53724001]\n",
      "[0.47576029 0.52423971]\n",
      "[0.1425521 0.8574479]\n",
      "[0.23362747 0.76637253]\n",
      "[0.09118521 0.90881479]\n",
      "[0.3343452 0.6656548]\n",
      "[0.14167873 0.85832127]\n",
      "[0.25648453 0.74351547]\n",
      "[0.20484021 0.79515979]\n",
      "[0.47678964 0.52321036]\n",
      "[0.11815854 0.88184146]\n",
      "[0.33560547 0.66439453]\n",
      "[0.20401912 0.79598088]\n",
      "[0.16467557 0.83532443]\n",
      "[0.21699644 0.78300356]\n",
      "[0.21598873 0.78401127]\n",
      "[0.26761146 0.73238854]\n",
      "[0.23973818 0.76026182]\n",
      "[0.22615009 0.77384991]\n",
      "[0.29873116 0.70126884]\n",
      "[0.18177458 0.81822542]\n",
      "[0.26636004 0.73363996]\n",
      "[0.38197883 0.61802117]\n",
      "[0.33606624 0.66393376]\n",
      "[0.24093169 0.75906831]\n",
      "[0.44287659 0.55712341]\n",
      "[0.27657692 0.72342308]\n",
      "[0.42208319 0.57791681]\n",
      "[0.23128691 0.76871309]\n",
      "[0.26739846 0.73260154]\n",
      "[0.08300855 0.91699145]\n",
      "[0.1834757 0.8165243]\n",
      "[0.40434866 0.59565134]\n",
      "[0.25006169 0.74993831]\n",
      "[0.16244475 0.83755525]\n",
      "[0.44317047 0.55682953]\n",
      "[0.2926114 0.7073886]\n",
      "[0.06883516 0.93116484]\n",
      "[0.18314959 0.81685041]\n",
      "[0.2904398 0.7095602]\n",
      "[0.28879824 0.71120176]\n",
      "[0.08002552 0.91997448]\n",
      "[0.4937454 0.5062546]\n",
      "[0.46588249 0.53411751]\n",
      "[0.15505906 0.84494094]\n",
      "[0.31245737 0.68754263]\n",
      "[0.16323049 0.83676951]\n",
      "[0.08250949 0.91749051]\n",
      "[0.28239636 0.71760364]\n",
      "[0.28809495 0.71190505]\n",
      "[0.30467351 0.69532649]\n",
      "[0.08251533 0.91748467]\n",
      "[0.19523756 0.80476244]\n",
      "[0.35725755 0.64274245]\n",
      "[0.32898693 0.67101307]\n",
      "[0.48969509 0.51030491]\n",
      "[0.18047293 0.81952707]\n",
      "[0.43444217 0.56555783]\n",
      "[0.08806286 0.91193714]\n",
      "[0.31368004 0.68631996]\n",
      "[0.49276497 0.50723503]\n",
      "[0.08794707 0.91205293]\n",
      "[0.14542746 0.85457254]\n",
      "[0.240482 0.759518]\n",
      "[0.4114554 0.5885446]\n",
      "[0.2088837 0.7911163]\n",
      "[0.26877492 0.73122508]\n",
      "[0.3989099 0.6010901]\n",
      "[0.35638472 0.64361528]\n",
      "[0.34872657 0.65127343]\n",
      "[0.13489459 0.86510541]\n",
      "[0.29093814 0.70906186]\n",
      "[0.28533901 0.71466099]\n",
      "[0.38333474 0.61666526]\n",
      "[0.17083363 0.82916637]\n",
      "[0.15713586 0.84286414]\n",
      "[0.31835894 0.68164106]\n",
      "[0.08706561 0.91293439]\n",
      "[0.35024831 0.64975169]\n",
      "[0.21630659 0.78369341]\n",
      "[0.2296274 0.7703726]\n",
      "[0.41361851 0.58638149]\n",
      "[0.19844562 0.80155438]\n",
      "[0.17702195 0.82297805]\n",
      "[0.34875317 0.65124683]\n",
      "[0.12094721 0.87905279]\n",
      "[0.18949821 0.81050179]\n",
      "[0.21739416 0.78260584]\n",
      "[0.24655474 0.75344526]\n",
      "[0.22044883 0.77955117]\n",
      "[0.417639 0.582361]\n",
      "[0.11783952 0.88216048]\n",
      "[0.34904295 0.65095705]\n",
      "[0.35165041 0.64834959]\n",
      "[0.29190598 0.70809402]\n",
      "[0.20535851 0.79464149]\n",
      "[0.36736014 0.63263986]\n",
      "[0.38236683 0.61763317]\n",
      "[0.36425828 0.63574172]\n",
      "[0.21436418 0.78563582]\n",
      "[0.18718741 0.81281259]\n",
      "[0.22675809 0.77324191]\n",
      "[0.16432382 0.83567618]\n",
      "[0.34656006 0.65343994]\n",
      "[0.21829696 0.78170304]\n",
      "[0.22428997 0.77571003]\n",
      "[0.41515364 0.58484636]\n",
      "[0.28859714 0.71140286]\n",
      "[0.27218346 0.72781654]\n",
      "[0.11197238 0.88802762]\n",
      "[0.1617306 0.8382694]\n",
      "[0.3794053 0.6205947]\n",
      "[0.41866758 0.58133242]\n",
      "[0.22827195 0.77172805]\n",
      "[0.13207838 0.86792162]\n",
      "[0.21369972 0.78630028]\n",
      "[0.39299077 0.60700923]\n",
      "[0.24091389 0.75908611]\n",
      "[0.28758009 0.71241991]\n",
      "[0.13684291 0.86315709]\n",
      "[0.17642597 0.82357403]\n",
      "[0.18946684 0.81053316]\n",
      "[0.29302354 0.70697646]\n",
      "[0.18101068 0.81898932]\n",
      "[0.15122324 0.84877676]\n",
      "[0.33638466 0.66361534]\n",
      "[0.14363604 0.85636396]\n",
      "[0.1826804 0.8173196]\n",
      "[0.47506425 0.52493575]\n",
      "[0.19880073 0.80119927]\n",
      "[0.31173059 0.68826941]\n",
      "[0.25545254 0.74454746]\n",
      "[0.16554368 0.83445632]\n",
      "[0.23203565 0.76796435]\n",
      "[0.12980202 0.87019798]\n",
      "[0.15222702 0.84777298]\n",
      "[0.24886428 0.75113572]\n",
      "168\n",
      "reminding: 0.49700598802395207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8614457831325302\n",
      "(334, 32, 1033)\n",
      "[0.18019778 0.81980222]\n",
      "[0.42039515 0.57960485]\n",
      "[0.23138797 0.76861203]\n",
      "[0.27833027 0.72166973]\n",
      "[0.13768129 0.86231871]\n",
      "[0.21316125 0.78683875]\n",
      "[0.46853376 0.53146624]\n",
      "[0.10034112 0.89965888]\n",
      "[0.15580151 0.84419849]\n",
      "[0.08315754 0.91684246]\n",
      "[0.21872734 0.78127266]\n",
      "[0.34256012 0.65743988]\n",
      "[0.31471191 0.68528809]\n",
      "[0.11907302 0.88092698]\n",
      "[0.19775697 0.80224303]\n",
      "[0.25259036 0.74740964]\n",
      "[0.35446431 0.64553569]\n",
      "[0.3679004 0.6320996]\n",
      "[0.14493363 0.85506637]\n",
      "[0.27416582 0.72583418]\n",
      "[0.23122752 0.76877248]\n",
      "[0.28746067 0.71253933]\n",
      "[0.14025645 0.85974355]\n",
      "[0.16109604 0.83890396]\n",
      "[0.17810547 0.82189453]\n",
      "[0.24628235 0.75371765]\n",
      "[0.31970625 0.68029375]\n",
      "[0.33313181 0.66686819]\n",
      "[0.21814537 0.78185463]\n",
      "[0.17801012 0.82198988]\n",
      "[0.08066027 0.91933973]\n",
      "[0.27674142 0.72325858]\n",
      "[0.26557284 0.73442716]\n",
      "[0.27962612 0.72037388]\n",
      "[0.10408911 0.89591089]\n",
      "[0.4083309 0.5916691]\n",
      "[0.25361353 0.74638647]\n",
      "[0.18923664 0.81076336]\n",
      "[0.30304132 0.69695868]\n",
      "[0.17892273 0.82107727]\n",
      "[0.18387533 0.81612467]\n",
      "[0.13656229 0.86343771]\n",
      "[0.47647884 0.52352116]\n",
      "[0.15400239 0.84599761]\n",
      "[0.17398663 0.82601337]\n",
      "[0.13324334 0.86675666]\n",
      "[0.19928624 0.80071376]\n",
      "[0.19218719 0.80781281]\n",
      "[0.16596362 0.83403638]\n",
      "[0.39856655 0.60143345]\n",
      "[0.41329136 0.58670864]\n",
      "[0.20203257 0.79796743]\n",
      "[0.28424841 0.71575159]\n",
      "[0.43551606 0.56448394]\n",
      "[0.3385997 0.6614003]\n",
      "[0.14433603 0.85566397]\n",
      "[0.19245868 0.80754132]\n",
      "[0.3064581 0.6935419]\n",
      "[0.29849218 0.70150782]\n",
      "[0.31079022 0.68920978]\n",
      "[0.1492974 0.8507026]\n",
      "[0.2306924 0.7693076]\n",
      "[0.40627299 0.59372701]\n",
      "[0.27235657 0.72764343]\n",
      "[0.42626607 0.57373393]\n",
      "[0.08854394 0.91145606]\n",
      "[0.27758711 0.72241289]\n",
      "[0.36548017 0.63451983]\n",
      "[0.30872799 0.69127201]\n",
      "[0.09482145 0.90517855]\n",
      "[0.30212984 0.69787016]\n",
      "[0.20399319 0.79600681]\n",
      "[0.26159713 0.73840287]\n",
      "[0.4098076 0.5901924]\n",
      "[0.22730386 0.77269614]\n",
      "[0.2484818 0.7515182]\n",
      "[0.24181712 0.75818288]\n",
      "[0.15367097 0.84632903]\n",
      "[0.15780336 0.84219664]\n",
      "[0.29207204 0.70792796]\n",
      "[0.07867737 0.92132263]\n",
      "[0.28067791 0.71932209]\n",
      "[0.14087127 0.85912873]\n",
      "[0.17643477 0.82356523]\n",
      "[0.46303108 0.53696892]\n",
      "[0.19048224 0.80951776]\n",
      "[0.1850227 0.8149773]\n",
      "[0.27234405 0.72765595]\n",
      "[0.3920251 0.6079749]\n",
      "[0.09864847 0.90135153]\n",
      "[0.27285674 0.72714326]\n",
      "[0.16188235 0.83811765]\n",
      "[0.24662968 0.75337032]\n",
      "[0.3694693 0.6305307]\n",
      "[0.3646181 0.6353819]\n",
      "[0.16573496 0.83426504]\n",
      "[0.39836253 0.60163747]\n",
      "[0.28862669 0.71137331]\n",
      "[0.1861061 0.8138939]\n",
      "[0.24850504 0.75149496]\n",
      "[0.17499501 0.82500499]\n",
      "[0.46749862 0.53250138]\n",
      "[0.14810597 0.85189403]\n",
      "[0.30720132 0.69279868]\n",
      "[0.16560749 0.83439251]\n",
      "[0.30183647 0.69816353]\n",
      "[0.46275999 0.53724001]\n",
      "[0.47576029 0.52423971]\n",
      "[0.1425521 0.8574479]\n",
      "[0.23362747 0.76637253]\n",
      "[0.09118521 0.90881479]\n",
      "[0.3343452 0.6656548]\n",
      "[0.14167873 0.85832127]\n",
      "[0.25648453 0.74351547]\n",
      "[0.20484021 0.79515979]\n",
      "[0.47678964 0.52321036]\n",
      "[0.11815854 0.88184146]\n",
      "[0.33560547 0.66439453]\n",
      "[0.20401912 0.79598088]\n",
      "[0.16467557 0.83532443]\n",
      "[0.21699644 0.78300356]\n",
      "[0.21598873 0.78401127]\n",
      "[0.26761146 0.73238854]\n",
      "[0.23973818 0.76026182]\n",
      "[0.22615009 0.77384991]\n",
      "[0.29873116 0.70126884]\n",
      "[0.18177458 0.81822542]\n",
      "[0.26636004 0.73363996]\n",
      "[0.38197883 0.61802117]\n",
      "[0.33606624 0.66393376]\n",
      "[0.24093169 0.75906831]\n",
      "[0.44287659 0.55712341]\n",
      "[0.27657692 0.72342308]\n",
      "[0.42208319 0.57791681]\n",
      "[0.23128691 0.76871309]\n",
      "[0.26739846 0.73260154]\n",
      "[0.08300855 0.91699145]\n",
      "[0.1834757 0.8165243]\n",
      "[0.40434866 0.59565134]\n",
      "[0.25006169 0.74993831]\n",
      "[0.16244475 0.83755525]\n",
      "[0.44317047 0.55682953]\n",
      "[0.2926114 0.7073886]\n",
      "[0.06883516 0.93116484]\n",
      "[0.18314959 0.81685041]\n",
      "[0.2904398 0.7095602]\n",
      "[0.28879824 0.71120176]\n",
      "[0.08002552 0.91997448]\n",
      "[0.4937454 0.5062546]\n",
      "[0.46588249 0.53411751]\n",
      "[0.15505906 0.84494094]\n",
      "[0.31245737 0.68754263]\n",
      "[0.16323049 0.83676951]\n",
      "[0.08250949 0.91749051]\n",
      "[0.28239636 0.71760364]\n",
      "[0.28809495 0.71190505]\n",
      "[0.30467351 0.69532649]\n",
      "[0.08251533 0.91748467]\n",
      "[0.19523756 0.80476244]\n",
      "[0.35725755 0.64274245]\n",
      "[0.32898693 0.67101307]\n",
      "[0.48969509 0.51030491]\n",
      "[0.18047293 0.81952707]\n",
      "[0.43444217 0.56555783]\n",
      "[0.08806286 0.91193714]\n",
      "[0.31368004 0.68631996]\n",
      "[0.49276497 0.50723503]\n",
      "[0.08794707 0.91205293]\n",
      "[0.14542746 0.85457254]\n",
      "[0.240482 0.759518]\n",
      "[0.4114554 0.5885446]\n",
      "[0.2088837 0.7911163]\n",
      "[0.26877492 0.73122508]\n",
      "[0.3989099 0.6010901]\n",
      "[0.35638472 0.64361528]\n",
      "[0.34872657 0.65127343]\n",
      "[0.13489459 0.86510541]\n",
      "[0.29093814 0.70906186]\n",
      "[0.28533901 0.71466099]\n",
      "[0.38333474 0.61666526]\n",
      "[0.17083363 0.82916637]\n",
      "[0.15713586 0.84286414]\n",
      "[0.31835894 0.68164106]\n",
      "[0.08706561 0.91293439]\n",
      "[0.35024831 0.64975169]\n",
      "[0.21630659 0.78369341]\n",
      "[0.2296274 0.7703726]\n",
      "[0.41361851 0.58638149]\n",
      "[0.19844562 0.80155438]\n",
      "[0.17702195 0.82297805]\n",
      "[0.34875317 0.65124683]\n",
      "[0.12094721 0.87905279]\n",
      "[0.18949821 0.81050179]\n",
      "[0.21739416 0.78260584]\n",
      "[0.24655474 0.75344526]\n",
      "[0.22044883 0.77955117]\n",
      "[0.417639 0.582361]\n",
      "[0.11783952 0.88216048]\n",
      "[0.34904295 0.65095705]\n",
      "[0.35165041 0.64834959]\n",
      "[0.29190598 0.70809402]\n",
      "[0.20535851 0.79464149]\n",
      "[0.36736014 0.63263986]\n",
      "[0.38236683 0.61763317]\n",
      "[0.36425828 0.63574172]\n",
      "[0.21436418 0.78563582]\n",
      "[0.18718741 0.81281259]\n",
      "[0.22675809 0.77324191]\n",
      "[0.16432382 0.83567618]\n",
      "[0.34656006 0.65343994]\n",
      "[0.21829696 0.78170304]\n",
      "[0.22428997 0.77571003]\n",
      "[0.41515364 0.58484636]\n",
      "[0.28859714 0.71140286]\n",
      "[0.27218346 0.72781654]\n",
      "[0.11197238 0.88802762]\n",
      "[0.1617306 0.8382694]\n",
      "[0.3794053 0.6205947]\n",
      "[0.41866758 0.58133242]\n",
      "[0.22827195 0.77172805]\n",
      "[0.13207838 0.86792162]\n",
      "[0.21369972 0.78630028]\n",
      "[0.39299077 0.60700923]\n",
      "[0.24091389 0.75908611]\n",
      "[0.28758009 0.71241991]\n",
      "[0.13684291 0.86315709]\n",
      "[0.17642597 0.82357403]\n",
      "[0.18946684 0.81053316]\n",
      "[0.29302354 0.70697646]\n",
      "[0.18101068 0.81898932]\n",
      "[0.15122324 0.84877676]\n",
      "[0.33638466 0.66361534]\n",
      "[0.14363604 0.85636396]\n",
      "[0.1826804 0.8173196]\n",
      "[0.47506425 0.52493575]\n",
      "[0.19880073 0.80119927]\n",
      "[0.31173059 0.68826941]\n",
      "[0.25545254 0.74454746]\n",
      "[0.16554368 0.83445632]\n",
      "[0.23203565 0.76796435]\n",
      "[0.12980202 0.87019798]\n",
      "[0.15222702 0.84777298]\n",
      "[0.24886428 0.75113572]\n",
      "194\n",
      "reminding: 0.41916167664670656\n",
      "0.9\n",
      "(334, 32, 1033)\n",
      "[0.18019778 0.81980222]\n",
      "[0.42039515 0.57960485]\n",
      "[0.23138797 0.76861203]\n",
      "[0.27833027 0.72166973]\n",
      "[0.13768129 0.86231871]\n",
      "[0.21316125 0.78683875]\n",
      "[0.46853376 0.53146624]\n",
      "[0.10034112 0.89965888]\n",
      "[0.15580151 0.84419849]\n",
      "[0.08315754 0.91684246]\n",
      "[0.21872734 0.78127266]\n",
      "[0.34256012 0.65743988]\n",
      "[0.31471191 0.68528809]\n",
      "[0.11907302 0.88092698]\n",
      "[0.19775697 0.80224303]\n",
      "[0.25259036 0.74740964]\n",
      "[0.35446431 0.64553569]\n",
      "[0.3679004 0.6320996]\n",
      "[0.14493363 0.85506637]\n",
      "[0.27416582 0.72583418]\n",
      "[0.23122752 0.76877248]\n",
      "[0.28746067 0.71253933]\n",
      "[0.14025645 0.85974355]\n",
      "[0.16109604 0.83890396]\n",
      "[0.17810547 0.82189453]\n",
      "[0.24628235 0.75371765]\n",
      "[0.31970625 0.68029375]\n",
      "[0.33313181 0.66686819]\n",
      "[0.21814537 0.78185463]\n",
      "[0.17801012 0.82198988]\n",
      "[0.08066027 0.91933973]\n",
      "[0.27674142 0.72325858]\n",
      "[0.26557284 0.73442716]\n",
      "[0.27962612 0.72037388]\n",
      "[0.10408911 0.89591089]\n",
      "[0.4083309 0.5916691]\n",
      "[0.25361353 0.74638647]\n",
      "[0.18923664 0.81076336]\n",
      "[0.30304132 0.69695868]\n",
      "[0.17892273 0.82107727]\n",
      "[0.18387533 0.81612467]\n",
      "[0.13656229 0.86343771]\n",
      "[0.47647884 0.52352116]\n",
      "[0.15400239 0.84599761]\n",
      "[0.17398663 0.82601337]\n",
      "[0.13324334 0.86675666]\n",
      "[0.19928624 0.80071376]\n",
      "[0.19218719 0.80781281]\n",
      "[0.16596362 0.83403638]\n",
      "[0.39856655 0.60143345]\n",
      "[0.41329136 0.58670864]\n",
      "[0.20203257 0.79796743]\n",
      "[0.28424841 0.71575159]\n",
      "[0.43551606 0.56448394]\n",
      "[0.3385997 0.6614003]\n",
      "[0.14433603 0.85566397]\n",
      "[0.19245868 0.80754132]\n",
      "[0.3064581 0.6935419]\n",
      "[0.29849218 0.70150782]\n",
      "[0.31079022 0.68920978]\n",
      "[0.1492974 0.8507026]\n",
      "[0.2306924 0.7693076]\n",
      "[0.40627299 0.59372701]\n",
      "[0.27235657 0.72764343]\n",
      "[0.42626607 0.57373393]\n",
      "[0.08854394 0.91145606]\n",
      "[0.27758711 0.72241289]\n",
      "[0.36548017 0.63451983]\n",
      "[0.30872799 0.69127201]\n",
      "[0.09482145 0.90517855]\n",
      "[0.30212984 0.69787016]\n",
      "[0.20399319 0.79600681]\n",
      "[0.26159713 0.73840287]\n",
      "[0.4098076 0.5901924]\n",
      "[0.22730386 0.77269614]\n",
      "[0.2484818 0.7515182]\n",
      "[0.24181712 0.75818288]\n",
      "[0.15367097 0.84632903]\n",
      "[0.15780336 0.84219664]\n",
      "[0.29207204 0.70792796]\n",
      "[0.07867737 0.92132263]\n",
      "[0.28067791 0.71932209]\n",
      "[0.14087127 0.85912873]\n",
      "[0.17643477 0.82356523]\n",
      "[0.46303108 0.53696892]\n",
      "[0.19048224 0.80951776]\n",
      "[0.1850227 0.8149773]\n",
      "[0.27234405 0.72765595]\n",
      "[0.3920251 0.6079749]\n",
      "[0.09864847 0.90135153]\n",
      "[0.27285674 0.72714326]\n",
      "[0.16188235 0.83811765]\n",
      "[0.24662968 0.75337032]\n",
      "[0.3694693 0.6305307]\n",
      "[0.3646181 0.6353819]\n",
      "[0.16573496 0.83426504]\n",
      "[0.39836253 0.60163747]\n",
      "[0.28862669 0.71137331]\n",
      "[0.1861061 0.8138939]\n",
      "[0.24850504 0.75149496]\n",
      "[0.17499501 0.82500499]\n",
      "[0.46749862 0.53250138]\n",
      "[0.14810597 0.85189403]\n",
      "[0.30720132 0.69279868]\n",
      "[0.16560749 0.83439251]\n",
      "[0.30183647 0.69816353]\n",
      "[0.46275999 0.53724001]\n",
      "[0.47576029 0.52423971]\n",
      "[0.1425521 0.8574479]\n",
      "[0.23362747 0.76637253]\n",
      "[0.09118521 0.90881479]\n",
      "[0.3343452 0.6656548]\n",
      "[0.14167873 0.85832127]\n",
      "[0.25648453 0.74351547]\n",
      "[0.20484021 0.79515979]\n",
      "[0.47678964 0.52321036]\n",
      "[0.11815854 0.88184146]\n",
      "[0.33560547 0.66439453]\n",
      "[0.20401912 0.79598088]\n",
      "[0.16467557 0.83532443]\n",
      "[0.21699644 0.78300356]\n",
      "[0.21598873 0.78401127]\n",
      "[0.26761146 0.73238854]\n",
      "[0.23973818 0.76026182]\n",
      "[0.22615009 0.77384991]\n",
      "[0.29873116 0.70126884]\n",
      "[0.18177458 0.81822542]\n",
      "[0.26636004 0.73363996]\n",
      "[0.38197883 0.61802117]\n",
      "[0.33606624 0.66393376]\n",
      "[0.24093169 0.75906831]\n",
      "[0.44287659 0.55712341]\n",
      "[0.27657692 0.72342308]\n",
      "[0.42208319 0.57791681]\n",
      "[0.23128691 0.76871309]\n",
      "[0.26739846 0.73260154]\n",
      "[0.08300855 0.91699145]\n",
      "[0.1834757 0.8165243]\n",
      "[0.40434866 0.59565134]\n",
      "[0.25006169 0.74993831]\n",
      "[0.16244475 0.83755525]\n",
      "[0.44317047 0.55682953]\n",
      "[0.2926114 0.7073886]\n",
      "[0.06883516 0.93116484]\n",
      "[0.18314959 0.81685041]\n",
      "[0.2904398 0.7095602]\n",
      "[0.28879824 0.71120176]\n",
      "[0.08002552 0.91997448]\n",
      "[0.4937454 0.5062546]\n",
      "[0.46588249 0.53411751]\n",
      "[0.15505906 0.84494094]\n",
      "[0.31245737 0.68754263]\n",
      "[0.16323049 0.83676951]\n",
      "[0.08250949 0.91749051]\n",
      "[0.28239636 0.71760364]\n",
      "[0.28809495 0.71190505]\n",
      "[0.30467351 0.69532649]\n",
      "[0.08251533 0.91748467]\n",
      "[0.19523756 0.80476244]\n",
      "[0.35725755 0.64274245]\n",
      "[0.32898693 0.67101307]\n",
      "[0.48969509 0.51030491]\n",
      "[0.18047293 0.81952707]\n",
      "[0.43444217 0.56555783]\n",
      "[0.08806286 0.91193714]\n",
      "[0.31368004 0.68631996]\n",
      "[0.49276497 0.50723503]\n",
      "[0.08794707 0.91205293]\n",
      "[0.14542746 0.85457254]\n",
      "[0.240482 0.759518]\n",
      "[0.4114554 0.5885446]\n",
      "[0.2088837 0.7911163]\n",
      "[0.26877492 0.73122508]\n",
      "[0.3989099 0.6010901]\n",
      "[0.35638472 0.64361528]\n",
      "[0.34872657 0.65127343]\n",
      "[0.13489459 0.86510541]\n",
      "[0.29093814 0.70906186]\n",
      "[0.28533901 0.71466099]\n",
      "[0.38333474 0.61666526]\n",
      "[0.17083363 0.82916637]\n",
      "[0.15713586 0.84286414]\n",
      "[0.31835894 0.68164106]\n",
      "[0.08706561 0.91293439]\n",
      "[0.35024831 0.64975169]\n",
      "[0.21630659 0.78369341]\n",
      "[0.2296274 0.7703726]\n",
      "[0.41361851 0.58638149]\n",
      "[0.19844562 0.80155438]\n",
      "[0.17702195 0.82297805]\n",
      "[0.34875317 0.65124683]\n",
      "[0.12094721 0.87905279]\n",
      "[0.18949821 0.81050179]\n",
      "[0.21739416 0.78260584]\n",
      "[0.24655474 0.75344526]\n",
      "[0.22044883 0.77955117]\n",
      "[0.417639 0.582361]\n",
      "[0.11783952 0.88216048]\n",
      "[0.34904295 0.65095705]\n",
      "[0.35165041 0.64834959]\n",
      "[0.29190598 0.70809402]\n",
      "[0.20535851 0.79464149]\n",
      "[0.36736014 0.63263986]\n",
      "[0.38236683 0.61763317]\n",
      "[0.36425828 0.63574172]\n",
      "[0.21436418 0.78563582]\n",
      "[0.18718741 0.81281259]\n",
      "[0.22675809 0.77324191]\n",
      "[0.16432382 0.83567618]\n",
      "[0.34656006 0.65343994]\n",
      "[0.21829696 0.78170304]\n",
      "[0.22428997 0.77571003]\n",
      "[0.41515364 0.58484636]\n",
      "[0.28859714 0.71140286]\n",
      "[0.27218346 0.72781654]\n",
      "[0.11197238 0.88802762]\n",
      "[0.1617306 0.8382694]\n",
      "[0.3794053 0.6205947]\n",
      "[0.41866758 0.58133242]\n",
      "[0.22827195 0.77172805]\n",
      "[0.13207838 0.86792162]\n",
      "[0.21369972 0.78630028]\n",
      "[0.39299077 0.60700923]\n",
      "[0.24091389 0.75908611]\n",
      "[0.28758009 0.71241991]\n",
      "[0.13684291 0.86315709]\n",
      "[0.17642597 0.82357403]\n",
      "[0.18946684 0.81053316]\n",
      "[0.29302354 0.70697646]\n",
      "[0.18101068 0.81898932]\n",
      "[0.15122324 0.84877676]\n",
      "[0.33638466 0.66361534]\n",
      "[0.14363604 0.85636396]\n",
      "[0.1826804 0.8173196]\n",
      "[0.47506425 0.52493575]\n",
      "[0.19880073 0.80119927]\n",
      "[0.31173059 0.68826941]\n",
      "[0.25545254 0.74454746]\n",
      "[0.16554368 0.83445632]\n",
      "[0.23203565 0.76796435]\n",
      "[0.12980202 0.87019798]\n",
      "[0.15222702 0.84777298]\n",
      "[0.24886428 0.75113572]\n",
      "214\n",
      "reminding: 0.3592814371257485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8916666666666667\n",
      "(334, 32, 1033)\n",
      "[0.18019778 0.81980222]\n",
      "[0.42039515 0.57960485]\n",
      "[0.23138797 0.76861203]\n",
      "[0.27833027 0.72166973]\n",
      "[0.13768129 0.86231871]\n",
      "[0.21316125 0.78683875]\n",
      "[0.46853376 0.53146624]\n",
      "[0.10034112 0.89965888]\n",
      "[0.15580151 0.84419849]\n",
      "[0.08315754 0.91684246]\n",
      "[0.21872734 0.78127266]\n",
      "[0.34256012 0.65743988]\n",
      "[0.31471191 0.68528809]\n",
      "[0.11907302 0.88092698]\n",
      "[0.19775697 0.80224303]\n",
      "[0.25259036 0.74740964]\n",
      "[0.35446431 0.64553569]\n",
      "[0.3679004 0.6320996]\n",
      "[0.14493363 0.85506637]\n",
      "[0.27416582 0.72583418]\n",
      "[0.23122752 0.76877248]\n",
      "[0.28746067 0.71253933]\n",
      "[0.14025645 0.85974355]\n",
      "[0.16109604 0.83890396]\n",
      "[0.17810547 0.82189453]\n",
      "[0.24628235 0.75371765]\n",
      "[0.31970625 0.68029375]\n",
      "[0.33313181 0.66686819]\n",
      "[0.21814537 0.78185463]\n",
      "[0.17801012 0.82198988]\n",
      "[0.08066027 0.91933973]\n",
      "[0.27674142 0.72325858]\n",
      "[0.26557284 0.73442716]\n",
      "[0.27962612 0.72037388]\n",
      "[0.10408911 0.89591089]\n",
      "[0.4083309 0.5916691]\n",
      "[0.25361353 0.74638647]\n",
      "[0.18923664 0.81076336]\n",
      "[0.30304132 0.69695868]\n",
      "[0.17892273 0.82107727]\n",
      "[0.18387533 0.81612467]\n",
      "[0.13656229 0.86343771]\n",
      "[0.47647884 0.52352116]\n",
      "[0.15400239 0.84599761]\n",
      "[0.17398663 0.82601337]\n",
      "[0.13324334 0.86675666]\n",
      "[0.19928624 0.80071376]\n",
      "[0.19218719 0.80781281]\n",
      "[0.16596362 0.83403638]\n",
      "[0.39856655 0.60143345]\n",
      "[0.41329136 0.58670864]\n",
      "[0.20203257 0.79796743]\n",
      "[0.28424841 0.71575159]\n",
      "[0.43551606 0.56448394]\n",
      "[0.3385997 0.6614003]\n",
      "[0.14433603 0.85566397]\n",
      "[0.19245868 0.80754132]\n",
      "[0.3064581 0.6935419]\n",
      "[0.29849218 0.70150782]\n",
      "[0.31079022 0.68920978]\n",
      "[0.1492974 0.8507026]\n",
      "[0.2306924 0.7693076]\n",
      "[0.40627299 0.59372701]\n",
      "[0.27235657 0.72764343]\n",
      "[0.42626607 0.57373393]\n",
      "[0.08854394 0.91145606]\n",
      "[0.27758711 0.72241289]\n",
      "[0.36548017 0.63451983]\n",
      "[0.30872799 0.69127201]\n",
      "[0.09482145 0.90517855]\n",
      "[0.30212984 0.69787016]\n",
      "[0.20399319 0.79600681]\n",
      "[0.26159713 0.73840287]\n",
      "[0.4098076 0.5901924]\n",
      "[0.22730386 0.77269614]\n",
      "[0.2484818 0.7515182]\n",
      "[0.24181712 0.75818288]\n",
      "[0.15367097 0.84632903]\n",
      "[0.15780336 0.84219664]\n",
      "[0.29207204 0.70792796]\n",
      "[0.07867737 0.92132263]\n",
      "[0.28067791 0.71932209]\n",
      "[0.14087127 0.85912873]\n",
      "[0.17643477 0.82356523]\n",
      "[0.46303108 0.53696892]\n",
      "[0.19048224 0.80951776]\n",
      "[0.1850227 0.8149773]\n",
      "[0.27234405 0.72765595]\n",
      "[0.3920251 0.6079749]\n",
      "[0.09864847 0.90135153]\n",
      "[0.27285674 0.72714326]\n",
      "[0.16188235 0.83811765]\n",
      "[0.24662968 0.75337032]\n",
      "[0.3694693 0.6305307]\n",
      "[0.3646181 0.6353819]\n",
      "[0.16573496 0.83426504]\n",
      "[0.39836253 0.60163747]\n",
      "[0.28862669 0.71137331]\n",
      "[0.1861061 0.8138939]\n",
      "[0.24850504 0.75149496]\n",
      "[0.17499501 0.82500499]\n",
      "[0.46749862 0.53250138]\n",
      "[0.14810597 0.85189403]\n",
      "[0.30720132 0.69279868]\n",
      "[0.16560749 0.83439251]\n",
      "[0.30183647 0.69816353]\n",
      "[0.46275999 0.53724001]\n",
      "[0.47576029 0.52423971]\n",
      "[0.1425521 0.8574479]\n",
      "[0.23362747 0.76637253]\n",
      "[0.09118521 0.90881479]\n",
      "[0.3343452 0.6656548]\n",
      "[0.14167873 0.85832127]\n",
      "[0.25648453 0.74351547]\n",
      "[0.20484021 0.79515979]\n",
      "[0.47678964 0.52321036]\n",
      "[0.11815854 0.88184146]\n",
      "[0.33560547 0.66439453]\n",
      "[0.20401912 0.79598088]\n",
      "[0.16467557 0.83532443]\n",
      "[0.21699644 0.78300356]\n",
      "[0.21598873 0.78401127]\n",
      "[0.26761146 0.73238854]\n",
      "[0.23973818 0.76026182]\n",
      "[0.22615009 0.77384991]\n",
      "[0.29873116 0.70126884]\n",
      "[0.18177458 0.81822542]\n",
      "[0.26636004 0.73363996]\n",
      "[0.38197883 0.61802117]\n",
      "[0.33606624 0.66393376]\n",
      "[0.24093169 0.75906831]\n",
      "[0.44287659 0.55712341]\n",
      "[0.27657692 0.72342308]\n",
      "[0.42208319 0.57791681]\n",
      "[0.23128691 0.76871309]\n",
      "[0.26739846 0.73260154]\n",
      "[0.08300855 0.91699145]\n",
      "[0.1834757 0.8165243]\n",
      "[0.40434866 0.59565134]\n",
      "[0.25006169 0.74993831]\n",
      "[0.16244475 0.83755525]\n",
      "[0.44317047 0.55682953]\n",
      "[0.2926114 0.7073886]\n",
      "[0.06883516 0.93116484]\n",
      "[0.18314959 0.81685041]\n",
      "[0.2904398 0.7095602]\n",
      "[0.28879824 0.71120176]\n",
      "[0.08002552 0.91997448]\n",
      "[0.4937454 0.5062546]\n",
      "[0.46588249 0.53411751]\n",
      "[0.15505906 0.84494094]\n",
      "[0.31245737 0.68754263]\n",
      "[0.16323049 0.83676951]\n",
      "[0.08250949 0.91749051]\n",
      "[0.28239636 0.71760364]\n",
      "[0.28809495 0.71190505]\n",
      "[0.30467351 0.69532649]\n",
      "[0.08251533 0.91748467]\n",
      "[0.19523756 0.80476244]\n",
      "[0.35725755 0.64274245]\n",
      "[0.32898693 0.67101307]\n",
      "[0.48969509 0.51030491]\n",
      "[0.18047293 0.81952707]\n",
      "[0.43444217 0.56555783]\n",
      "[0.08806286 0.91193714]\n",
      "[0.31368004 0.68631996]\n",
      "[0.49276497 0.50723503]\n",
      "[0.08794707 0.91205293]\n",
      "[0.14542746 0.85457254]\n",
      "[0.240482 0.759518]\n",
      "[0.4114554 0.5885446]\n",
      "[0.2088837 0.7911163]\n",
      "[0.26877492 0.73122508]\n",
      "[0.3989099 0.6010901]\n",
      "[0.35638472 0.64361528]\n",
      "[0.34872657 0.65127343]\n",
      "[0.13489459 0.86510541]\n",
      "[0.29093814 0.70906186]\n",
      "[0.28533901 0.71466099]\n",
      "[0.38333474 0.61666526]\n",
      "[0.17083363 0.82916637]\n",
      "[0.15713586 0.84286414]\n",
      "[0.31835894 0.68164106]\n",
      "[0.08706561 0.91293439]\n",
      "[0.35024831 0.64975169]\n",
      "[0.21630659 0.78369341]\n",
      "[0.2296274 0.7703726]\n",
      "[0.41361851 0.58638149]\n",
      "[0.19844562 0.80155438]\n",
      "[0.17702195 0.82297805]\n",
      "[0.34875317 0.65124683]\n",
      "[0.12094721 0.87905279]\n",
      "[0.18949821 0.81050179]\n",
      "[0.21739416 0.78260584]\n",
      "[0.24655474 0.75344526]\n",
      "[0.22044883 0.77955117]\n",
      "[0.417639 0.582361]\n",
      "[0.11783952 0.88216048]\n",
      "[0.34904295 0.65095705]\n",
      "[0.35165041 0.64834959]\n",
      "[0.29190598 0.70809402]\n",
      "[0.20535851 0.79464149]\n",
      "[0.36736014 0.63263986]\n",
      "[0.38236683 0.61763317]\n",
      "[0.36425828 0.63574172]\n",
      "[0.21436418 0.78563582]\n",
      "[0.18718741 0.81281259]\n",
      "[0.22675809 0.77324191]\n",
      "[0.16432382 0.83567618]\n",
      "[0.34656006 0.65343994]\n",
      "[0.21829696 0.78170304]\n",
      "[0.22428997 0.77571003]\n",
      "[0.41515364 0.58484636]\n",
      "[0.28859714 0.71140286]\n",
      "[0.27218346 0.72781654]\n",
      "[0.11197238 0.88802762]\n",
      "[0.1617306 0.8382694]\n",
      "[0.3794053 0.6205947]\n",
      "[0.41866758 0.58133242]\n",
      "[0.22827195 0.77172805]\n",
      "[0.13207838 0.86792162]\n",
      "[0.21369972 0.78630028]\n",
      "[0.39299077 0.60700923]\n",
      "[0.24091389 0.75908611]\n",
      "[0.28758009 0.71241991]\n",
      "[0.13684291 0.86315709]\n",
      "[0.17642597 0.82357403]\n",
      "[0.18946684 0.81053316]\n",
      "[0.29302354 0.70697646]\n",
      "[0.18101068 0.81898932]\n",
      "[0.15122324 0.84877676]\n",
      "[0.33638466 0.66361534]\n",
      "[0.14363604 0.85636396]\n",
      "[0.1826804 0.8173196]\n",
      "[0.47506425 0.52493575]\n",
      "[0.19880073 0.80119927]\n",
      "[0.31173059 0.68826941]\n",
      "[0.25545254 0.74454746]\n",
      "[0.16554368 0.83445632]\n",
      "[0.23203565 0.76796435]\n",
      "[0.12980202 0.87019798]\n",
      "[0.15222702 0.84777298]\n",
      "[0.24886428 0.75113572]\n",
      "231\n",
      "reminding: 0.3083832335329341\n",
      "0.8932038834951457\n"
     ]
    }
   ],
   "source": [
    "def check_good(epochs, threshold = 0.65):\n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_check_bad= cov.transform(epochs)\n",
    "    T_test = ts.transform(cov_check_bad)\n",
    "    bad = bad_catcher.predict(T_test)\n",
    "    bad_proba = bad_catcher.predict_proba(T_test)\n",
    "    for i in range(len(bad)):\n",
    "        if bad[i] == 1: \n",
    "            print(bad_proba[i])\n",
    "            if bad_proba[i,1] < threshold:\n",
    "                bad[i] = 0\n",
    "                \n",
    "    print(list(bad).count(1))\n",
    "    res = [i for i in range(epochs.shape[0]) if bad[i] == 0]\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "threshold = [1,0.9, 0.85, 0.8, 0.75, 0.7, 0.65, 0.6, 0.55]\n",
    "\n",
    "for t in threshold:\n",
    "    print(X_validation.shape)\n",
    "    ind = check_good(X_validation, t)\n",
    "\n",
    "\n",
    "    X_validation_ind = X_validation[ind]\n",
    "    print(\"reminding: {}\".format(X_validation_ind.shape[0] / X_validation.shape[0]))\n",
    "\n",
    "    y_validation_ind = y_validation[ind]\n",
    "\n",
    "\n",
    "\n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_validation= cov.transform(X_validation_ind)\n",
    "\n",
    "\n",
    "\n",
    "    y_predict = clf.predict(cov_X_validation)\n",
    "\n",
    "\n",
    "    print(sklearn.metrics.accuracy_score(y_predict, y_validation_ind))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appendix:\n",
    "    \n",
    "\n",
    "\n",
    "[(1128, 34), (1268, 32), (1090, 28), (983, 28), (608, 28), (625, 28), (833, 27), (1201, 26), (602, 25), (901, 25), (1061, 24), (771, 24), (1117, 24), (777, 24), (785, 24), (1295, 24), (680, 24), (903, 24), (724, 24), (826, 24), (296, 23), (744, 23), (247, 23), (295, 23), (1178, 23), (1155, 23), (675, 23), (470, 23), (1243, 22), (369, 22), (81, 21), (858, 21), (1185, 21), (1143, 20), (879, 20), (643, 20), (1272, 20), (1209, 20), (554, 20), (931, 20), (505, 20), (835, 20), (676, 20), (580, 20), (1286, 20), (1324, 20), (715, 20), (656, 20), (1127, 20), (1051, 20), (21, 20), (1033, 20), (723, 19), (765, 19), (254, 19), (576, 19), (738, 19), (1180, 19), (760, 19), (936, 19), (670, 19), (1115, 19), (1222, 18), (716, 18), (1182, 18), (315, 18), (839, 18), (463, 18), (1186, 18), (184, 17), (1179, 17), (836, 17), (1109, 17), (743, 17), (283, 17), (704, 16), (1247, 16), (1257, 16), (485, 16), (1314, 16), (1057, 16), (1005, 16), (944, 16), (425, 16), (472, 16), (1104, 16), (996, 16), (1161, 16), (1080, 16), (834, 16), (429, 16), (577, 16), (975, 16), (490, 16), (1015, 16), (1008, 16), (1176, 15), (838, 15), (471, 15), (825, 15), (1192, 15), (1083, 15), (755, 15), (1126, 15), (1248, 15), (874, 15), (1320, 15), (898, 15), (790, 15), (1029, 14), (244, 14), (1053, 14), (1254, 14), (518, 14), (719, 14), (599, 14), (682, 14), (831, 14), (689, 14), (1184, 14), (1242, 14), (1274, 14), (997, 14), (1049, 14), (1167, 14), (371, 13), (650, 13), (1141, 13), (655, 13), (811, 13), (1079, 13), (1043, 13), (803, 13), (1157, 12), (1018, 12), (872, 12), (354, 12), (638, 12), (717, 12), (1082, 12), (991, 12), (837, 12), (1025, 12), (37, 12), (1170, 12), (805, 12), (1211, 12), (701, 12), (786, 12), (276, 12)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[1128, 1268, 1090, 983, 833, 608, 625, 1201, 602, 901, 1061, 1117, 777, 785, 1295, 680, 903, 724, 826, 296, 771, 1178, 1155, 675, 470, 744, 247, 295, 1243, 369, 554, 858, 715, 656, 1051, 1143, 81, 879, 643, 1272, 1209, 931, 505, 835, 676, 580, 1286, 1185, 1324, 1127, 21, 1033, 765, 576, 738, 1180, 760, 670, 1222, 723, 254, 1182, 839, 936, 490, 1115, 716, 315, 743, 463, 1186, 184, 1179, 1109, 429, 283, 704, 1247, 1257, 485, 1314, 1057, 471, 1005, 944, 425, 472, 1104, 996, 836, 1161, 1126, 1080, 834, 577, 975, 1015, 1008, 244, 1176, 825, 1192, 682, 1083, 1248, 1320, 898, 790, 838, 755, 831, 1184, 874, 1242, 1274, 1029, 1053, 371, 650, 518, 719, 1141, 655, 599, 997, 1079, 1043, 1049, 1167, 503, 1254, 1211, 811, 436, 803, 1157, 1018, 872, 354, 638, 717, 1082, 991, 837, 1025, 37, 1170, 805, 701, 786]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_data = agg_epochs_std\n",
    "# labels = agg_labels\n",
    "import sklearn\n",
    "import math\n",
    "\n",
    "\n",
    "entropies = []\n",
    "for e in range(agg_epochs_std.shape[0]):\n",
    "    u, s, vh = np.linalg.svd(agg_epochs_std[e,:,:], full_matrices=True)\n",
    "    s = s/np.linalg.norm(s, ord=1)\n",
    "    svd_entropy = sum([-1*(p * math.log(p)) for p in s])\n",
    "    entropies.append(svd_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.49101796407185627\n",
      "0.4820359281437126\n",
      "0.4880239520958084\n",
      "0.47305389221556887\n",
      "0.49101796407185627\n",
      "0.4880239520958084\n",
      "0.47904191616766467\n",
      "0.5\n",
      "0.47904191616766467\n",
      "Classification accuracy: 0.487126 / Chance level: 0.500899\n"
     ]
    }
   ],
   "source": [
    "entropies = np.asarray(entropies).reshape(-1, 1)\n",
    "\n",
    "\n",
    "import sklearn \n",
    "import numpy as np\n",
    "import pyriemann.estimation\n",
    "import pyriemann.classification\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import ShuffleSplit  \n",
    "from scipy.fftpack import fft, ifft\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for train_idx, test_idx in cv.split(entropies):\n",
    "    y_train, y_test = np.asarray(agg_labels)[train_idx], np.asarray(agg_labels)[test_idx]\n",
    "    X_train = entropies[train_idx]\n",
    "    X_test = entropies[test_idx]\n",
    "        \n",
    "\n",
    "    clf = sklearn.linear_model.LogisticRegression(C=1e-5)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    y_predict = clf.predict(X_test)\n",
    "    print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "class_balance = np.mean(np.asarray(agg_labels) == np.asarray(agg_labels)[0])\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                                  class_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=3 must be between 0 and n_features=2 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-3891ad99c3a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\decomposition\\pca.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\decomposition\\pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msvd_solver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'full'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msvd_solver\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'arpack'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'randomized'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvd_solver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\decomposition\\pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[1;34m(self, X, n_components)\u001b[0m\n\u001b[0;32m    408\u001b[0m             raise ValueError(\"n_components=%r must be between 0 and \"\n\u001b[0;32m    409\u001b[0m                              \u001b[1;34m\"n_features=%r with svd_solver='full'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m                              % (n_components, n_features))\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;31m# Center data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: n_components=3 must be between 0 and n_features=2 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1335, 32, 900)\n",
      "0.7215568862275449\n",
      "(1335, 32, 900)\n",
      "0.7724550898203593\n",
      "(1335, 32, 900)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-d7f32d6c28d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTangentSpace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcov_X_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m#     clf = sklearn.linear_model.LogisticRegression()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\pyriemann\\tangentspace.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_reference_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         self.reference_ = mean_covariance(X, metric=self.metric,\n\u001b[1;32m--> 169\u001b[1;33m                                           sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    170\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtangent_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreference_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\pyriemann\\utils\\mean.py\u001b[0m in \u001b[0;36mmean_covariance\u001b[1;34m(covmats, metric, sample_weight, *args)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcovmats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_methods\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcovmats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\pyriemann\\utils\\mean.py\u001b[0m in \u001b[0;36mmean_riemann\u001b[1;34m(covmats, tol, maxiter, init, sample_weight)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCm12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcovmats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCm12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mJ\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlogm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mcrit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import pyriemann.estimation\n",
    "import pyriemann.classification\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import ShuffleSplit  \n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from pyriemann.tangentspace import FGDA, TangentSpace\n",
    "\n",
    "ind = np.linspace(0,1032, num = 900)\n",
    "ind = [int(np.floor(i)) for i in ind]\n",
    "epochs_ds = agg_epochs_std[:,:,ind]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "epochs_data = epochs_ds\n",
    "labels = agg_labels\n",
    "\n",
    "for train_idx, test_idx in cv.split(epochs_data):\n",
    "    y_train, y_test = np.asarray(labels)[train_idx], np.asarray(labels)[test_idx]\n",
    "    X_train = epochs_data[train_idx]\n",
    "    X_test = epochs_data[test_idx]\n",
    "    print(X_train.shape)\n",
    "\n",
    "    \n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    \n",
    "    ts = TangentSpace()\n",
    "    T = ts.fit_transform(cov_X_train)\n",
    "    \n",
    "#     clf = sklearn.linear_model.LogisticRegression()\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(200, ), random_state=1)\n",
    "    clf.fit(T, y_train)\n",
    "\n",
    "    \n",
    "    \n",
    "    T_test = ts.transform(cov_X_test)\n",
    "    \n",
    "    y_predict = clf.predict(T_test)\n",
    "    print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "class_balance = np.mean(np.asarray(labels) == np.asarray(labels)[0])\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1335, 32, 900)\n",
      "(1335, 51984)\n",
      "0.6317365269461078\n",
      "Classification accuracy: 0.631737 / Chance level: 0.500899\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import pyriemann.estimation\n",
    "import pyriemann.classification\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import ShuffleSplit  \n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from pyriemann.tangentspace import FGDA, TangentSpace\n",
    "\n",
    "ind = np.linspace(0,1032, num = 900)\n",
    "ind = [int(np.floor(i)) for i in ind]\n",
    "epochs_ds = agg_epochs_std[:,:,ind]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "epochs_data = epochs_ds\n",
    "labels = agg_labels\n",
    "\n",
    "for train_idx, test_idx in cv.split(epochs_data):\n",
    "    y_train, y_test = np.asarray(labels)[train_idx], np.asarray(labels)[test_idx]\n",
    "    X_train = epochs_data[train_idx]\n",
    "    X_test = epochs_data[test_idx]\n",
    "    print(X_train.shape)\n",
    "\n",
    "    \n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    \n",
    "    ts = TangentSpace()\n",
    "    T = ts.fit_transform(cov_X_train, y_train)\n",
    "    T = rkhs(T)\n",
    "    \n",
    "    print(T.shape)\n",
    "    \n",
    "    clf = sklearn.linear_model.LogisticRegression()\n",
    "    clf.fit(T, y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    T_test = ts.fit_transform(cov_X_test)\n",
    "    T_test = rkhs(T_test)\n",
    "    \n",
    "    y_predict = clf.predict(T_test)\n",
    "    print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "class_balance = np.mean(np.asarray(labels) == np.asarray(labels)[0])\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = [[1,1,2],[2,1,3]]\n",
    "# T = np.asarray(T)\n",
    "\n",
    "\n",
    "import random, math\n",
    "def polynomial(T):\n",
    "    res = []\n",
    "    n_samples, n_features = T.shape\n",
    "    for n in range(n_samples):\n",
    "        ret = []\n",
    "        for k in range(100):\n",
    "            ind = [random.uniform(0, 1) for i in range(n_features)]\n",
    "            ind = [2 if i>0.5 else 1 for i in ind]\n",
    "            s = sum([math.pow(T[n,i], ind[i]) for i in range(n_features)])\n",
    "            ret.append(s)\n",
    "        res.append(ret)\n",
    "    return np.asarray(res)\n",
    "    \n",
    "    \n",
    "    \n",
    "# res = polynomial(T)\n",
    "# res = np.asarray(res)\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "def rkhs_helper(v):\n",
    "    rkhs = []\n",
    "    for i in range(len(v)-300):\n",
    "        for j in range(len(v)-300):\n",
    "            if i == j:\n",
    "                rkhs.append(v[i]*v[j])\n",
    "            else:\n",
    "                rkhs.append(math.sqrt(2) * v[i]*v[j])\n",
    "    return rkhs\n",
    "\n",
    "\n",
    "def rkhs(T):\n",
    "    ret = []\n",
    "    for i in range(T.shape[0]):\n",
    "        ret.append(rkhs_helper(T[i]))\n",
    "    return np.asarray(ret)\n",
    "\n",
    "\n",
    "\n",
    "# print(rkhs(np.asarray([[1,2,3],[4,5,6],[1,2,3]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1335, 32, 900)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kun\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6407185628742516\n",
      "(1335, 32, 900)\n",
      "0.5568862275449101\n",
      "(1335, 32, 900)\n",
      "0.6047904191616766\n",
      "(1335, 32, 900)\n",
      "0.5988023952095808\n",
      "(1335, 32, 900)\n",
      "0.5958083832335329\n",
      "(1335, 32, 900)\n",
      "0.5598802395209581\n",
      "(1335, 32, 900)\n",
      "0.5658682634730539\n",
      "(1335, 32, 900)\n",
      "0.5598802395209581\n",
      "(1335, 32, 900)\n",
      "0.6017964071856288\n",
      "(1335, 32, 900)\n",
      "0.6137724550898204\n",
      "Classification accuracy: 0.589820 / Chance level: 0.500899\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import pyriemann.estimation\n",
    "import pyriemann.classification\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import ShuffleSplit  \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from pyriemann.tangentspace import FGDA, TangentSpace\n",
    "\n",
    "ind = np.linspace(0,1032, num = 900)\n",
    "ind = [int(np.floor(i)) for i in ind]\n",
    "epochs_ds = agg_epochs_std[:,:,ind]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "epochs_data = epochs_ds\n",
    "labels = agg_labels\n",
    "\n",
    "for train_idx, test_idx in cv.split(epochs_data):\n",
    "    y_train, y_test = np.asarray(labels)[train_idx], np.asarray(labels)[test_idx]\n",
    "    X_train = epochs_data[train_idx]\n",
    "    X_test = epochs_data[test_idx]\n",
    "    print(X_train.shape)\n",
    "\n",
    "    \n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    \n",
    "    ts = TangentSpace()\n",
    "    T = ts.fit_transform(cov_X_train, y_train)\n",
    "    \n",
    "    \n",
    "    clf = QuadraticDiscriminantAnalysis()\n",
    "    clf.fit(T, y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    T_test = ts.fit_transform(cov_X_test)\n",
    "    \n",
    "    y_predict = clf.predict(T_test)\n",
    "    print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "class_balance = np.mean(np.asarray(labels) == np.asarray(labels)[0])\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1526818432767743, 0.4054674414465533, -0.057156080501559604, -0.4054627747697755, -0.6931448472215563, -0.9444592755024624, -1.1727179274834425, -1.3862920277815018, -1.591086440427515, -1.791757135889666, -1.9924278313518173]\n"
     ]
    }
   ],
   "source": [
    "tau = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45, 0.5, 0.55]\n",
    "inter_adj = [np.log((1-t)*0.142857/(t*0.85714)) for t in tau]\n",
    "\n",
    "print(inter_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22 44 33 55 11]\n"
     ]
    }
   ],
   "source": [
    "a = [1,3,2,4,0]\n",
    "n = [11,22,33,44,55]\n",
    "print(np.asarray(n)[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
