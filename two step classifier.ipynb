{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and concatenante data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1669, 32, 1033)\n",
      "(1669,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "\n",
    "# sparse_files = ['sparse_ANM210861_20130701.npy', 'sparse_ANM210861_20130702.npy', \n",
    "#                'sparse_ANM210861_20130703.npy']\n",
    "\n",
    "# label_files = ['ANM210861_20130701_labels.npy', 'ANM210861_20130702_labels.npy',\n",
    "#               'ANM210861_20130703_labels.npy']\n",
    "\n",
    "sparse_files = ['sparse_ANM210861_20130701.npy', 'sparse_ANM210861_20130702.npy', \n",
    "               'sparse_ANM210861_20130703.npy', 'sparse_ANM210862_20130626.npy', 'sparse_ANM210862_20130627.npy', \n",
    "               'sparse_ANM210862_20130628.npy']\n",
    "\n",
    "label_files = ['ANM210861_20130701_labels.npy', 'ANM210861_20130702_labels.npy',\n",
    "              'ANM210861_20130703_labels.npy', 'ANM210862_20130626_labels.npy', 'ANM210862_20130627_labels.npy',\n",
    "              'ANM210862_20130628_labels.npy']\n",
    "\n",
    "\n",
    "agg_spares_epochs = np.load(sparse_files[0])\n",
    "agg_labels = np.load(label_files[0])\n",
    "ind = np.linspace(0,3443-1, num = 1033)\n",
    "ind = [int(np.floor(i)) for i in ind]\n",
    "agg_spares_epochs = agg_spares_epochs[:,:, ind]\n",
    "\n",
    "\n",
    "for i in range(1,6):\n",
    "    new_epochs =  np.load(sparse_files[i])\n",
    "    agg_spares_epochs = np.concatenate((agg_spares_epochs, new_epochs), axis = 0)\n",
    "    new_label = np.load(label_files[i])\n",
    "    agg_labels = np.concatenate((agg_labels, new_label), axis = 0)\n",
    "\n",
    "print(agg_spares_epochs.shape)\n",
    "print(agg_labels.shape)\n",
    "\n",
    "\n",
    "\n",
    "agg_epochs_std = copy.copy(agg_spares_epochs)\n",
    "sample_num, chan_num, timepoint = agg_spares_epochs.shape\n",
    "for c in range(chan_num):\n",
    "    original_timepoints = agg_spares_epochs[:,c,:]\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(original_timepoints)\n",
    "    chan_std = scaler.transform(original_timepoints)\n",
    "    agg_epochs_std[:,c,:] = chan_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tangent Space classifier with single SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7604790419161677\n",
      "0.7754491017964071\n",
      "0.7634730538922155\n",
      "0.7904191616766467\n",
      "0.8143712574850299\n",
      "0.7664670658682635\n",
      "0.7964071856287425\n",
      "0.8173652694610778\n",
      "0.781437125748503\n",
      "0.7844311377245509\n",
      "Classification accuracy: 0.785030 / Chance level: 0.500899\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import pyriemann.estimation\n",
    "import pyriemann.classification\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import ShuffleSplit  \n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "epochs_data = agg_epochs_std\n",
    "labels = agg_labels\n",
    "\n",
    "for train_idx, test_idx in cv.split(epochs_data):\n",
    "    y_train, y_test = np.asarray(labels)[train_idx], np.asarray(labels)[test_idx]\n",
    "    X_train = epochs_data[train_idx]\n",
    "    X_test = epochs_data[test_idx]\n",
    "\n",
    "    \n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    \n",
    "#     TSclassifier = pyriemann.classification.TSclassifier(metric='riemann', clf=sklearn.discriminant_analysis.LinearDiscriminantAnalysis())\n",
    "    TSclassifier = pyriemann.classification.TSclassifier(metric='riemann', clf=SVC(kernel='rbf', random_state=0, gamma= 0.03, C=100))\n",
    "     \n",
    "#     TSclassifier = pyriemann.classification.TSclassifier(metric='riemann', clf=LogisticRegression())\n",
    "\n",
    "    TSclassifier.fit(cov_X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_predict = TSclassifier.predict(cov_X_test)\n",
    "    print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "class_balance = np.mean(np.asarray(labels) == np.asarray(labels)[0])\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging of 21 SVM base classifiers with fine-tuned parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1065, 32, 1033)\n",
      "0.7865168539325843\n",
      "(1065, 32, 1033)\n",
      "0.7902621722846442\n",
      "(1065, 32, 1033)\n",
      "0.7902621722846442\n",
      "(1065, 32, 1033)\n",
      "0.7790262172284644\n",
      "(1065, 32, 1033)\n",
      "0.7827715355805244\n",
      "(1065, 32, 1033)\n",
      "0.7677902621722846\n",
      "(1065, 32, 1033)\n",
      "0.7827715355805244\n",
      "(1065, 32, 1033)\n",
      "0.8014981273408239\n",
      "(1065, 32, 1033)\n",
      "0.8352059925093633\n",
      "(1065, 32, 1033)\n",
      "0.7940074906367042\n",
      "(1065, 32, 1033)\n",
      "0.7715355805243446\n",
      "(1065, 32, 1033)\n",
      "0.7827715355805244\n",
      "(1065, 32, 1033)\n",
      "0.846441947565543\n",
      "(1065, 32, 1033)\n",
      "0.8202247191011236\n",
      "(1065, 32, 1033)\n",
      "0.7528089887640449\n",
      "(1065, 32, 1033)\n",
      "0.8052434456928839\n",
      "(1065, 32, 1033)\n",
      "0.7902621722846442\n",
      "(1065, 32, 1033)\n",
      "0.8127340823970037\n",
      "(1065, 32, 1033)\n",
      "0.8314606741573034\n",
      "(1065, 32, 1033)\n",
      "0.7715355805243446\n",
      "(1065, 32, 1033)\n",
      "0.7677902621722846\n",
      "(1065, 32, 1033)\n",
      "0.8052434456928839\n",
      "(1065, 32, 1033)\n",
      "0.8202247191011236\n",
      "(1065, 32, 1033)\n",
      "0.8127340823970037\n",
      "(1065, 32, 1033)\n",
      "0.8014981273408239\n",
      "(1065, 32, 1033)\n",
      "0.8014981273408239\n",
      "(1065, 32, 1033)\n",
      "0.7940074906367042\n",
      "(1065, 32, 1033)\n",
      "0.8014981273408239\n",
      "(1065, 32, 1033)\n",
      "0.7865168539325843\n",
      "(1065, 32, 1033)\n",
      "0.7827715355805244\n",
      "(1065, 32, 1033)\n",
      "0.797752808988764\n",
      "(1065, 32, 1033)\n",
      "0.8089887640449438\n",
      "(1065, 32, 1033)\n",
      "0.8014981273408239\n",
      "(1065, 32, 1033)\n",
      "0.8277153558052435\n",
      "(1065, 32, 1033)\n",
      "0.7528089887640449\n",
      "(1065, 32, 1033)\n",
      "0.7940074906367042\n",
      "(1065, 32, 1033)\n",
      "0.7902621722846442\n",
      "(1065, 32, 1033)\n",
      "0.7827715355805244\n",
      "(1065, 32, 1033)\n",
      "0.7865168539325843\n",
      "(1065, 32, 1033)\n",
      "0.7752808988764045\n",
      "(1065, 32, 1033)\n",
      "0.8314606741573034\n",
      "(1065, 32, 1033)\n",
      "0.8052434456928839\n",
      "(1065, 32, 1033)\n",
      "0.8052434456928839\n",
      "(1065, 32, 1033)\n",
      "0.8164794007490637\n",
      "(1065, 32, 1033)\n",
      "0.7528089887640449\n",
      "(1065, 32, 1033)\n",
      "0.8089887640449438\n",
      "(1065, 32, 1033)\n",
      "0.7790262172284644\n",
      "(1065, 32, 1033)\n",
      "0.8089887640449438\n",
      "(1065, 32, 1033)\n",
      "0.7640449438202247\n",
      "(1065, 32, 1033)\n",
      "0.8052434456928839\n",
      "Classification accuracy: 0.795281 / Chance level: 0.490991\n"
     ]
    }
   ],
   "source": [
    "import sklearn \n",
    "import pyriemann.estimation\n",
    "import pyriemann.classification\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import ShuffleSplit  \n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "\n",
    "\n",
    "\n",
    "n_estimator = 21\n",
    "n_samples, _,_ = agg_epochs_std.shape\n",
    "labels = agg_labels[:(n_samples//5 * 4)]\n",
    "\n",
    "agg_epochs_std_train_test = agg_epochs_std[:(n_samples//5 * 4),:,:]\n",
    "epochs_data = agg_epochs_std_train_test\n",
    "\n",
    "wrong = []\n",
    "\n",
    "for train_idx, test_idx in cv.split(epochs_data):\n",
    "    y_train, y_test = np.asarray(labels)[train_idx], np.asarray(labels)[test_idx]\n",
    "    X_train = epochs_data[train_idx]\n",
    "    X_test = epochs_data[test_idx]\n",
    "    print(X_train.shape)\n",
    "\n",
    "    \n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    \n",
    "    n_samples, _,_ = cov_X_train.shape\n",
    "    subset_size = n_samples//3 * 2\n",
    "    \n",
    "    ind_sets = [np.random.randint(0, n_samples, size = subset_size) for i in range(n_estimator)]\n",
    "    \n",
    "    clfs = [pyriemann.classification.TSclassifier(metric='riemann', clf=SVC(kernel='rbf', random_state=0, gamma= 0.03, C=100, probability=True)) for i in range(n_estimator)]\n",
    "\n",
    "    for i in range(n_estimator):\n",
    "        clfs[i].fit(cov_X_train[ind_sets[i],:,:], y_train[ind_sets[i]])\n",
    "    \n",
    "    y_predict = [clfs[i].predict(cov_X_test) for i in range(n_estimator)]\n",
    "    y_predict = scipy.stats.mode(y_predict, axis=0).mode[0]\n",
    "    \n",
    "\n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "    print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "    wrong.append([test_idx[i] for i in range(len(y_test)) if y_predict[i] != y_test[i]])\n",
    "\n",
    "class_balance = np.mean(np.asarray(labels) == np.asarray(labels)[0])\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick out the channel that were repeatedly classified wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(608, 21), (1128, 16), (744, 16), (831, 16), (1143, 15), (1090, 15), (1268, 15), (625, 15), (901, 15), (1178, 14), (276, 14), (834, 14), (302, 14), (975, 14), (983, 13), (1243, 13), (879, 13), (1117, 13), (765, 13), (643, 13), (1272, 13), (1176, 13), (1257, 13), (833, 13), (1005, 13), (825, 13), (1155, 13), (658, 13), (656, 13), (847, 13), (296, 12), (1325, 12), (1254, 12), (785, 12), (1051, 12), (931, 12), (1295, 12), (803, 12), (315, 12), (724, 12), (1161, 12), (1201, 12), (1061, 11), (1179, 11), (650, 11), (838, 11), (295, 11), (978, 11), (719, 11), (1115, 11), (711, 11), (835, 11), (37, 11), (680, 11), (836, 11), (760, 11), (538, 11), (429, 11), (1312, 11), (21, 11), (1033, 11), (997, 11), (754, 11), (662, 11), (1043, 11), (1271, 11), (704, 10), (503, 10), (771, 10), (665, 10), (254, 10), (1209, 10), (717, 10), (602, 10), (858, 10), (991, 10), (837, 10), (805, 10), (1180, 10), (472, 10), (903, 10), (697, 10), (1104, 10), (996, 10), (839, 10), (1228, 10), (715, 10), (470, 10), (577, 10), (1242, 10), (283, 10), (1049, 10), (1015, 10), (667, 10), (701, 10), (750, 10), (1247, 9), (739, 9), (115, 9), (1157, 9), (247, 9), (777, 9), (354, 9), (371, 9), (1057, 9), (505, 9), (1065, 9), (576, 9), (1083, 9), (851, 9), (1080, 9), (359, 9), (936, 9), (679, 9), (1127, 9), (826, 9), (1248, 9), (918, 9), (1148, 9), (892, 9), (743, 9), (898, 9), (989, 9), (670, 9), (287, 9), (726, 9), (981, 9), (1297, 8), (946, 8), (1053, 8), (638, 8), (1098, 8), (797, 8), (1141, 8), (1076, 8), (334, 8), (1170, 8), (676, 8), (580, 8), (655, 8), (599, 8), (1182, 8), (675, 8), (877, 8), (436, 8), (1200, 8), (463, 8), (423, 8), (369, 8), (1153, 8)]\n",
      "[608, 1128, 744, 831, 1143, 1090, 1268, 625, 901, 1178, 276, 834, 302, 975, 983, 1243, 879, 1117, 765, 643, 1272, 1176, 1257, 833, 1005, 825, 1155, 658, 656, 847, 296, 1325, 1254, 785, 1051, 931, 1295, 803, 315, 724, 1161, 1201, 1061, 1179, 650, 838, 295, 978, 719, 1115, 711, 835, 37, 680, 836, 760, 538, 429, 1312, 21, 1033, 997, 754, 662, 1043, 1271, 704, 503, 771, 665, 254, 1209, 717, 602, 858, 991, 837, 805, 1180, 472, 903, 697, 1104, 996, 839, 1228, 715, 470, 577, 1242, 283, 1049, 1015, 667, 701, 750, 1247, 739, 115, 1157, 247, 777, 354, 371, 1057, 505, 1065, 576, 1083, 851, 1080, 359, 936, 679, 1127, 826, 1248, 918, 1148, 892, 743, 898, 989, 670, 287, 726, 981, 1297, 946, 1053, 638, 1098, 797, 1141, 1076, 334, 1170, 676, 580, 655, 599, 1182, 675, 877, 436, 1200, 463, 423, 369, 1153]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "result = result + sum(wrong, [])\n",
    "from collections import Counter\n",
    "l = [i[0] for i in list(Counter(result).most_common(150))]\n",
    "print(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training another classifier to classify \"good\" epochs and \"bad\" epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9378238341968912\n",
      "0.9067357512953368\n",
      "0.9222797927461139\n",
      "0.8808290155440415\n",
      "0.9015544041450777\n",
      "0.8963730569948186\n",
      "0.9222797927461139\n",
      "0.8963730569948186\n",
      "0.9119170984455959\n",
      "0.9067357512953368\n",
      "Classification accuracy: 0.908290 / Chance level: 0.844237\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct = [i for i in np.random.randint(0,(n_samples//5 * 4),900) if i not in l]\n",
    "bad = l\n",
    "ind = correct + bad\n",
    "X = agg_epochs_std_train_test[ind]\n",
    "y = [0 for i in range(len(correct))] + [1 for i in range(len(bad))] \n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "epochs_data = X\n",
    "labels = y\n",
    "\n",
    "\n",
    "for train_idx, test_idx in cv.split(epochs_data):\n",
    "    y_train, y_test = np.asarray(labels)[train_idx], np.asarray(labels)[test_idx]\n",
    "    X_train = epochs_data[train_idx]\n",
    "    X_test = epochs_data[test_idx]\n",
    "\n",
    "    \n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    \n",
    "    \n",
    "    bad_catcher = pyriemann.classification.TSclassifier(metric='riemann')\n",
    "    bad_catcher.fit(cov_X_train, y_train)\n",
    "    y_predict = bad_catcher.predict(cov_X_test)\n",
    "    print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "class_balance = np.mean(np.asarray(labels) == np.asarray(labels)[0])\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two stag classifer on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(817, 32, 1033)\n",
      "(56, 32, 1033)\n",
      "0.9107142857142857\n"
     ]
    }
   ],
   "source": [
    "def check_good(epochs):\n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    bad = bad_catcher.predict(cov.transform(epochs))\n",
    "    bad_proba = bad_catcher.predict_proba(cov.transform(epochs))\n",
    "\n",
    "    for i in range(len(bad)):\n",
    "        if bad[i] == 1: \n",
    "            if bad_proba[i,1] < 0.4:\n",
    "                bad[i] = 0\n",
    "                      \n",
    "    res = [i for i in range(epochs.shape[0]) if bad[i] == 0]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "label_validation = agg_labels[(n_samples//5 * 4):]\n",
    "X_validation = agg_epochs_std[(n_samples//5 * 4):,:,:]\n",
    "print(X_validation.shape)\n",
    "ind = check_good(X_validation)\n",
    "\n",
    "\n",
    "X_validation = X_validation[ind]\n",
    "label_validation = label_validation[ind]\n",
    "print(X_validation.shape)\n",
    "\n",
    "cov =  pyriemann.estimation.Covariances('lwf')\n",
    "cov_X_validation= cov.transform(X_validation)\n",
    "\n",
    "\n",
    "y_predict = [clfs[i].predict(cov_X_validation) for i in range(n_estimator)]\n",
    "y_predict = scipy.stats.mode(y_predict, axis=0).mode[0]\n",
    "\n",
    "\n",
    "print(sklearn.metrics.accuracy_score(y_predict,  label_validation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appendix:\n",
    "    \n",
    "[(608, 21), (1128, 16), (744, 16), (831, 16), (1143, 15), (1090, 15), (1268, 15), (625, 15), (901, 15), (1178, 14), (276, 14), (834, 14), (302, 14), (975, 14), (983, 13), (1243, 13), (879, 13), (1117, 13), (765, 13), (643, 13), (1272, 13), (1176, 13), (1257, 13), (833, 13), (1005, 13), (825, 13), (1155, 13), (658, 13), (656, 13), (847, 13), (296, 12), (1325, 12), (1254, 12), (785, 12), (1051, 12), (931, 12), (1295, 12), (803, 12), (315, 12), (724, 12), (1161, 12), (1201, 12), (1061, 11), (1179, 11), (650, 11), (838, 11), (295, 11), (978, 11), (719, 11), (1115, 11), (711, 11), (835, 11), (37, 11), (680, 11), (836, 11), (760, 11), (538, 11), (429, 11), (1312, 11), (21, 11), (1033, 11), (997, 11), (754, 11), (662, 11), (1043, 11), (1271, 11), (704, 10), (503, 10), (771, 10), (665, 10), (254, 10), (1209, 10), (717, 10), (602, 10), (858, 10), (991, 10), (837, 10), (805, 10), (1180, 10), (472, 10), (903, 10), (697, 10), (1104, 10), (996, 10), (839, 10), (1228, 10), (715, 10), (470, 10), (577, 10), (1242, 10), (283, 10), (1049, 10), (1015, 10), (667, 10), (701, 10), (750, 10), (1247, 9), (739, 9), (115, 9), (1157, 9), (247, 9), (777, 9), (354, 9), (371, 9), (1057, 9), (505, 9), (1065, 9), (576, 9), (1083, 9), (851, 9), (1080, 9), (359, 9), (936, 9), (679, 9), (1127, 9), (826, 9), (1248, 9), (918, 9), (1148, 9), (892, 9), (743, 9), (898, 9), (989, 9), (670, 9), (287, 9), (726, 9), (981, 9), (1297, 8), (946, 8), (1053, 8), (638, 8), (1098, 8), (797, 8), (1141, 8), (1076, 8), (334, 8), (1170, 8), (676, 8), (580, 8), (655, 8), (599, 8), (1182, 8), (675, 8), (877, 8), (436, 8), (1200, 8), (463, 8), (423, 8), (369, 8), (1153, 8)]\n",
    "[608, 1128, 744, 831, 1143, 1090, 1268, 625, 901, 1178, 276, 834, 302, 975, 983, 1243, 879, 1117, 765, 643, 1272, 1176, 1257, 833, 1005, 825, 1155, 658, 656, 847, 296, 1325, 1254, 785, 1051, 931, 1295, 803, 315, 724, 1161, 1201, 1061, 1179, 650, 838, 295, 978, 719, 1115, 711, 835, 37, 680, 836, 760, 538, 429, 1312, 21, 1033, 997, 754, 662, 1043, 1271, 704, 503, 771, 665, 254, 1209, 717, 602, 858, 991, 837, 805, 1180, 472, 903, 697, 1104, 996, 839, 1228, 715, 470, 577, 1242, 283, 1049, 1015, 667, 701, 750, 1247, 739, 115, 1157, 247, 777, 354, 371, 1057, 505, 1065, 576, 1083, 851, 1080, 359, 936, 679, 1127, 826, 1248, 918, 1148, 892, 743, 898, 989, 670, 287, 726, 981, 1297, 946, 1053, 638, 1098, 797, 1141, 1076, 334, 1170, 676, 580, 655, 599, 1182, 675, 877, 436, 1200, 463, 423, 369, 1153]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
