{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# use %%capture command to suppress output for this cell\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#initializing training samples and labels\n",
    "#epochs will be concatenated\n",
    "epochs_total = np.zeros(1)\n",
    "labels_total = np.zeros(1)\n",
    "epochs_train_total = np.zeros(1)\n",
    "\n",
    "\n",
    "#Using data taken from 108 different people, each performing various MI tasks. In this experiment, we are trying to \n",
    "#classify motor imagery of hands vs. feet, only run 6, 10, 14 are relevant\n",
    "epoch_size = []\n",
    "for i in range(108):\n",
    "    print(str(i))\n",
    "    if (i == 87) or (i == 91) or (i == 99):\n",
    "        continue\n",
    "    subject = i+1\n",
    "#     runs = [6, 10, 14] \n",
    "    runs = [4, 8, 12] \n",
    "    \n",
    "    #the 3 lines below are taken from mne website\n",
    "    #reading eeg files and concatenate them into one file\n",
    "    raw_fnames = mne.datasets.eegbci.load_data(subject, runs)\n",
    "    raw_files = [mne.io.read_raw_edf(f, preload=True, stim_channel='auto') for f in\n",
    "                 raw_fnames]\n",
    "    raw = mne.io.concatenate_raws(raw_files)\n",
    "    raw.rename_channels(lambda x: x.strip('.'))\n",
    "\n",
    "    #We can print the names of all 64 electrode channels, but only some of them are \n",
    "    #relevant to motor imagery.\n",
    "    #The relevant channels are FC5, FC3, C5, C3, CP5, CP3, FP2, FC4, FC6, C4\n",
    "    print(raw.ch_names)\n",
    "    \n",
    "    #Electrode relevant to right hand MI: FC5, FC3, C5, C3, CP5, CP3\n",
    "    right_hand = np.array([0,1,7,8,14,15])\n",
    "    #Electrode relevant to left hand MI: FC2, FC4, FC6, C4\n",
    "    left_hand = np.array([23, 5, 6, 12])\n",
    "    \n",
    "    \n",
    "    #print the channel names to verify we got the right ones\n",
    "    for i in right_hand:\n",
    "        print(raw.ch_names[i])\n",
    "    \n",
    "    for i in left_hand:\n",
    "        print(raw.ch_names[i])\n",
    "\n",
    "        \n",
    "        \n",
    "    #Since it is shown motor imagery will change the mu band (8 -13 Hz) and beta band (13 - 25 Hz), we want to \n",
    "    #filter out the noise by applying a band pass filter\n",
    "    \n",
    "    \n",
    "#     raw.filter(7., 30., fir_design='firwin', skip_by_annotation='edge')\n",
    "\n",
    "    \n",
    "    #the next four lines make raw data into epochs for training\n",
    "    #The time points when stimuli was presented in front of the experimental subjects \n",
    "    #are recorded in stim channel. We take a second before the stimuli happened and four seconds\n",
    "    #afterward.\n",
    "    #passing these parameter into mne.Epochs\n",
    "    events = mne.find_events(raw, shortest_event=0, stim_channel='STI 014')\n",
    "    picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                       exclude='bads')\n",
    "    tmin, tmax = -1., 4.\n",
    "    event_id = dict(hands=2, feet=3)\n",
    "    epochs = mne.Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks,\n",
    "                    baseline=None, preload=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Since right after the stimuli the eeg might not be pure motor imagery\n",
    "    #only take the 1-2 seconds after as training data\n",
    "    epochs_train = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "    epochs_train = epochs_train.get_data()\n",
    "    \n",
    "    \n",
    "    epoch_size.append(epochs_train.shape[0])\n",
    "    labels = epochs.events[:, -1] - 2\n",
    "\n",
    "    \n",
    "    \n",
    "    #the section below simply concatenate all epochs into one ndarray\n",
    "    epochs_data = epochs.get_data()\n",
    "    if epochs_total.size == 1:\n",
    "        epochs_total = epochs_data\n",
    "    else:\n",
    "        epochs_total = np.concatenate((epochs_total, epochs_data), axis = 0)\n",
    "    \n",
    "    if labels_total.size == 1:\n",
    "        labels_total = labels\n",
    "    else:\n",
    "        labels_total = np.concatenate((labels_total, labels), axis = 0)\n",
    "        \n",
    "        \n",
    "    if epochs_train_total.size == 1:\n",
    "        epochs_train_total = epochs_train\n",
    "    else:\n",
    "        epochs_train_total = np.concatenate((epochs_train_total, epochs_train), axis = 0)\n",
    "        \n",
    "    print(\"total epoch shape:  \" + str(epochs_train_total.shape))\n",
    "\n",
    "        \n",
    "#printing the shape of the samples and labels to make sure they make sense\n",
    "print(epochs_total.shape)\n",
    "print(labels_total.shape)\n",
    "print(epochs_train_total.shape)\n",
    "\n",
    "\n",
    "#Please ignore the error message below. This is due to corrupted #89 dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw.ch_names[8])\n",
    "print(raw.ch_names[10])\n",
    "print(raw.ch_names[12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_index = [0]\n",
    "ind = 0\n",
    "for e_size in epoch_size:\n",
    "    ind = ind + e_size\n",
    "    e_index.append(ind)\n",
    "\n",
    "    \n",
    "print(e_index)\n",
    "\n",
    "#3762 + 941"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import numpy as np\n",
    "import pyriemann.estimation\n",
    "import pyriemann.classification\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "scores = []\n",
    "epochs_data = epochs_train_total[:150, :]\n",
    "\n",
    "for train_idx, test_idx in cv.split(labels_total[:150]):\n",
    "    y_train, y_test = labels_total[train_idx], labels_total[test_idx]\n",
    "    X_train = epochs_data[train_idx]\n",
    "    X_test = epochs_data[test_idx]\n",
    "\n",
    "    \n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    \n",
    "    TSclassifier = pyriemann.classification.TSclassifier(metric='riemann')\n",
    "    TSclassifier.fit(cov_X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_predict = TSclassifier.predict(cov_X_test)\n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below is a function that takes the upper half of a matrix and put them in an array\n",
    "def takeupper(m):\n",
    "    print(m.shape)\n",
    "    ret = []\n",
    "    for k in range(m.shape[0]):\n",
    "        row = []\n",
    "        for i in range(m.shape[1]):\n",
    "            for j in range(i):\n",
    "                row.append(m[k][i][j])\n",
    "        ret.append(row)\n",
    "    return np.array(ret)\n",
    "\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10)\n",
    "scores = []\n",
    "epochs_data = epochs_train_total\n",
    "clf = sklearn.discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "labels = labels_total\n",
    "\n",
    "for train_idx, test_idx in cv.split(labels):\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "    X_train = epochs_data[train_idx][:,index]\n",
    "    X_test = epochs_data[test_idx][:,index]\n",
    "\n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    \n",
    "    #take the covariance matrix of input signal, then only take the upper half to avoid dupplicate\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    X_tr = takeupper(cov_X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    X_ts = takeupper(cov_X_test)\n",
    "    \n",
    "\n",
    "    clf.fit(X_tr, y_train)\n",
    "    y_predict = clf.predict(X_ts)\n",
    "    scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "    \n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                          class_balance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the part below a CNN will be built to detect patterns in the covariance matrix of the EEG signal. \n",
    "\n",
    "Since only 10 channels are relevant to motor imagery, the input data size is 3115 X 10 X 10 (sample, num_channel, num_channel)\n",
    "\n",
    "The first two layers are convolutional layers. The kernel size is set to be 3X3. There are 8 filters at each layer. Since each element in the covariance matrix could provide useful information, and the size is only 10 X 10, no max pooling layer is added.\n",
    "\n",
    "The batch size is set to be 128, and epoch set to be 4. Tuning batch size does not seem to improve the result.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import ShuffleSplit  \n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import pyriemann.estimation\n",
    "\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "scores = []\n",
    "\n",
    "\n",
    "#Using only the 10 relevant channels instead of 64 channels.\n",
    "index = np.concatenate((left_hand, right_hand))\n",
    "\n",
    "epochs_data = epochs_train_total\n",
    "labels = labels_total\n",
    "\n",
    "print(epochs_data.shape)\n",
    "\n",
    "\n",
    "\n",
    "for train_idx, test_idx in cv.split(labels):\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "    X_train = epochs_data[train_idx][:,index]\n",
    "    X_test = epochs_data[test_idx][:,index]\n",
    "    cov =  pyriemann.estimation.Covariances('lwf')\n",
    "    cov_X_train = cov.transform(X_train)\n",
    "    cov_X_test = cov.transform(X_test)\n",
    "    \n",
    "    print(\"the shape of cov matrix is {}\".format(cov_X_train.shape))\n",
    "\n",
    "    num_train = cov_X_train.shape[0]\n",
    "    num_test = cov_X_test.shape[0]\n",
    "    \n",
    "    cov_X_train = cov_X_train.reshape(num_train, 1, 10, 10)\n",
    "    cov_X_test = cov_X_test.reshape(num_test, 1, 10, 10)\n",
    "\n",
    "    x_train = cov_X_train\n",
    "    x_test = cov_X_test\n",
    "\n",
    "\n",
    "\n",
    "    num_classes = 2\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=(1,10, 10), data_format='channels_first'))\n",
    "    model.add(Conv2D(8, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=128,\n",
    "              epochs=4,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    scores.append(score)\n",
    "\n",
    "# Printing the results\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(np.asarray(scores)[:,1]),\n",
    "                                                          class_balance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import ShuffleSplit  \n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "# define model parameters\n",
    "# samples = 4703  # how many trials of eeg data\n",
    "n_features = 1  # how many channels of eeg in each sample\n",
    "time_steps = 161 # how many ms was each sample run for\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=2, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "epochs_data = epochs_train_total[:]\n",
    "labels = labels_total[:]\n",
    "\n",
    "scores = []\n",
    "for train_idx, test_idx in cv.split(labels):\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "    X_train = epochs_data[train_idx][:,8]\n",
    "    # 8 is for C3\n",
    "    \n",
    "#     X_train = X_train.reshape((36, 161, 64))\n",
    "    X_train = X_train.reshape((3762, 161, 1))\n",
    "    X_test = epochs_data[test_idx][:,8]\n",
    "#     X_test = X_test.reshape((9, 161, 64))\n",
    "    X_test = X_test.reshape((941, 161, 1))\n",
    "\n",
    "# code for building an LSTM with 100 neurons and dropout. Runs for 50 epochs\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=(time_steps, n_features)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(32, return_sequences=False, input_shape=(time_steps, n_features)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    model.fit(X_train, y_train, batch_size=9, epochs=50)\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    scores.append(score)\n",
    "\n",
    "\n",
    "# Printing the results\n",
    "class_balance = np.mean(labels == labels[0])\n",
    "class_balance = max(class_balance, 1. - class_balance)\n",
    "\n",
    "print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(np.asarray(scores)[:,1]),\n",
    "                                                          class_balance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)\n",
    "np.mean(np.asarray(scores)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.decoding import CSP\n",
    "csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
    "X_train = csp.fit_transform(epochs_data, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(epochs_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.decoding import CSP\n",
    "from sklearn import svm\n",
    "csp = CSP(n_components=4, reg=None, log=False, norm_trace=False)\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "# C = [0.01, 0.1, 1, 10, 1000]\n",
    "C = [1]\n",
    "# gam = [0.1, 0.2, 0.5, 0.8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "gam = [0.5]\n",
    "\n",
    "epochs_data = epochs_train_total[45:90]\n",
    "labels = labels_total[45:90]\n",
    "# 3762  ->   941\n",
    "#C as 1 amd gamma as 0.5 gives 0.5557917109458024%\n",
    "max_score = 0.0\n",
    "for C_ in C:\n",
    "    for gamma in gam:\n",
    "        clf = svm.SVC(C=C_, cache_size=200, class_weight=None, coef0=0.0,\n",
    "            decision_function_shape='ovr', degree=3, gamma=gamma, kernel='rbf',\n",
    "            max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "            tol=0.001, verbose=False)\n",
    "\n",
    "        print(\"now using C as {} and gamma as {}\".format(C_, gamma))\n",
    "        scores = []\n",
    "        for train_idx, test_idx in cv.split(labels):\n",
    "            y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "            X_train = epochs_data[train_idx]\n",
    "            X_train = X_train.reshape((36, 161, 64))\n",
    "            X_train_csp = csp.fit_transform(X_train, y_train)\n",
    "\n",
    "            X_test = epochs_data[test_idx]\n",
    "            X_test = X_test.reshape((9, 161, 64))\n",
    "            X_test_csp = csp.fit_transform(X_test, y_test)\n",
    "            #(4703, 4)\n",
    "\n",
    "            X = X_train_csp\n",
    "            y = y_train\n",
    "\n",
    "\n",
    "            clf.fit(X, y)  \n",
    "            y_predict = clf.predict(X_test_csp)\n",
    "\n",
    "\n",
    "            print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "            scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "        class_balance = np.mean(labels == labels[0])\n",
    "        class_balance = max(class_balance, 1. - class_balance)\n",
    "        print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                                  class_balance))\n",
    "        if np.mean(scores) > max_score:\n",
    "            max_score = np.mean(scores)\n",
    "            \n",
    "print(max_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "from mne.decoding import CSP\n",
    "from sklearn import svm\n",
    "csp = CSP(n_components=4, reg=None, log=False, norm_trace=False)\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "\n",
    "s = []\n",
    "for i in range(103):\n",
    "    start = 45 * i\n",
    "    end = start + 45\n",
    "    epochs_data = epochs_train_total[start:end]\n",
    "    labels = labels_total[start:end]\n",
    "\n",
    "    #C as 1 amd gamma as 0.5 gives 0.5557917109458024\n",
    "\n",
    "    clf = svm.SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "        decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',\n",
    "        max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "        tol=0.001, verbose=False)\n",
    "\n",
    "    print(\"now using C as {} and gamma as {}\".format(C_, gamma))\n",
    "    scores = []\n",
    "    for train_idx, test_idx in cv.split(labels):\n",
    "        y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "        X_train = epochs_data[train_idx]\n",
    "        X_train = X_train.reshape((36, 161, 64))\n",
    "        X_train_csp = csp.fit_transform(X_train, y_train)\n",
    "\n",
    "        X_test = epochs_data[test_idx]\n",
    "        X_test = X_test.reshape((9, 161, 64))\n",
    "        X_test_csp = csp.fit_transform(X_test, y_test)\n",
    "        #(4703, 4)\n",
    "\n",
    "\n",
    "\n",
    "        X = X_train_csp\n",
    "        y = y_train\n",
    "\n",
    "\n",
    "        clf.fit(X, y)  \n",
    "\n",
    "\n",
    "        y_predict = clf.predict(X_test_csp)\n",
    "\n",
    "\n",
    "        print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "        scores.append(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n",
    "\n",
    "    class_balance = np.mean(labels == labels[0])\n",
    "    class_balance = max(class_balance, 1. - class_balance)\n",
    "    print(\"Classification accuracy: %f / Chance level: %f\" % (np.mean(scores),\n",
    "                                                              class_balance))\n",
    "    s.append(np.mean(scores))\n",
    "    print(\"start is {}, end is {}, scores are {}\".format(start, end, s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8/30/2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_data = epochs_train_total[:45]\n",
    "labels = labels_total[:45]\n",
    "\n",
    "channels = [8,10,12]\n",
    "epochs_select_chan = epochs_data[:,channels,:]\n",
    "\n",
    "print(epochs_select_chan.shape)\n",
    "\n",
    "\n",
    "def avg_power(epochs_select_chan, labels):\n",
    "    hands = []\n",
    "    feets = []\n",
    "    samples, chan_num, timesteps = epochs_select_chan.shape\n",
    "    for sample in range(samples):\n",
    "        if labels[sample] == 0:\n",
    "            hands.append(epochs_select_chan[sample,:,:])\n",
    "        else:\n",
    "            feets.append(epochs_select_chan[sample,:,:])\n",
    "    hands = np.asarray(hands)\n",
    "    feets = np.asarray(feets) \n",
    "    samples, chan_num, timesteps = epochs_select_chan.shape\n",
    "    C3_hands = np.mean((hands[:,0,:])**2, axis = 0)\n",
    "    CZ_hands = np.mean((hands[:,1,:])**2, axis = 0)\n",
    "    C4_hands = np.mean((hands[:,2,:])**2, axis = 0)\n",
    "    C3_feets = np.mean((feets[:,0,:])**2, axis = 0)\n",
    "    CZ_feets = np.mean((feets[:,1,:])**2, axis = 0)\n",
    "    C4_feets = np.mean((feets[:,2,:])**2, axis = 0)\n",
    "    return C3_hands, CZ_hands, C4_hands, C3_feets, CZ_feets, C4_feets\n",
    "\n",
    "\n",
    "C3_hands, CZ_hands, C4_hands, C3_feets, CZ_feets, C4_feets = avg_power(epochs_select_chan,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(C3_hands)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(C3_feets)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# label 0 means hands, label 1 means feets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "coeffs = pywt.wavedec(C4_hands, 'db4', level=4)\n",
    "#because filtered to be 7 - 30, can only have 4 db level\n",
    "\n",
    "# for c in coeffs:\n",
    "#     plt.figure()\n",
    "#     plt.plot(c)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def make_dwt_epoch(C3_hands, CZ_hands, C4_hands, C3_feets, CZ_feets, C4_feets):\n",
    "    dwt_hands = []\n",
    "    dwt_hands.append(pywt.wavedec(C3_hands, 'db4', level=4)[0])\n",
    "    dwt_hands.append(pywt.wavedec(C4_hands, 'db4', level=4)[0])\n",
    "    dwt_hands.append(pywt.wavedec(CZ_hands, 'db4', level=4)[0])  \n",
    "    dwt_feets = []\n",
    "    dwt_feets.append(pywt.wavedec(C3_feets, 'db4', level=4)[0]) \n",
    "    dwt_feets.append(pywt.wavedec(C4_feets, 'db4', level=4)[0])\n",
    "    dwt_feets.append(pywt.wavedec(CZ_feets, 'db4', level=4)[0])   \n",
    "    return np.asarray(dwt_hands), np.asarray(dwt_feets)\n",
    "\n",
    "\n",
    "dwt_hands, dwt_feets = make_dwt_epoch(C3_hands, CZ_hands, C4_hands, C3_feets, CZ_feets, C4_feets)\n",
    "plt.plot(dwt_hands[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_epochs(epochs_train_total, labels_total):\n",
    "    epochs = []\n",
    "    labels_dwt = []\n",
    "    for ind in range(len(e_index)-1):\n",
    "        start = e_index[ind]\n",
    "        end = e_index[ind+1]\n",
    "        epochs_data = epochs_train_total[start:end]\n",
    "        labels = labels_total[start:end]\n",
    "        channels = [8,10,12]\n",
    "        epochs_select_chan = epochs_data[:,channels,:]\n",
    "        C3_hands, CZ_hands, C4_hands, C3_feets, CZ_feets, C4_feets = avg_power(epochs_select_chan, labels)\n",
    "        dwt_hands, dwt_feets = make_dwt_epoch(C3_hands, CZ_hands, C4_hands, C3_feets, CZ_feets, C4_feets)\n",
    "       \n",
    "        epochs.append(dwt_hands)\n",
    "        labels_dwt.append(0)\n",
    "        epochs.append(dwt_feets)\n",
    "        labels_dwt.append(1)\n",
    "        \n",
    "    return np.asarray(epochs), np.asarray(labels_dwt)\n",
    "        \n",
    "epochs, labels = make_epochs(epochs_train_total, labels_total)\n",
    "epochs = epochs.swapaxes(1,2)\n",
    "print(epochs.shape)\n",
    "\n",
    "print(labels[:10])\n",
    "\n",
    "plt.plot(epochs[1,:,0])\n",
    "plt.plot(epochs[1,:,1])\n",
    "plt.plot(epochs[1,:,2])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs[3,:,0])\n",
    "plt.plot(epochs[3,:,1])\n",
    "plt.plot(epochs[3,:,2])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs[5,:,0])\n",
    "plt.plot(epochs[5,:,1])\n",
    "plt.plot(epochs[5,:,2])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs[7,:,0])\n",
    "plt.plot(epochs[7,:,1])\n",
    "plt.plot(epochs[7,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "subject = 3\n",
    "\n",
    "start = e_index[subject-1]\n",
    "end = e_index[subject+20]\n",
    "\n",
    "print(\"start is {}, end is {}\".format(start, end))\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "testing_epochs = np.asarray(testing_epochs)\n",
    "\n",
    "testing_epochs = testing_epochs.swapaxes(1,2)\n",
    "\n",
    "time_steps = 16\n",
    "n_features = 3\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(3, return_sequences=True, input_shape=(time_steps, n_features)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(10, return_sequences=False, input_shape=(time_steps, n_features)))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "testing_epochs_ANN = testing_epochs.reshape(testing_epochs.shape[0], -1)\n",
    "print(np.asarray(testing_epochs_ANN)[start:end,:].shape)\n",
    "model = Sequential()\n",
    "model.add(Dense(60, input_dim=48, init='uniform', activation='relu'))\n",
    "model.add(Dense(1, init='uniform', activation='relu'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# model.fit(np.asarray(testing_epochs)[start:end,:,:], labels_total[start:end], batch_size=1, epochs=20)\n",
    "model.fit(np.asarray(testing_epochs_ANN)[start:end,:], labels_total[start:end], batch_size=1, epochs=20)\n",
    "\n",
    "\n",
    "\n",
    "# score = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X, y)  \n",
    "\n",
    "\n",
    "y_predict = clf.predict(X_test_csp)\n",
    "\n",
    "\n",
    "print(sklearn.metrics.accuracy_score(y_predict, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples,_,_ = epochs_train_total.shape\n",
    "# epochs_test = []\n",
    "# labels_test = []\n",
    "# for s in range(samples):\n",
    "#     e = epochs_train_total[s,channels,:].reshape(1,3,161)\n",
    "#     C3_hands, CZ_hands, C4_hands, C3_feets, CZ_feets, C4_feets = avg_power(e,labels_total)\n",
    "#     dwt_hands, dwt_feets = make_dwt_epoch(C3_hands, CZ_hands, C4_hands, C3_feets, CZ_feets, C4_feets)\n",
    "#     epochs_test.append(dwt_hands)\n",
    "#     labels_test.append(0)\n",
    "#     epochs_test.append(dwt_feets)\n",
    "#     labels_test.append(1)\n",
    "\n",
    "# print(epochs_test.shape)\n",
    "\n",
    "# def make_testing_epoch(epochs_train_total):\n",
    "\n",
    "import pywt\n",
    "\n",
    "testing_epochs = []\n",
    "single_epoch = []\n",
    "samples, chan_num, timesteps = epochs_train_total.shape\n",
    "epochs_power = epochs_train_total**2   \n",
    "for s in range(samples):\n",
    "    single_epoch = []\n",
    "    single_epoch.append(pywt.wavedec(epochs_power[s,8,:], 'db4', level=4)[0])\n",
    "    single_epoch.append(pywt.wavedec(epochs_power[s,10,:], 'db4', level=4)[0])\n",
    "    single_epoch.append(pywt.wavedec(epochs_power[s,12,:], 'db4', level=4)[0])\n",
    "    testing_epochs.append(np.asarray(single_epoch))\n",
    "\n",
    "print(np.asarray(testing_epochs).shape)\n",
    "\n",
    "print(len(labels_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
